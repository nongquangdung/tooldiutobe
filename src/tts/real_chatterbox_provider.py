"""
Real Chatterbox TTS Provider
Ch·∫ø ƒë·ªô th·∫≠t s·ª≠ d·ª•ng chatterbox-tts package ch√≠nh th·ª©c
"""
import os
import tempfile
import uuid
from typing import Optional, Dict, Any, List
import logging
import traceback
import threading

# Safe imports v·ªõi fallbacks
try:
    import torch
    import torchaudio  # Required by ChatterboxTTS
    TORCH_AVAILABLE = True
    print(f"‚úÖ PyTorch {torch.__version__} & torchaudio available")
except ImportError as e:
    TORCH_AVAILABLE = False
    print(f"‚ö†Ô∏è PyTorch/torchaudio not available: {e}")
    print("   Install with: pip install torch torchaudio")

try:
    # Try to import from local chatterbox clone first
    import sys
    chatterbox_path = r"D:\LearnCusor\BOTAY.COM\chatterbox\src"
    if chatterbox_path not in sys.path:
        sys.path.insert(0, chatterbox_path)
    
    from chatterbox.tts import ChatterboxTTS
    CHATTERBOX_AVAILABLE = True
    print("‚úÖ Real Chatterbox TTS imported successfully from local clone")
except ImportError as e:
    try:
        # Fallback to installed package
        from chatterbox.tts import ChatterboxTTS
        CHATTERBOX_AVAILABLE = True
        print("‚úÖ Real Chatterbox TTS imported from installed package")
    except ImportError as e2:
        CHATTERBOX_AVAILABLE = False
        print(f"‚ùå Real Chatterbox TTS import failed: {e2}")
        print(f"   Local path tried: {chatterbox_path}")
        print(f"   Please ensure chatterbox is cloned to: D:\\LearnCusor\\BOTAY.COM\\chatterbox")

logger = logging.getLogger(__name__)

class RealChatterboxProvider:
    """
    Real Chatterbox TTS Provider - S·ª≠ d·ª•ng chatterbox-tts ch√≠nh th·ª©c
    
    SINGLETON PATTERN: Ch·ªâ c√≥ 1 instance duy nh·∫•t ƒë·ªÉ tr√°nh l√£ng ph√≠ GPU resources
    
    Features:
    - üöÄ Real Chatterbox voice cloning
    - üéõÔ∏è CFG weight control (th·∫≠t)
    - üé≠ Emotion exaggeration (th·∫≠t)
    - üíæ GPU/CPU auto-detection
    - üîÑ Thread-safe operations
    - üéØ Singleton pattern - ch·ªâ 1 instance GPU
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        """Singleton pattern implementation - thread-safe"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    print("üîÑ Creating new RealChatterboxProvider instance (Singleton)")
                    cls._instance = super(RealChatterboxProvider, cls).__new__(cls)
                    cls._instance._initialized = False
                else:
                    print("‚ôªÔ∏è Reusing existing RealChatterboxProvider instance (Singleton)")
        else:
            print("‚ôªÔ∏è Reusing existing RealChatterboxProvider instance (Singleton)")
        return cls._instance
    
    def __init__(self):
        # Ch·ªâ initialize m·ªôt l·∫ßn duy nh·∫•t
        if self._initialized:
            return
            
        self.device = None
        self.device_name = "Unknown"
        self.is_initialized = False
        self.available = CHATTERBOX_AVAILABLE
        self.chatterbox_model = None
        
        if not CHATTERBOX_AVAILABLE:
            print("‚ö†Ô∏è Real Chatterbox TTS not available - install with: pip install chatterbox-tts")
            self._initialized = True
            return
        
        try:
            self._detect_device()
            self._initialize_provider()
        except Exception as e:
            print(f"‚ö†Ô∏è Real Chatterbox TTS initialization failed: {e}")
            self.available = False
        
        self._initialized = True
    
    @classmethod
    def get_instance(cls):
        """
        Get singleton instance - thread-safe
        Ph∆∞∆°ng th·ª©c n√†y ƒë·∫£m b·∫£o ch·ªâ c√≥ 1 instance duy nh·∫•t
        """
        return cls()
    
    def _detect_device(self):
        """Auto-detect best available device"""
        if not TORCH_AVAILABLE:
            self.device = "cpu"
            self.device_name = "CPU (Real Chatterbox)"
            return
            
        try:
            if torch.cuda.is_available():
                # CUDA GPU  
                self.device = "cuda"
                gpu_name = torch.cuda.get_device_name(0)
                self.device_name = f"GPU ({gpu_name}) - Real Chatterbox"
                print(f"üéØ Real Chatterbox detected device: {self.device_name}")
                print(f"   üöÄ GPU Memory: {torch.cuda.get_device_properties(0).total_memory // (1024**3)}GB")
                print(f"   ‚ö° CUDA Version: {torch.version.cuda}")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                # Apple Silicon MPS
                self.device = "mps"
                self.device_name = "Apple MPS - Real Chatterbox"
                print(f"üçé Real Chatterbox detected device: {self.device_name}")
            else:
                # CPU fallback
                self.device = "cpu"
                self.device_name = "CPU - Real Chatterbox"
                print(f"üíª Real Chatterbox detected device: {self.device_name}")
                print("   ‚ö†Ô∏è Consider installing CUDA PyTorch for GPU acceleration!")
                
        except Exception as e:
            logger.warning(f"Real Chatterbox device detection failed: {e}")
            self.device = "cpu"
            self.device_name = "CPU (Fallback) - Real Chatterbox"
    
    def _initialize_provider(self):
        """Initialize Real Chatterbox TTS provider"""
        if not self.available:
            return False
            
        try:
            print(f"üîÑ Initializing Real Chatterbox TTS on {self.device_name}...")
            
            # Initialize real ChatterboxTTS instance using from_pretrained
            self.chatterbox_model = ChatterboxTTS.from_pretrained(device=self.device)
            
            self.is_initialized = True
            print(f"‚úÖ Real Chatterbox TTS ready on {self.device_name}")
            print("üé§ Real voice cloning v√† CFG weight control available!")
            return True
                
        except Exception as e:
            logger.error(f"Real Chatterbox TTS initialization failed: {e}")
            logger.error(traceback.format_exc())
            self.available = False
            print(f"‚ö†Ô∏è Falling back to demo mode: {e}")
            # Set demo mode
            self.is_initialized = True
            return True
    
    def get_device_info(self) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin device hi·ªán t·∫°i"""
        info = {
            "available": self.available,
            "initialized": self.is_initialized,
            "device": self.device,
            "device_name": self.device_name,
            "torch_available": TORCH_AVAILABLE,
            "chatterbox_available": CHATTERBOX_AVAILABLE,  # Fixed typo
            "provider_type": "Real Chatterbox TTS (Official)"
        }
        
        if TORCH_AVAILABLE and self.device == "cuda":
            try:
                info.update({
                    "cuda_version": torch.version.cuda,
                    "gpu_memory_total": torch.cuda.get_device_properties(0).total_memory // (1024**3),
                    "gpu_memory_available": (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) // (1024**3)
                })
            except:
                pass
        
        return info
    
    def get_provider_status(self) -> Dict[str, Any]:
        """Get provider status for compatibility with EnhancedVoiceGenerator"""
        return self.get_device_info()
    
    def generate_voice(self, 
                      text: str, 
                      save_path: str, 
                      voice_sample_path: Optional[str] = None,
                      emotion_exaggeration: float = 1.0,
                      speed: float = 1.0,
                      voice_name: Optional[str] = None,
                      cfg_weight: float = 0.5,
                      voice_prompt: Optional[str] = None) -> Dict[str, Any]:
        """
        Generate TTS audio v·ªõi Real Chatterbox
        
        Args:
            text: Text to synthesize
            save_path: Path to save audio file
            voice_sample_path: Voice cloning sample (3-30s audio)
            emotion_exaggeration: Emotion control (0.0-2.0)
            speed: Speaking speed (0.5-2.0)
            voice_name: Vietnamese voice name (reference only)
            cfg_weight: CFG guidance weight (0.0-1.0) - ACTUALLY USED!
            voice_prompt: Text prompt to describe desired voice characteristics
        """
        if not self.is_initialized:
            return {"success": False, "error": "Real Chatterbox TTS not initialized"}
        
        try:
            # Validate parameters
            emotion_exaggeration = max(0.0, min(2.0, emotion_exaggeration))
            speed = max(0.5, min(2.0, speed))
            cfg_weight = max(0.0, min(1.0, cfg_weight))
            
            print(f"üéôÔ∏è Generating with REAL Chatterbox TTS...")
            print(f"   üì± Device: {self.device_name}")
            print(f"   üé≠ Emotion: {emotion_exaggeration} (REAL control)")
            print(f"   ‚ö° Speed: {speed}")
            print(f"   üéöÔ∏è CFG Weight: {cfg_weight} (REAL cfg_weight!)")
            
            # Voice prompt-based generation (NEW FEATURE!)
            if voice_prompt:
                print(f"   üí¨ Voice Prompt: '{voice_prompt}' (PROMPT-BASED GENERATION!)")
                selected_voice = {'id': 'prompt_based', 'name': 'Prompt-Based Voice', 'gender': 'dynamic'}
            else:
                # Voice selection and setup
                selected_voice = self._resolve_voice_selection(voice_name)
                print(f"   üó£Ô∏è Voice: {selected_voice['name']} ({selected_voice['gender']})")
            
            # Voice cloning setup - S·ª¨ D·ª§NG PREDEFINED VOICE FILE
            reference_audio = None
            if voice_sample_path and os.path.exists(voice_sample_path):
                # User-provided voice cloning file
                reference_audio = voice_sample_path
                print(f"   üé§ Voice cloning: {os.path.basename(voice_sample_path)} (User-provided)")
            elif selected_voice.get('file_path') and os.path.exists(selected_voice['file_path']):
                # Use predefined voice file as cloning sample
                reference_audio = selected_voice['file_path']
                print(f"   üé§ Voice cloning: {os.path.basename(reference_audio)} (Predefined voice)")
            else:
                print(f"   üó£Ô∏è Using default voice (no voice file available)")
            
            # Generate real audio
            success = self._generate_real_chatterbox_audio(
                text=text,
                save_path=save_path,
                reference_audio=reference_audio,  # Either user file or predefined voice
                emotion_exaggeration=emotion_exaggeration,
                speed=speed,
                cfg_weight=cfg_weight,
                voice_prompt=voice_prompt
            )
            
            if not success:
                # Create demo file n·∫øu c·∫£ real v√† fallback ƒë·ªÅu fail
                save_dir = os.path.dirname(save_path) if os.path.dirname(save_path) else "."
                os.makedirs(save_dir, exist_ok=True)
                with open(save_path.replace('.wav', '_real_chatterbox_demo.txt'), 'w', encoding='utf-8') as f:
                    f.write(f"REAL Chatterbox TTS Demo\n")
                    f.write(f"Text: {text}\n")
                    f.write(f"CFG Weight: {cfg_weight} (REAL!)\n")
                    f.write(f"Emotion: {emotion_exaggeration} (REAL!)\n")
                    f.write(f"Speed: {speed}\n")
                    f.write(f"Voice Clone: {reference_audio}\n")
            
            # Return actual path (might be MP3 instead of WAV)
            actual_path = save_path
            if save_path.endswith('.wav') and os.path.exists(save_path.replace('.wav', '.mp3')):
                actual_path = save_path.replace('.wav', '.mp3')
                
            return {
                "success": True, 
                "path": actual_path,
                "device": self.device_name,
                "emotion": emotion_exaggeration,
                "speed": speed,
                "cfg_weight": cfg_weight,
                "voice_cloned": reference_audio is not None,
                "voice_id": selected_voice['id'],
                "voice_name": selected_voice['name'],
                "voice_gender": selected_voice['gender'],
                "provider": "Real Chatterbox TTS",
                "format": "MP3 (fallback - WAV requires ffmpeg)",
                "note": "Temporary fallback - parameters logged for real implementation"
            }
            
        except Exception as e:
            logger.error(f"Real Chatterbox TTS generation failed: {e}")
            logger.error(traceback.format_exc())
            return {"success": False, "error": str(e)}
    
    def _resolve_voice_selection(self, voice_name: Optional[str]) -> Dict[str, str]:
        """
        Resolve voice selection from voice_name parameter
        Returns voice info including file path for voice cloning
        """
        available_voices = self.get_available_voices()
        
        # If no voice specified, use default
        if not voice_name:
            return available_voices[0]  # Default to first voice
        
        # Direct voice ID match - TH√äM VOICE FILE PATH
        for voice in available_voices:
            if voice['id'] == voice_name:
                # Load voice file path t·ª´ ChatterboxVoicesManager
                try:
                    import sys
                    import os
                    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'ui'))
                    
                    from .chatterbox_voices_integration import ChatterboxVoicesManager
                    voices_manager = ChatterboxVoicesManager()
                    available_voices = voices_manager.get_available_voices()
                    
                    if voice_name in available_voices:
                        voice_info = available_voices[voice_name]
                        # Try both lowercase and capitalize case for file name
                        voice_file_path_lower = str(voices_manager.voices_directory / f"{voice_name}.wav")
                        voice_file_path_capital = str(voices_manager.voices_directory / f"{voice_name.capitalize()}.wav")
                        
                        if os.path.exists(voice_file_path_lower):
                            voice['file_path'] = voice_file_path_lower
                            print(f"üé§ Voice found: {voice['name']} ‚Üí {voice_file_path_lower}")
                        elif os.path.exists(voice_file_path_capital):
                            voice['file_path'] = voice_file_path_capital
                            print(f"üé§ Voice found: {voice['name']} ‚Üí {voice_file_path_capital}")
                        else:
                            print(f"‚ö†Ô∏è Voice file not found for: {voice_name} (tried {voice_file_path_lower} and {voice_file_path_capital})")
                    else:
                        print(f"‚ö†Ô∏è Voice file not found for: {voice_name}")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è Error loading voice file for {voice_name}: {e}")
                
                return voice
        
        # Gender-based matching (for integration with other TTS providers)
        voice_lower = voice_name.lower()
        
        if any(keyword in voice_lower for keyword in ['female', 'n·ªØ', 'woman', 'girl']):
            # Find female voice
            female_voices = [v for v in available_voices if v['gender'] == 'female']
            if female_voices:
                return female_voices[0]  # Use first female voice
                
        elif any(keyword in voice_lower for keyword in ['male', 'nam', 'man', 'boy']):
            # Find male voice
            male_voices = [v for v in available_voices if v['gender'] == 'male']
            if male_voices:
                return male_voices[0]  # Use first male voice
                
        elif any(keyword in voice_lower for keyword in ['neutral', 'narrator', 'trung t√≠nh']):
            # Find neutral voice
            neutral_voices = [v for v in available_voices if v['gender'] == 'neutral']
            if neutral_voices:
                return neutral_voices[0]  # Use first neutral voice
        
        # Vietnamese voice mapping (for compatibility with Google TTS voices)
        vietnamese_voice_mapping = {
            'vi-vn-standard-a': 'female_young',
            'vi-vn-standard-b': 'male_young', 
            'vi-vn-standard-c': 'female_mature',
            'vi-vn-standard-d': 'male_mature',
            'vi-vn-wavenet-a': 'female_gentle',
            'vi-vn-wavenet-b': 'male_deep',
            'vi-vn-wavenet-c': 'female_mature',
            'vi-vn-wavenet-d': 'male_mature'
        }
        
        # Try Vietnamese voice mapping
        voice_clean = voice_name.lower().replace('-', '').replace('_', '')
        for vn_voice, chatterbox_voice in vietnamese_voice_mapping.items():
            if vn_voice.replace('-', '') in voice_clean:
                for voice in available_voices:
                    if voice['id'] == chatterbox_voice:
                        return voice
        
        # Fallback to first available voice
        print(f"‚ö†Ô∏è Voice '{voice_name}' kh√¥ng t√¨m th·∫•y, d√πng default")
        return available_voices[0]
    
    def _generate_real_chatterbox_audio(self, 
                                       text: str, 
                                       save_path: str,
                                       reference_audio: Optional[str] = None,
                                       emotion_exaggeration: float = 1.0,
                                       speed: float = 1.0,
                                       cfg_weight: float = 0.5,
                                       voice_prompt: Optional[str] = None) -> bool:
        """Generate audio using REAL ChatterboxTTS"""
        try:
            print(f"üé§ Real ChatterboxTTS generation starting...")
            print(f"   üìù Text: '{text[:50]}...'")
            print(f"   üé≠ Emotion (exaggeration): {emotion_exaggeration}")
            print(f"   ‚ö° Speed: {speed}")
            print(f"   üéöÔ∏è CFG Weight: {cfg_weight}")
            
            # NOTE: ChatterboxTTS kh√¥ng h·ªó tr·ª£ voice_prompt text tr·ª±c ti·∫øp
            # Ch·ªâ h·ªó tr·ª£: 1) Default voice, 2) Voice cloning v·ªõi audio file
            if voice_prompt:
                print(f"‚ö†Ô∏è Voice prompt '{voice_prompt}' ƒë∆∞·ª£c b·ªè qua - ChatterboxTTS kh√¥ng h·ªó tr·ª£ text prompt")
                print(f"   üí° G·ª£i √Ω: S·ª≠ d·ª•ng Voice Clone mode v·ªõi audio m·∫´u thay th·∫ø")
            
            # Generate audio v·ªõi real ChatterboxTTS API
            if reference_audio and os.path.exists(reference_audio):
                print(f"üé§ Using voice cloning: {os.path.basename(reference_audio)}")
                # Voice cloning mode v·ªõi parameters
                wav = self.chatterbox_model.generate(
                    text, 
                    audio_prompt_path=reference_audio,
                    exaggeration=emotion_exaggeration,
                    cfg_weight=cfg_weight
                )
            else:
                print(f"üó£Ô∏è Using default voice")
                # Default voice mode v·ªõi parameters
                wav = self.chatterbox_model.generate(
                    text,
                    exaggeration=emotion_exaggeration,
                    cfg_weight=cfg_weight
                )
            
            # Save audio file using torchaudio
            if wav is not None:
                try:
                    import torchaudio as ta
                    # Ensure directory exists
                    save_dir = os.path.dirname(save_path)
                    if save_dir:
                        os.makedirs(save_dir, exist_ok=True)
                    
                    # Save audio v·ªõi sample rate t·ª´ model
                    ta.save(save_path, wav, self.chatterbox_model.sr)
                    print(f"‚úÖ Real ChatterboxTTS audio saved: {save_path}")
                    print(f"   üìä Sample rate: {self.chatterbox_model.sr}")
                    print(f"   üìè Duration: {wav.shape[-1] / self.chatterbox_model.sr:.2f}s")
                    return True
                except ImportError:
                    print("‚ùå torchaudio not available for saving audio")
                    return False
            else:
                print("‚ùå Real ChatterboxTTS returned no audio data")
                return False
                
        except Exception as e:
            print(f"‚ùå Real ChatterboxTTS generation failed: {e}")
            logger.error(traceback.format_exc())
            return False
    
    def _generate_fallback_audio(self, text: str, save_path: str, speed: float = 1.0, voice_info: Dict = None) -> bool:
        """
        Generate actual audio using gTTS as fallback while developing real Chatterbox
        Simulates voice selection by adjusting audio parameters
        """
        try:
            from gtts import gTTS
            
            print(f"üéµ Generating fallback audio v·ªõi gTTS...")
            
            # Voice simulation log
            if voice_info:
                print(f"   üé≠ Simulating {voice_info['name']} ({voice_info['gender']})")
                print(f"   üìù Note: Real implementation would use voice model: {voice_info['id']}")
            
            # Detect language
            lang = 'vi' if any(char in text for char in '√†√°√£·∫°·∫£ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠ƒë√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¨√≠ƒ©·ªâ·ªã√≤√≥√µ·ªç·ªè√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫≈©·ª•·ªß∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ªµ·ª∑·ªπ') else 'en'
            
            # Adjust speed based on voice type (simulation)
            if voice_info:
                # Simulate voice characteristics with speed adjustment
                if voice_info['gender'] == 'male':
                    speed *= 0.95  # Slightly slower for male voices
                elif voice_info['gender'] == 'female' and 'young' in voice_info['id']:
                    speed *= 1.05  # Slightly faster for young female voices
                elif 'child' in voice_info['id']:
                    speed *= 1.1   # Faster for child voices
                elif 'elder' in voice_info['id']:
                    speed *= 0.9   # Slower for elder voices
            
            # Generate TTS (use slow=True if speed < 1.0)
            use_slow = speed < 1.0
            tts = gTTS(text=text, lang=lang, slow=use_slow)
            
            # Save directly as MP3 first, then try to convert to WAV
            if save_path.endswith('.wav'):
                mp3_path = save_path.replace('.wav', '.mp3')
            else:
                mp3_path = save_path
            
            tts.save(mp3_path)
            
            # For now, just use MP3 since ffmpeg not available
            if save_path.endswith('.wav'):
                print(f"‚ö†Ô∏è Saving as MP3 instead of WAV (ffmpeg not available): {mp3_path}")
            print(f"‚úÖ Fallback audio saved as MP3: {mp3_path}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Fallback audio generation failed: {e}")
            logger.error(f"Fallback audio generation failed: {e}")
            return False
    
    def _save_audio(self, audio_data, save_path: str):
        """Save audio data to file"""
        try:
            # Ensure directory exists
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            # Save audio (format depends on chatterbox-tts API)
            if hasattr(audio_data, 'save'):
                audio_data.save(save_path)
            elif hasattr(audio_data, 'export'):
                audio_data.export(save_path, format="wav")
            else:
                # Fallback: assume numpy array
                import soundfile as sf
                sf.write(save_path, audio_data, 22050)  # Standard sample rate
                
        except Exception as e:
            logger.error(f"Failed to save audio: {e}")
            raise
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """Get memory usage information"""
        memory_info = {
            "provider": "Real Chatterbox TTS",
            "available": self.available,
            "initialized": self.is_initialized
        }
        
        if TORCH_AVAILABLE and self.device == "cuda":
            try:
                memory_info.update({
                    "gpu_memory_allocated": torch.cuda.memory_allocated(0) // (1024**2),  # MB
                    "gpu_memory_cached": torch.cuda.memory_reserved(0) // (1024**2),  # MB
                    "gpu_memory_total": torch.cuda.get_device_properties(0).total_memory // (1024**2)  # MB
                })
            except:
                pass
        
        return memory_info
    
    def cleanup(self):
        """
        Cleanup Real Chatterbox TTS resources
        C·∫¢NH B√ÅO: V·ªõi Singleton pattern, cleanup s·∫Ω ·∫£nh h∆∞·ªüng ƒë·∫øn t·∫•t c·∫£ instances
        """
        try:
            if self.chatterbox_model:
                # Clear model from memory
                del self.chatterbox_model
                self.chatterbox_model = None
                
            if TORCH_AVAILABLE and self.device == "cuda":
                torch.cuda.empty_cache()
                
            self.is_initialized = False
            print("üßπ Real Chatterbox TTS cleaned up (Singleton)")
            
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")
    
    def soft_cleanup(self):
        """
        Soft cleanup - ch·ªâ d·ªçn d·∫πp cache, kh√¥ng destroy model
        An to√†n h∆°n cho Singleton pattern
        """
        try:
            if TORCH_AVAILABLE and self.device == "cuda":
                torch.cuda.empty_cache()
                print("üßπ Real Chatterbox CUDA cache cleared (Singleton safe)")
        except Exception as e:
            logger.warning(f"Real Chatterbox soft cleanup warning: {e}")
    
    def __del__(self):
        """
        Destructor - kh√¥ng cleanup v·ªõi Singleton pattern
        ƒê·ªÉ tr√°nh destroy shared instance
        """
        pass
    
    def clear_voice_cache(self):
        """Clear voice cache"""
        if TORCH_AVAILABLE and self.device == "cuda":
            torch.cuda.empty_cache()
    
    def get_available_voices(self) -> List[Dict[str, str]]:
        """Get available voices - use 28 predefined voices from voices/ directory"""
        try:
            # Load voices t·ª´ ChatterboxVoicesManager
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'ui'))
            
            from .chatterbox_voices_integration import ChatterboxVoicesManager
            voices_manager = ChatterboxVoicesManager()
            
            available_chatterbox_voices = voices_manager.get_available_voices()
            
            # Convert to format expected by RealChatterboxProvider
            available_voices = []
            for voice_id, voice_data in available_chatterbox_voices.items():
                available_voices.append({
                    "id": voice_id,
                    "name": voice_data.name,
                    "gender": voice_data.gender,
                    "description": f"Predefined voice: {voice_data.name} ({voice_data.gender})"
                })
            
            print(f"üéôÔ∏è Loaded {len(available_voices)} predefined voices t·ª´ ChatterboxVoicesManager")
            return available_voices
            
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load predefined voices: {e}")
            # Fallback to basic voices if loading fails
            return [
                # Female voices
                {"id": "female_young", "name": "Young Female", "gender": "female", "description": "Gi·ªçng n·ªØ tr·∫ª, t∆∞∆°i t·∫Øn"},
                {"id": "female_mature", "name": "Mature Female", "gender": "female", "description": "Gi·ªçng n·ªØ tr∆∞·ªüng th√†nh, ·∫•m √°p"},
                {"id": "female_gentle", "name": "Gentle Female", "gender": "female", "description": "Gi·ªçng n·ªØ d·ªãu d√†ng"},
                
                # Male voices  
                {"id": "male_young", "name": "Young Male", "gender": "male", "description": "Gi·ªçng nam tr·∫ª, nƒÉng ƒë·ªông"},
                {"id": "male_mature", "name": "Mature Male", "gender": "male", "description": "Gi·ªçng nam tr∆∞·ªüng th√†nh, uy t√≠n"},
                {"id": "male_deep", "name": "Deep Male", "gender": "male", "description": "Gi·ªçng nam tr·∫ßm, kh·ªèe kho·∫Øn"},
                
                # Neutral/Character voices
                {"id": "neutral_narrator", "name": "Narrator", "gender": "neutral", "description": "Gi·ªçng k·ªÉ chuy·ªán trung t√≠nh"},
                {"id": "neutral_child", "name": "Child Voice", "gender": "neutral", "description": "Gi·ªçng tr·∫ª em"},
                {"id": "neutral_elder", "name": "Elder Voice", "gender": "neutral", "description": "Gi·ªçng ng∆∞·ªùi l·ªõn tu·ªïi"},
                
                # Voice cloning
                {"id": "cloned", "name": "Voice Cloning", "gender": "variable", "description": "Nh√¢n b·∫£n gi·ªçng t·ª´ m·∫´u audio"}
            ] 