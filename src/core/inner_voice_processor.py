<<<<<<< Updated upstream
#!/usr/bin/env python3
"""
ğŸ­ INNER VOICE PROCESSOR
=======================

Xá»­ lÃ½ hiá»‡u á»©ng inner voice (thoáº¡i ná»™i tÃ¢m) cho Voice Studio.
Sá»­ dá»¥ng FFmpeg Ä‘á»ƒ táº¡o echo effects cho dialogue vá»›i inner_voice: true
"""

import os
import subprocess
import tempfile
from enum import Enum
from typing import Dict, Any, Optional
from pathlib import Path

class InnerVoiceType(Enum):
    """CÃ¡c loáº¡i inner voice effects"""
    LIGHT = "light"      # Ná»™i tÃ¢m nháº¹ - tá»± sá»±, tÃ¢m sá»±
    DEEP = "deep"        # Ná»™i tÃ¢m sÃ¢u - cÄƒng tháº³ng, há»“i tÆ°á»Ÿng  
    DREAMY = "dreamy"    # Ná»™i tÃ¢m cÃ¡ch Ã¢m - xa thá»±c táº¡i, mÆ¡ há»“

class InnerVoiceProcessor:
    """Processor cho inner voice effects"""
    
    def __init__(self):
        self.ffmpeg_available = self._check_ffmpeg()
        
        # Default echo presets cho tá»«ng loáº¡i inner voice
        self.echo_presets = {
            InnerVoiceType.LIGHT: {
                "name": "Ná»™i tÃ¢m nháº¹",
                "description": "Tá»± sá»±, tÃ¢m sá»± - phÃ¹ há»£p ná»¯ tráº», nhÃ¢n váº­t suy tÆ°",
                "filter": "aecho=0.6:0.5:50:0.3",
                "suffix": "_inner_light"
            },
            InnerVoiceType.DEEP: {
                "name": "Ná»™i tÃ¢m sÃ¢u", 
                "description": "CÄƒng tháº³ng, há»“i tÆ°á»Ÿng - phÃ¹ há»£p Ä‘á»™c thoáº¡i nam, giá»ng náº·ng trÄ©u",
                "filter": "aecho=0.7:0.6:150:0.4|0.3",
                "suffix": "_inner_deep"
            },
            InnerVoiceType.DREAMY: {
                "name": "Ná»™i tÃ¢m cÃ¡ch Ã¢m",
                "description": "Xa thá»±c táº¡i, mÆ¡ há»“ - phÃ¹ há»£p cáº£nh má»™ng, máº¥t phÆ°Æ¡ng hÆ°á»›ng", 
                "filter": "volume=0.8,aecho=0.5:0.6:300:0.4,lowpass=f=3000",
                "suffix": "_inner_dreamy"
            }
        }
        
        # Load custom settings tá»« config file
        self.load_config_from_file()
    
    def _check_ffmpeg(self) -> bool:
        """Check náº¿u FFmpeg available"""
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
            return True
        except FileNotFoundError:
            return False
    
    def load_config_from_file(self):
        """Load custom inner voice settings tá»« unified_emotions.json"""
        try:
            config_path = "configs/emotions/unified_emotions.json"
            
            if os.path.exists(config_path):
                import json
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                if "inner_voice_config" in config and "presets" in config["inner_voice_config"]:
                    presets = config["inner_voice_config"]["presets"]
                    
                    print(f"ğŸ­ LOADING InnerVoiceProcessor config from file...")
                    
                    for type_name, preset_data in presets.items():
                        try:
                            type_enum = InnerVoiceType(type_name.lower())
                            
                            if type_enum in self.echo_presets:
                                # Update vá»›i settings tá»« file
                                if "filter" in preset_data:
                                    self.echo_presets[type_enum]["filter"] = preset_data["filter"]
                                    print(f"   âœ… {type_name}: filter='{preset_data['filter']}'")
                                
                                # Store UI params cho debugging
                                for key in ["delay", "decay", "gain"]:
                                    if key in preset_data:
                                        self.echo_presets[type_enum][key] = preset_data[key]
                                        
                        except ValueError:
                            print(f"   âš ï¸ Unknown inner voice type: {type_name}")
                    
                    print(f"âœ… InnerVoiceProcessor config loaded from {config_path}")
                else:
                    print(f"ğŸ“‹ No inner_voice_config found, using defaults")
            else:
                print(f"ğŸ“‹ Config file not found, using default presets")
                
        except Exception as e:
            print(f"âš ï¸ Warning: Could not load inner voice config: {e}")
            print(f"ğŸ“‹ Using default presets")
    
    def get_inner_voice_type(self, character_name: str, emotion: str, gender: str = "neutral") -> InnerVoiceType:
        """Tá»± Ä‘á»™ng chá»n loáº¡i inner voice dá»±a trÃªn character vÃ  emotion"""
        
        # Logic auto-select dá»±a trÃªn emotion vÃ  gender
        emotion_lower = emotion.lower()
        
        # Ná»™i tÃ¢m sÃ¢u - emotions cÄƒng tháº³ng, náº·ng ná»
        deep_emotions = [
            "sad", "angry", "anxious", "worried", "frustrated", "disappointed",
            "desperate", "commanding", "fierce", "dramatic", "mysterious", "suspenseful"
        ]
        
        # Ná»™i tÃ¢m cÃ¡ch Ã¢m - emotions mÆ¡ há»“, xa vá»i
        dreamy_emotions = [
            "whisper", "soft", "contemplative", "sleepy", "confused", "bewildered",
            "romantic", "innocent", "gentle"
        ]
        
        # Kiá»ƒm tra emotion
        if any(e in emotion_lower for e in deep_emotions):
            return InnerVoiceType.DEEP
        elif any(e in emotion_lower for e in dreamy_emotions):
            return InnerVoiceType.DREAMY
        else:
            # Default: ná»™i tÃ¢m nháº¹ cho emotions bÃ¬nh thÆ°á»ng
            return InnerVoiceType.LIGHT
    
    def set_custom_preset(self, type_name: str, params: dict):
        """Cáº­p nháº­t preset cho 1 type tá»« UI/config"""
        try:
            # Convert string to enum
            type_enum = InnerVoiceType(type_name.lower())
            
            if type_enum in self.echo_presets:
                print(f"ğŸ›ï¸ UPDATING {type_name} preset:")
                
                # Táº¡o filter string tá»« UI params
                if all(key in params for key in ["delay", "decay", "gain"]):
                    # Build FFmpeg filter tá»« UI params  
                    delay = params["delay"]
                    decay = params["decay"] 
                    gain = params["gain"]
                    custom_filter = params.get("filter", f"aecho={gain}:{decay}:{delay}:{decay}")
                    
                    print(f"   ğŸ“Š delay={delay}, decay={decay}, gain={gain}")
                    print(f"   ğŸ›ï¸ filter='{custom_filter}'")
                    
                    # Update preset vá»›i UI values
                    self.echo_presets[type_enum].update({
                        "filter": custom_filter,
                        "description": f"{self.echo_presets[type_enum]['description']} - tá»« UI",
                        **params  # Include all UI params
                    })
                    
                    print(f"âœ… Updated {type_name} preset successfully")
                else:
                    print(f"âš ï¸ Missing required params for {type_name}")
                    
        except ValueError as e:
            print(f"âŒ Invalid inner voice type: {type_name} - {e}")
        except Exception as e:
            print(f"âŒ Error updating preset {type_name}: {e}")
    
    def process_inner_voice(self, input_path: str, output_path: str, 
                          inner_voice_type: InnerVoiceType = InnerVoiceType.LIGHT) -> Dict[str, Any]:
        """Process audio file Ä‘á»ƒ táº¡o inner voice effect"""
        
        if not self.ffmpeg_available:
            return {
                "success": False,
                "error": "FFmpeg not available - cannot process inner voice"
            }
        
        if not os.path.exists(input_path):
            return {
                "success": False,
                "error": f"Input file not found: {input_path}"
            }
        
        try:
            # Æ¯u tiÃªn preset custom náº¿u cÃ³
            preset = self.echo_presets.get(inner_voice_type)
            
            if preset is None:
                preset = self.echo_presets[self.get_inner_voice_type(character_name, emotion)]
            
            print(f"ğŸ­ PROCESSING INNER VOICE: {os.path.basename(input_path)}")
            print(f"   ğŸª Type: {preset['name']}")
            print(f"   ğŸ“ Effect: {preset['description']}")
            
            # Build FFmpeg command
            cmd = [
                'ffmpeg', '-i', input_path,
                '-af', preset['filter'],
                '-y',  # Overwrite output
                output_path
            ]
            
            # Execute FFmpeg
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"âœ… INNER VOICE SUCCESS!")
                print(f"   ğŸ“ Original: {os.path.basename(input_path)}")
                print(f"   ğŸ“ Processed: {os.path.basename(output_path)}")
                
                # Get file info
                original_size = os.path.getsize(input_path)
                processed_size = os.path.getsize(output_path)
                
                return {
                    "success": True,
                    "output_path": output_path,
                    "inner_voice_type": inner_voice_type.value,
                    "preset_name": preset['name'],
                    "original_size": original_size,
                    "processed_size": processed_size,
                    "filter": preset['filter']
                }
            else:
                return {
                    "success": False,
                    "error": f"FFmpeg failed: {result.stderr}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"Error processing inner voice: {str(e)}"
            }
    
    def process_dialogue_with_inner_voice(self, input_path: str, dialogue_data: Dict[str, Any],
                                        output_dir: str) -> Dict[str, Any]:
        """Process má»™t dialogue vá»›i inner voice flag"""
        
        # Check náº¿u cÃ³ inner voice flag
        if not dialogue_data.get("inner_voice", False):
            # KhÃ´ng cÃ³ inner voice, return original path
            return {
                "success": True,
                "output_path": input_path,
                "inner_voice_applied": False
            }
        
        # Determine inner voice type
        character_id = dialogue_data.get("speaker", "unknown")
        emotion = dialogue_data.get("emotion", "neutral")
        
        # CÃ³ thá»ƒ override type báº±ng inner_voice_type field
        if "inner_voice_type" in dialogue_data:
            type_str = dialogue_data["inner_voice_type"].lower()
            inner_voice_type = {
                "light": InnerVoiceType.LIGHT,
                "deep": InnerVoiceType.DEEP, 
                "dreamy": InnerVoiceType.DREAMY
            }.get(type_str, InnerVoiceType.LIGHT)
        else:
            # Auto-detect based on emotion
            inner_voice_type = self.get_inner_voice_type(character_id, emotion)
        
        # Generate output filename
        input_name = Path(input_path).stem
        preset = self.echo_presets[inner_voice_type]
        output_name = f"{input_name}{preset['suffix']}.mp3"
        output_path = os.path.join(output_dir, output_name)
        
        # Process inner voice
        result = self.process_inner_voice(input_path, output_path, inner_voice_type)
        
        if result["success"]:
            result["inner_voice_applied"] = True
            result["original_path"] = input_path
        
        return result
    
    def get_available_types(self) -> Dict[str, Dict[str, str]]:
        """Get danh sÃ¡ch available inner voice types"""
        return {
            type_enum.value: {
                "name": preset["name"],
                "description": preset["description"],
                "filter": preset["filter"]
            }
            for type_enum, preset in self.echo_presets.items()
        }

def main():
    """Test inner voice processor"""
    processor = InnerVoiceProcessor()
    
    if not processor.ffmpeg_available:
        print("âŒ FFmpeg not available - cannot test inner voice")
        print("ğŸ’¡ Install FFmpeg to use this feature")
        return
    
    print("ğŸ­ Inner Voice Processor - Available Types:")
    print("=" * 50)
    
    types = processor.get_available_types()
    for type_id, info in types.items():
        print(f"\nğŸª {type_id.upper()}:")
        print(f"   ğŸ“ Name: {info['name']}")
        print(f"   ğŸ“– Description: {info['description']}")
        print(f"   ğŸ›ï¸ Filter: {info['filter']}")
    
    # Test vá»›i file cÃ³ sáºµn náº¿u cÃ³
    test_files = [
        "./test_audio_output/emotion_preview_neutral.wav",
        "./test_audio_output/emotion_preview_contemplative.wav"
    ]
    
    for test_file in test_files:
        if os.path.exists(test_file):
            print(f"\nğŸ§ª Testing vá»›i: {test_file}")
            
            for inner_type in InnerVoiceType:
                output_path = f"./test_inner_voice_{inner_type.value}.mp3"
                result = processor.process_inner_voice(test_file, output_path, inner_type)
                
                if result["success"]:
                    print(f"   âœ… {inner_type.value}: {result['preset_name']}")
                else:
                    print(f"   âŒ {inner_type.value}: {result.get('error', 'Unknown error')}")
            break
    else:
        print("\nğŸ“ No test audio files found")
        print("ğŸ’¡ Create some audio first to test inner voice effects")

if __name__ == '__main__':
=======
#!/usr/bin/env python3
"""
[THEATER] INNER VOICE PROCESSOR
=======================

Xá»­ lÃ½ hiá»‡u á»©ng inner voice (thoáº¡i ná»™i tÃ¢m) cho Voice Studio.
Sá»­ dá»¥ng FFmpeg Ä‘á»ƒ táº¡o echo effects cho dialogue vá»›i inner_voice: true
"""

import os
import subprocess
import tempfile
from enum import Enum
from typing import Dict, Any, Optional
from pathlib import Path

class InnerVoiceType(Enum):
    """CÃ¡c loáº¡i inner voice effects"""
    LIGHT = "light"      # Ná»™i tÃ¢m nháº¹ - tá»± sá»±, tÃ¢m sá»±
    DEEP = "deep"        # Ná»™i tÃ¢m sÃ¢u - cÄƒng tháº³ng, há»“i tÆ°á»Ÿng  
    DREAMY = "dreamy"    # Ná»™i tÃ¢m cÃ¡ch Ã¢m - xa thá»±c táº¡i, mÆ¡ há»“

class InnerVoiceProcessor:
    """Processor cho inner voice effects"""
    
    def __init__(self):
        self.ffmpeg_available = self._check_ffmpeg()
        
        # Default echo presets cho tá»«ng loáº¡i inner voice
        self.echo_presets = {
            InnerVoiceType.LIGHT: {
                "name": "Ná»™i tÃ¢m nháº¹",
                "description": "Tá»± sá»±, tÃ¢m sá»± - phÃ¹ há»£p ná»¯ tráº», nhÃ¢n váº­t suy tÆ°",
                "filter": "aecho=0.6:0.5:50:0.3",
                "suffix": "_inner_light"
            },
            InnerVoiceType.DEEP: {
                "name": "Ná»™i tÃ¢m sÃ¢u", 
                "description": "CÄƒng tháº³ng, há»“i tÆ°á»Ÿng - phÃ¹ há»£p Ä‘á»™c thoáº¡i nam, giá»ng náº·ng trÄ©u",
                "filter": "aecho=0.7:0.6:150:0.4|0.3",
                "suffix": "_inner_deep"
            },
            InnerVoiceType.DREAMY: {
                "name": "Ná»™i tÃ¢m cÃ¡ch Ã¢m",
                "description": "Xa thá»±c táº¡i, mÆ¡ há»“ - phÃ¹ há»£p cáº£nh má»™ng, máº¥t phÆ°Æ¡ng hÆ°á»›ng", 
                "filter": "volume=0.8,aecho=0.5:0.6:300:0.4,lowpass=f=3000",
                "suffix": "_inner_dreamy"
            }
        }
        
        # Load custom settings tá»« config file
        self.load_config_from_file()
    
    def _check_ffmpeg(self) -> bool:
        """Check náº¿u FFmpeg available"""
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True,
                         stderr=subprocess.DEVNULL)  # Suppress stderr
            return True
        except FileNotFoundError:
            return False
    
    def load_config_from_file(self):
        """Load custom inner voice settings tá»« unified_emotions.json"""
        try:
            config_path = "configs/emotions/unified_emotions.json"
            
            if os.path.exists(config_path):
                import json
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                if "inner_voice_config" in config and "presets" in config["inner_voice_config"]:
                    presets = config["inner_voice_config"]["presets"]
                    
                    print(f"[THEATER] LOADING InnerVoiceProcessor config from file...")
                    
                    for type_name, preset_data in presets.items():
                        try:
                            type_enum = InnerVoiceType(type_name.lower())
                            
                            if type_enum in self.echo_presets:
                                # Update vá»›i settings tá»« file
                                if "filter" in preset_data:
                                    self.echo_presets[type_enum]["filter"] = preset_data["filter"]
                                    print(f"   [OK] {type_name}: filter='{preset_data['filter']}'")
                                
                                # Store UI params cho debugging
                                for key in ["delay", "decay", "gain"]:
                                    if key in preset_data:
                                        self.echo_presets[type_enum][key] = preset_data[key]
                                        
                        except ValueError:
                            print(f"   [WARNING] Unknown inner voice type: {type_name}")
                    
                    print(f"[OK] InnerVoiceProcessor config loaded from {config_path}")
                else:
                    print(f"[CLIPBOARD] No inner_voice_config found, using defaults")
            else:
                print(f"[CLIPBOARD] Config file not found, using default presets")
                
        except Exception as e:
            print(f"[WARNING] Warning: Could not load inner voice config: {e}")
            print(f"[CLIPBOARD] Using default presets")
    
    def get_inner_voice_type(self, character_name: str, emotion: str, gender: str = "neutral") -> InnerVoiceType:
        """Tá»± Ä‘á»™ng chá»n loáº¡i inner voice dá»±a trÃªn character vÃ  emotion"""
        
        # Logic auto-select dá»±a trÃªn emotion vÃ  gender
        emotion_lower = emotion.lower()
        
        # Ná»™i tÃ¢m sÃ¢u - emotions cÄƒng tháº³ng, náº·ng ná»
        deep_emotions = [
            "sad", "angry", "anxious", "worried", "frustrated", "disappointed",
            "desperate", "commanding", "fierce", "dramatic", "mysterious", "suspenseful"
        ]
        
        # Ná»™i tÃ¢m cÃ¡ch Ã¢m - emotions mÆ¡ há»“, xa vá»i
        dreamy_emotions = [
            "whisper", "soft", "contemplative", "sleepy", "confused", "bewildered",
            "romantic", "innocent", "gentle"
        ]
        
        # Kiá»ƒm tra emotion
        if any(e in emotion_lower for e in deep_emotions):
            return InnerVoiceType.DEEP
        elif any(e in emotion_lower for e in dreamy_emotions):
            return InnerVoiceType.DREAMY
        else:
            # Default: ná»™i tÃ¢m nháº¹ cho emotions bÃ¬nh thÆ°á»ng
            return InnerVoiceType.LIGHT
    
    def set_custom_preset(self, type_name: str, params: dict):
        """Cáº­p nháº­t preset cho 1 type tá»« UI/config"""
        try:
            # Convert string to enum
            type_enum = InnerVoiceType(type_name.lower())
            
            if type_enum in self.echo_presets:
                print(f"[EMOJI] UPDATING {type_name} preset:")
                
                # Táº¡o filter string tá»« UI params
                if all(key in params for key in ["delay", "decay", "gain"]):
                    # Build FFmpeg filter tá»« UI params  
                    delay = params["delay"]
                    decay = params["decay"] 
                    gain = params["gain"]
                    custom_filter = params.get("filter", f"aecho={gain}:{decay}:{delay}:{decay}")
                    
                    print(f"   [STATS] delay={delay}, decay={decay}, gain={gain}")
                    print(f"   [EMOJI] filter='{custom_filter}'")
                    
                    # Update preset vá»›i UI values
                    self.echo_presets[type_enum].update({
                        "filter": custom_filter,
                        "description": f"{self.echo_presets[type_enum]['description']} - tá»« UI",
                        **params  # Include all UI params
                    })
                    
                    print(f"[OK] Updated {type_name} preset successfully")
                else:
                    print(f"[WARNING] Missing required params for {type_name}")
                    
        except ValueError as e:
            print(f"[EMOJI] Invalid inner voice type: {type_name} - {e}")
        except Exception as e:
            print(f"[EMOJI] Error updating preset {type_name}: {e}")
    
    def process_inner_voice(self, input_path: str, output_path: str, 
                          inner_voice_type: InnerVoiceType = InnerVoiceType.LIGHT) -> Dict[str, Any]:
        """Process audio file Ä‘á»ƒ táº¡o inner voice effect"""
        
        if not self.ffmpeg_available:
            return {
                "success": False,
                "error": "FFmpeg not available - cannot process inner voice"
            }
        
        if not os.path.exists(input_path):
            return {
                "success": False,
                "error": f"Input file not found: {input_path}"
            }
        
        try:
            # Æ¯u tiÃªn preset custom náº¿u cÃ³
            preset = self.echo_presets.get(inner_voice_type)
            
            if preset is None:
                preset = self.echo_presets[self.get_inner_voice_type(character_name, emotion)]
            
            print(f"[THEATER] PROCESSING INNER VOICE: {os.path.basename(input_path)}")
            print(f"   [CIRCUS] Type: {preset['name']}")
            print(f"   [EDIT] Effect: {preset['description']}")
            
            # Build FFmpeg command
            cmd = [
                'ffmpeg', '-i', input_path,
                '-af', preset['filter'],
                '-y',  # Overwrite output
                output_path
            ]
            
            # Execute FFmpeg (suppress stderr noise)
            result = subprocess.run(cmd, capture_output=True, text=True,
                                  stderr=subprocess.DEVNULL)
            
            if result.returncode == 0:
                print(f"[OK] INNER VOICE SUCCESS!")
                print(f"   [FOLDER] Original: {os.path.basename(input_path)}")
                print(f"   [FOLDER] Processed: {os.path.basename(output_path)}")
                
                # Get file info
                original_size = os.path.getsize(input_path)
                processed_size = os.path.getsize(output_path)
                
                return {
                    "success": True,
                    "output_path": output_path,
                    "inner_voice_type": inner_voice_type.value,
                    "preset_name": preset['name'],
                    "original_size": original_size,
                    "processed_size": processed_size,
                    "filter": preset['filter']
                }
            else:
                return {
                    "success": False,
                    "error": f"FFmpeg failed: {result.stderr}"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"Error processing inner voice: {str(e)}"
            }
    
    def process_dialogue_with_inner_voice(self, input_path: str, dialogue_data: Dict[str, Any],
                                        output_dir: str) -> Dict[str, Any]:
        """Process má»™t dialogue vá»›i inner voice flag"""
        
        # Check náº¿u cÃ³ inner voice flag
        if not dialogue_data.get("inner_voice", False):
            # KhÃ´ng cÃ³ inner voice, return original path
            return {
                "success": True,
                "output_path": input_path,
                "inner_voice_applied": False
            }
        
        # Determine inner voice type
        character_id = dialogue_data.get("speaker", "unknown")
        emotion = dialogue_data.get("emotion", "neutral")
        
        # CÃ³ thá»ƒ override type báº±ng inner_voice_type field
        if "inner_voice_type" in dialogue_data:
            type_str = dialogue_data["inner_voice_type"].lower()
            inner_voice_type = {
                "light": InnerVoiceType.LIGHT,
                "deep": InnerVoiceType.DEEP, 
                "dreamy": InnerVoiceType.DREAMY
            }.get(type_str, InnerVoiceType.LIGHT)
        else:
            # Auto-detect based on emotion
            inner_voice_type = self.get_inner_voice_type(character_id, emotion)
        
        # Generate output filename
        input_name = Path(input_path).stem
        preset = self.echo_presets[inner_voice_type]
        output_name = f"{input_name}{preset['suffix']}.mp3"
        output_path = os.path.join(output_dir, output_name)
        
        # Process inner voice
        result = self.process_inner_voice(input_path, output_path, inner_voice_type)
        
        if result["success"]:
            result["inner_voice_applied"] = True
            result["original_path"] = input_path
        
        return result
    
    def get_available_types(self) -> Dict[str, Dict[str, str]]:
        """Get danh sÃ¡ch available inner voice types"""
        return {
            type_enum.value: {
                "name": preset["name"],
                "description": preset["description"],
                "filter": preset["filter"]
            }
            for type_enum, preset in self.echo_presets.items()
        }

def main():
    """Test inner voice processor"""
    processor = InnerVoiceProcessor()
    
    if not processor.ffmpeg_available:
        print("[EMOJI] FFmpeg not available - cannot test inner voice")
        print("[IDEA] Install FFmpeg to use this feature")
        return
    
    print("[THEATER] Inner Voice Processor - Available Types:")
    print("=" * 50)
    
    types = processor.get_available_types()
    for type_id, info in types.items():
        print(f"\n[CIRCUS] {type_id.upper()}:")
        print(f"   [EDIT] Name: {info['name']}")
        print(f"   [BOOK] Description: {info['description']}")
        print(f"   [EMOJI] Filter: {info['filter']}")
    
    # Test vá»›i file cÃ³ sáºµn náº¿u cÃ³
    test_files = [
        "./test_audio_output/emotion_preview_neutral.wav",
        "./test_audio_output/emotion_preview_contemplative.wav"
    ]
    
    for test_file in test_files:
        if os.path.exists(test_file):
            print(f"\n[TEST] Testing vá»›i: {test_file}")
            
            for inner_type in InnerVoiceType:
                output_path = f"./test_inner_voice_{inner_type.value}.mp3"
                result = processor.process_inner_voice(test_file, output_path, inner_type)
                
                if result["success"]:
                    print(f"   [OK] {inner_type.value}: {result['preset_name']}")
                else:
                    print(f"   [EMOJI] {inner_type.value}: {result.get('error', 'Unknown error')}")
            break
    else:
        print("\n[FOLDER] No test audio files found")
        print("[IDEA] Create some audio first to test inner voice effects")

if __name__ == '__main__':
>>>>>>> Stashed changes
    main() 