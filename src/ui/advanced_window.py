from PySide6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, 
    QTextEdit, QPushButton, QLabel, QTabWidget, QListWidget, 
    QListWidgetItem, QMessageBox, QProgressBar, QComboBox, 
    QLineEdit, QCheckBox, QSplitter, QScrollArea, QFrame, QGroupBox,
    QGridLayout, QSlider, QSpinBox, QFileDialog, QStatusBar, QDialog,
    QTableWidget, QTableWidgetItem
)
from PySide6.QtCore import Qt, QThread, Signal, QTimer, QSize
from PySide6.QtGui import QTextCursor, QFont, QIcon, QAction, QPixmap
import os
import sys
import json
import subprocess
import tempfile
import platform
import traceback
import shutil
from .manual_voice_setup_dialog import ManualVoiceSetupDialog

# Import pipeline
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from core.video_pipeline import VideoPipeline
from video.effects_presets import EffectsPresets
from ai.prompt_templates import PromptTemplates
from core.api_manager import APIManager
from tts.voice_generator import VoiceGenerator

class VideoGenerationThread(QThread):
    progress_updated = Signal(int, str)
    finished = Signal(dict)
    
    def __init__(self, prompt, project_name, effects, use_custom_images=False, custom_images_folder=None,
                 voice_name="vi-VN-Standard-A", project_folder=None):
        super().__init__()
        self.prompt = prompt
        self.project_name = project_name
        self.effects = effects
        self.use_custom_images = use_custom_images
        self.custom_images_folder = custom_images_folder
        self.voice_name = voice_name
        self.project_folder = project_folder
        self.pipeline = VideoPipeline()
    
    def run(self):
        def progress_callback(step, message):
            self.progress_updated.emit(step, message)
        
        # T·∫°o video v·ªõi ho·∫∑c kh√¥ng c√≥ ·∫£nh th·ªß c√¥ng
        if self.use_custom_images and self.custom_images_folder:
            result = self.pipeline.create_video_with_custom_images(
                self.prompt, self.project_name, self.custom_images_folder, 
                self.effects, progress_callback
            )
        else:
            result = self.pipeline.create_video_from_prompt(
                self.prompt, self.project_name, self.effects, progress_callback,
                self.voice_name, self.project_folder
            )
        self.finished.emit(result)

class AdvancedMainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("AI Video Generator - Advanced")
        
        # T·ªëi ∆∞u k√≠ch th∆∞·ªõc cho MacOS 13 inch
        if platform.system() == "Darwin":  # macOS
            window_size = get_macos_window_size()
            self.setGeometry(50, 50, window_size['default_width'], window_size['default_height'])
            self.setMinimumSize(window_size['min_width'], window_size['min_height'])
            self.setMaximumSize(window_size['max_width'], window_size['max_height'])
        else:
            self.setGeometry(100, 100, 1000, 700)
        
        # Kh·ªüi t·∫°o pipeline v√† API manager
        self.pipeline = VideoPipeline()
        self.api_manager = APIManager()
        self.voice_generator = VoiceGenerator()
        self.current_project_id = None
        self.current_script_data = None  # Store generated script data
        
        # Thi·∫øt l·∫≠p style cho macOS
        self.setup_macos_style()
        
        # Widget trung t√¢m v·ªõi tabs
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        layout = QVBoxLayout()
        layout.setContentsMargins(10, 10, 10, 10)  # Gi·∫£m margin
        central_widget.setLayout(layout)
        
        # Tab widget
        self.tabs = QTabWidget()
        layout.addWidget(self.tabs)
        
        # T·∫°o c√°c tabs
        self.create_video_tab()
        self.create_voice_studio_tab()
        self.create_projects_tab()
        self.create_settings_tab()
        
        # T·∫°o status bar
        self.create_status_bar()
    
    def create_status_bar(self):
        """T·∫°o status bar v·ªõi th√¥ng tin h·ªá th·ªëng"""
        status_bar = self.statusBar()
        
        # Status text ch√≠nh
        self.status_text = "‚úÖ S·∫µn s√†ng"
        status_bar.showMessage(self.status_text)
        
        # API status indicator
        self.api_status_label = QLabel("üîë API: Checking...")
        status_bar.addPermanentWidget(self.api_status_label)
        
        # Ki·ªÉm tra API status ngay khi kh·ªüi ƒë·ªông
        self.update_api_status_indicator()
    
    def update_api_status_indicator(self):
        """C·∫≠p nh·∫≠t ch·ªâ b√°o tr·∫°ng th√°i API"""
        # Ki·ªÉm tra xem api_status_label ƒë√£ ƒë∆∞·ª£c t·∫°o ch∆∞a
        if not hasattr(self, 'api_status_label'):
            return
            
        try:
            status = self.api_manager.get_provider_status()
            
            # ƒê·∫øm s·ªë API available
            content_available = sum(status['content_providers'].values())
            image_available = sum(status['image_providers'].values()) 
            tts_available = sum(status['tts_providers'].values())
            
            total_available = content_available + image_available + tts_available
            
            if total_available >= 3:
                self.api_status_label.setText("üü¢ API: ƒê·∫ßy ƒë·ªß")
            elif total_available >= 1:
                self.api_status_label.setText("üü° API: M·ªôt ph·∫ßn")
            else:
                self.api_status_label.setText("üî¥ API: Ch∆∞a c·∫•u h√¨nh")
                
        except Exception:
            if hasattr(self, 'api_status_label'):
                self.api_status_label.setText("‚ö†Ô∏è API: L·ªói")
    
    def setup_macos_style(self):
        """Thi·∫øt l·∫≠p style ph√π h·ª£p v·ªõi macOS"""
        if platform.system() == "Darwin":
            # Font system c·ªßa macOS
            font = QFont("-apple-system", 13)  # macOS system font
            self.setFont(font)
            
            # S·ª≠ d·ª•ng stylesheet t·ª´ file ri√™ng
            self.setStyleSheet(get_macos_stylesheet())
    
    def create_video_tab(self):
        """Tab t·∫°o video m·ªõi v·ªõi layout t·ªëi ∆∞u cho MacOS"""
        tab = QWidget()
        
        # S·ª≠ d·ª•ng scroll area ƒë·ªÉ tr√°nh tr√†n m√†n h√¨nh
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        content_widget = QWidget()
        layout = QVBoxLayout()
        layout.setSpacing(8)  # Gi·∫£m spacing
        content_widget.setLayout(layout)
        
        # Group 1: Prompt v√† g·ª£i √Ω
        prompt_group = QGroupBox("üìù N·ªôi dung video")
        prompt_layout = QVBoxLayout()
        prompt_layout.setSpacing(6)
        
        # G·ª£i √Ω prompt - layout compact
        suggestions_layout = QGridLayout()
        suggestions_layout.addWidget(QLabel("Danh m·ª•c:"), 0, 0)
        
        self.category_combo = QComboBox()
        categories = PromptTemplates.get_all_categories()
        self.category_combo.addItem("-- Ch·ªçn danh m·ª•c --", "")
        for key, value in categories.items():
            self.category_combo.addItem(value["category"], key)
        self.category_combo.currentTextChanged.connect(self.load_prompt_suggestions)
        suggestions_layout.addWidget(self.category_combo, 0, 1)
        
        self.random_prompt_btn = QPushButton("üé≤ Ng·∫´u nhi√™n")
        self.random_prompt_btn.clicked.connect(self.get_random_prompt)
        suggestions_layout.addWidget(self.random_prompt_btn, 0, 2)
        
        prompt_layout.addLayout(suggestions_layout)
        
        # Danh s√°ch prompt g·ª£i √Ω
        self.prompt_suggestions_list = QComboBox()
        self.prompt_suggestions_list.addItem("-- Ch·ªçn prompt m·∫´u --")
        self.prompt_suggestions_list.currentTextChanged.connect(self.use_suggested_prompt)
        prompt_layout.addWidget(self.prompt_suggestions_list)
        
        # Nh·∫≠p prompt - gi·∫£m chi·ªÅu cao
        self.prompt_input = QTextEdit()
        self.prompt_input.setPlaceholderText("V√≠ d·ª•: T·∫°o video gi·ªõi thi·ªáu v·ªÅ du l·ªãch Vi·ªát Nam v·ªõi 5 ƒëi·ªÉm ƒë·∫øn n·ªïi ti·∫øng...")
        self.prompt_input.setMaximumHeight(80)  # Gi·∫£m t·ª´ 100 xu·ªëng 80
        prompt_layout.addWidget(self.prompt_input)
        
        prompt_group.setLayout(prompt_layout)
        layout.addWidget(prompt_group)
        
        # Group 2: C√†i ƒë·∫∑t d·ª± √°n
        project_group = QGroupBox("‚öôÔ∏è C√†i ƒë·∫∑t d·ª± √°n")
        project_layout = QGridLayout()
        project_layout.setSpacing(6)
        
        # T√™n project
        project_layout.addWidget(QLabel("T√™n d·ª± √°n:"), 0, 0)
        self.project_name_input = QLineEdit()
        self.project_name_input.setPlaceholderText("video_project")
        project_layout.addWidget(self.project_name_input, 0, 1, 1, 2)
        
        # Th∆∞ m·ª•c d·ª± √°n
        project_layout.addWidget(QLabel("Th∆∞ m·ª•c:"), 1, 0)
        self.project_folder_input = QLineEdit()
        self.project_folder_input.setPlaceholderText("M·∫∑c ƒë·ªãnh: ./projects/")
        self.project_folder_input.setReadOnly(True)
        project_layout.addWidget(self.project_folder_input, 1, 1)
        
        self.select_project_folder_btn = QPushButton("üìÅ")
        self.select_project_folder_btn.clicked.connect(self.select_project_folder)
        self.select_project_folder_btn.setMaximumWidth(40)
        project_layout.addWidget(self.select_project_folder_btn, 1, 2)
        
        project_group.setLayout(project_layout)
        layout.addWidget(project_group)
        
        # Group 3: T√πy ch·ªçn ·∫£nh
        image_group = QGroupBox("üñºÔ∏è T√πy ch·ªçn ·∫£nh")
        image_layout = QVBoxLayout()
        image_layout.setSpacing(6)
        
        # Radio buttons trong layout ngang
        image_options_layout = QHBoxLayout()
        self.auto_generate_radio = QCheckBox("T·ª± ƒë·ªông t·∫°o ·∫£nh AI")
        self.auto_generate_radio.setChecked(True)
        self.manual_images_radio = QCheckBox("Ch·ªçn ·∫£nh th·ªß c√¥ng")
        image_options_layout.addWidget(self.auto_generate_radio)
        image_options_layout.addWidget(self.manual_images_radio)
        image_layout.addLayout(image_options_layout)
        
        # Ch·ªçn th∆∞ m·ª•c ·∫£nh
        folder_layout = QHBoxLayout()
        self.select_images_btn = QPushButton("üìÅ Ch·ªçn th∆∞ m·ª•c ·∫£nh")
        self.select_images_btn.clicked.connect(self.select_images_folder)
        self.select_images_btn.setEnabled(False)
        folder_layout.addWidget(self.select_images_btn)
        
        self.selected_images_label = QLabel("Ch∆∞a ch·ªçn th∆∞ m·ª•c ·∫£nh")
        self.selected_images_label.setStyleSheet("color: gray; font-style: italic; font-size: 11px;")
        folder_layout.addWidget(self.selected_images_label)
        image_layout.addLayout(folder_layout)
        
        # K·∫øt n·ªëi s·ª± ki·ªán
        self.manual_images_radio.toggled.connect(self.toggle_image_mode)
        
        image_group.setLayout(image_layout)
        layout.addWidget(image_group)
        
        # Group 4: Hi·ªáu ·ª©ng
        effects_group = QGroupBox("‚ú® Hi·ªáu ·ª©ng")
        effects_layout = QVBoxLayout()
        effects_layout.setSpacing(6)
        
        # Preset hi·ªáu ·ª©ng
        preset_layout = QHBoxLayout()
        preset_layout.addWidget(QLabel("Preset:"))
        self.effects_preset_combo = QComboBox()
        presets = EffectsPresets.get_all_presets()
        for key, preset in presets.items():
            self.effects_preset_combo.addItem(f"{preset['name']} - {preset['description']}", key)
        self.effects_preset_combo.setCurrentText("NƒÉng ƒë·ªông")
        preset_layout.addWidget(self.effects_preset_combo)
        effects_layout.addLayout(preset_layout)
        
        # C√†i ƒë·∫∑t hi·ªáu ·ª©ng t√πy ch·ªânh
        custom_effects_layout = QHBoxLayout()
        self.zoom_checkbox = QCheckBox("Hi·ªáu ·ª©ng zoom")
        self.zoom_checkbox.setChecked(True)
        self.transitions_checkbox = QCheckBox("Chuy·ªÉn c·∫£nh")
        self.transitions_checkbox.setChecked(True)
        custom_effects_layout.addWidget(self.zoom_checkbox)
        custom_effects_layout.addWidget(self.transitions_checkbox)
        effects_layout.addLayout(custom_effects_layout)
        
        effects_group.setLayout(effects_layout)
        layout.addWidget(effects_group)
        
        # Group 5: Actions
        actions_group = QGroupBox("üé¨ T·∫°o video")
        actions_layout = QGridLayout()
        actions_layout.setSpacing(8)
        
        self.generate_story_btn = QPushButton("üìù T·∫°o c√¢u chuy·ªán")
        self.generate_story_btn.clicked.connect(self.generate_story_only)
        self.generate_story_btn.setToolTip("T·∫°o k·ªãch b·∫£n video t·ª´ prompt (Cmd+1)")
        self.generate_story_btn.setShortcut("Cmd+1" if platform.system() == "Darwin" else "Ctrl+1")
        actions_layout.addWidget(self.generate_story_btn, 0, 0)
        
        self.generate_audio_btn = QPushButton("üéµ T·∫°o Audio")
        self.generate_audio_btn.clicked.connect(self.generate_audio_only)
        self.generate_audio_btn.setEnabled(False)
        self.generate_audio_btn.setToolTip("T·∫°o audio t·ª´ k·ªãch b·∫£n ƒë√£ c√≥ (Cmd+2)")
        self.generate_audio_btn.setShortcut("Cmd+2" if platform.system() == "Darwin" else "Ctrl+2")
        actions_layout.addWidget(self.generate_audio_btn, 0, 1)
        
        # N√∫t t·∫°o video ho√†n ch·ªânh
        self.generate_video_btn = QPushButton("üé¨ T·∫°o Video Ho√†n ch·ªânh")
        self.generate_video_btn.clicked.connect(self.start_video_generation)
        self.generate_video_btn.setToolTip("T·∫°o video ho√†n ch·ªânh v·ªõi ·∫£nh v√† √¢m thanh (Cmd+3)")
        self.generate_video_btn.setShortcut("Cmd+3" if platform.system() == "Darwin" else "Ctrl+3")
        actions_layout.addWidget(self.generate_video_btn, 1, 0, 1, 2)
        
        # N√∫t c·∫•u h√¨nh gi·ªçng n√≥i th·ªß c√¥ng (lu√¥n hi·ªÉn th·ªã)
        self.manual_voice_setup_btn = QPushButton("üé≠ C·∫•u h√¨nh gi·ªçng theo nh√¢n v·∫≠t")
        self.manual_voice_setup_btn.clicked.connect(self.show_manual_voice_setup)
        self.manual_voice_setup_btn.setToolTip("T·∫°o v√† c·∫•u h√¨nh gi·ªçng n√≥i cho c√°c nh√¢n v·∫≠t th·ªß c√¥ng (Cmd+4)")
        self.manual_voice_setup_btn.setShortcut("Cmd+4" if platform.system() == "Darwin" else "Ctrl+4")
        actions_layout.addWidget(self.manual_voice_setup_btn, 2, 0, 1, 2)

        
        actions_group.setLayout(actions_layout)
        layout.addWidget(actions_group)
        
        # Group 6: Progress v√† Status
        progress_group = QGroupBox("üìä Ti·∫øn tr√¨nh")
        progress_layout = QVBoxLayout()
        progress_layout.setSpacing(6)
        
        # Progress bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        progress_layout.addWidget(self.progress_bar)
        
        # Progress label
        self.progress_label = QLabel("")
        self.progress_label.setVisible(False)
        self.progress_label.setStyleSheet("color: #666; font-size: 11px;")
        progress_layout.addWidget(self.progress_label)
        
        # Status v√† preview area
        self.status_label = QLabel("")
        self.status_label.setStyleSheet("color: #007AFF; font-weight: 500;")
        progress_layout.addWidget(self.status_label)
        
        # Preview content area - compact
        preview_label = QLabel("üìÑ Xem tr∆∞·ªõc n·ªôi dung:")
        preview_label.setStyleSheet("font-weight: 600; margin-top: 8px;")
        progress_layout.addWidget(preview_label)
        
        self.content_preview = QTextEdit()
        self.content_preview.setReadOnly(True)
        self.content_preview.setMaximumHeight(120)  # Compact height
        self.content_preview.setPlaceholderText("N·ªôi dung c√¢u chuy·ªán s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y sau khi t·∫°o...")
        progress_layout.addWidget(self.content_preview)
        
        # Audio controls - compact layout
        audio_controls_layout = QGridLayout()
        audio_controls_layout.setSpacing(6)
        
        self.open_audio_folder_btn = QPushButton("üìÅ Th∆∞ m·ª•c Audio")
        self.open_audio_folder_btn.clicked.connect(self.open_audio_folder)
        self.open_audio_folder_btn.setEnabled(False)
        self.open_audio_folder_btn.setToolTip("M·ªü th∆∞ m·ª•c ch·ª©a c√°c file audio ƒë√£ t·∫°o")
        audio_controls_layout.addWidget(self.open_audio_folder_btn, 0, 0)
        
        self.play_final_audio_btn = QPushButton("‚ñ∂Ô∏è Nghe Audio")
        self.play_final_audio_btn.clicked.connect(self.play_final_audio)
        self.play_final_audio_btn.setEnabled(False)
        self.play_final_audio_btn.setToolTip("Ph√°t file audio ho√†n ch·ªânh ƒë√£ gh√©p")
        audio_controls_layout.addWidget(self.play_final_audio_btn, 0, 1)
        
        progress_layout.addLayout(audio_controls_layout)
        
        # Voice settings - compact
        voice_layout = QHBoxLayout()
        voice_layout.addWidget(QLabel("Gi·ªçng TTS:"))
        self.voice_combo = QComboBox()
        vietnamese_voices = [
            "vi-VN-Standard-A (N·ªØ)",
            "vi-VN-Standard-B (Nam)",
            "vi-VN-Standard-C (N·ªØ)",
            "vi-VN-Standard-D (Nam)",
            "vi-VN-Wavenet-A (N·ªØ)",
            "vi-VN-Wavenet-B (Nam)",
            "vi-VN-Wavenet-C (N·ªØ)",
            "vi-VN-Wavenet-D (Nam)"
        ]
        self.voice_combo.addItems(vietnamese_voices)
        voice_layout.addWidget(self.voice_combo)
        progress_layout.addLayout(voice_layout)
        
        progress_group.setLayout(progress_layout)
        progress_group.setVisible(False)  # ·∫®n ban ƒë·∫ßu, hi·ªán khi c·∫ßn
        layout.addWidget(progress_group)
        
        # Store references
        self.progress_group = progress_group
        self.last_audio_output_dir = None
        self.last_final_audio_path = None
        
        # Th√™m stretch ƒë·ªÉ ƒë·∫©y n·ªôi dung l√™n tr√™n
        layout.addStretch()
        
        scroll.setWidget(content_widget)
        
        # Layout ch√≠nh c·ªßa tab
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(scroll)
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "üé¨ T·∫°o Video")
    
    def create_voice_studio_tab(self):
        """Tab Voice Studio ƒë·ªÉ c·∫•u h√¨nh gi·ªçng theo nh√¢n v·∫≠t v√† t·∫°o voice"""
        tab = QWidget()
        
        # S·ª≠ d·ª•ng scroll area
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        content_widget = QWidget()
        layout = QVBoxLayout()
        layout.setSpacing(12)
        layout.setContentsMargins(16, 16, 16, 16)
        content_widget.setLayout(layout)
        
        # Group 1: Import Data
        import_group = QGroupBox("üì• Import Script Data")
        import_layout = QVBoxLayout()
        import_layout.setSpacing(8)
        
        # Source selection
        source_layout = QHBoxLayout()
        source_layout.addWidget(QLabel("Ngu·ªìn d·ªØ li·ªáu:"))
        
        self.data_source_combo = QComboBox()
        self.data_source_combo.addItem("üìÅ Import t·ª´ file JSON", "file")
        self.data_source_combo.addItem("üîÑ S·ª≠ d·ª•ng data t·ª´ tab T·∫°o Video", "generated")
        self.data_source_combo.addItem("‚úèÔ∏è Nh·∫≠p th·ªß c√¥ng", "manual")
        self.data_source_combo.currentTextChanged.connect(self.switch_data_source)
        source_layout.addWidget(self.data_source_combo)
        
        source_layout.addStretch()
        import_layout.addLayout(source_layout)
        
        # File import section
        self.file_import_widget = QWidget()
        file_layout = QHBoxLayout()
        file_layout.setContentsMargins(0, 0, 0, 0)
        
        self.import_file_btn = QPushButton("üìÅ Ch·ªçn file JSON")
        self.import_file_btn.clicked.connect(self.import_script_file)
        file_layout.addWidget(self.import_file_btn)
        
        self.imported_file_label = QLabel("Ch∆∞a ch·ªçn file")
        self.imported_file_label.setStyleSheet("color: gray; font-style: italic;")
        file_layout.addWidget(self.imported_file_label)
        
        file_layout.addStretch()
        self.file_import_widget.setLayout(file_layout)
        import_layout.addWidget(self.file_import_widget)
        
        # Generated data section
        self.generated_data_widget = QWidget()
        generated_layout = QVBoxLayout()
        generated_layout.setContentsMargins(0, 0, 0, 0)
        
        generated_info = QLabel("üîÑ S·ª≠ d·ª•ng script data ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª´ tab 'T·∫°o Video'")
        generated_info.setStyleSheet("color: #007AFF; font-weight: bold;")
        generated_layout.addWidget(generated_info)
        
        self.use_generated_btn = QPushButton("üîÑ Load Data t·ª´ tab T·∫°o Video")
        self.use_generated_btn.clicked.connect(self.load_generated_script_data)
        generated_layout.addWidget(self.use_generated_btn)
        
        self.generated_data_widget.setLayout(generated_layout)
        self.generated_data_widget.setVisible(False)
        import_layout.addWidget(self.generated_data_widget)
        
        # Manual input section
        self.manual_input_widget = QWidget()
        manual_layout = QVBoxLayout()
        manual_layout.setContentsMargins(0, 0, 0, 0)
        
        manual_layout.addWidget(QLabel("‚úèÔ∏è Nh·∫≠p JSON script:"))
        self.manual_script_input = QTextEdit()
        self.manual_script_input.setPlaceholderText("Paste JSON script v√†o ƒë√¢y...")
        self.manual_script_input.setMaximumHeight(120)
        manual_layout.addWidget(self.manual_script_input)
        
        self.parse_manual_btn = QPushButton("‚úÖ Parse JSON")
        self.parse_manual_btn.clicked.connect(self.parse_manual_script)
        manual_layout.addWidget(self.parse_manual_btn)
        
        self.manual_input_widget.setLayout(manual_layout)
        self.manual_input_widget.setVisible(False)
        import_layout.addWidget(self.manual_input_widget)
        
        import_group.setLayout(import_layout)
        layout.addWidget(import_group)
        
        # Group 2: Script Overview
        overview_group = QGroupBox("üìã Script Overview")
        overview_layout = QVBoxLayout()
        overview_layout.setSpacing(8)
        
        # Script info
        self.script_info_label = QLabel("Ch∆∞a load script data")
        self.script_info_label.setStyleSheet("color: #666; font-style: italic;")
        overview_layout.addWidget(self.script_info_label)
        
        # Characters list
        characters_layout = QHBoxLayout()
        characters_layout.addWidget(QLabel("Nh√¢n v·∫≠t:"))
        self.characters_label = QLabel("Ch∆∞a c√≥ data")
        self.characters_label.setStyleSheet("font-weight: bold; color: #007AFF;")
        characters_layout.addWidget(self.characters_label)
        characters_layout.addStretch()
        overview_layout.addLayout(characters_layout)
        
        # Segments count
        segments_layout = QHBoxLayout()
        segments_layout.addWidget(QLabel("S·ªë segments:"))
        self.segments_count_label = QLabel("0")
        self.segments_count_label.setStyleSheet("font-weight: bold; color: #007AFF;")
        segments_layout.addWidget(self.segments_count_label)
        segments_layout.addStretch()
        overview_layout.addLayout(segments_layout)
        
        overview_group.setLayout(overview_layout)
        layout.addWidget(overview_group)
        
        # Group 4: Advanced Chatterbox Controls (Manual Configuration)
        chatterbox_group = QGroupBox("üéõÔ∏è C·∫•u h√¨nh Chatterbox TTS chi ti·∫øt (N√¢ng cao)")
        chatterbox_layout = QVBoxLayout()
        chatterbox_layout.setSpacing(8)
        
        # Enable/disable toggle
        chatterbox_controls_layout = QHBoxLayout()
        self.enable_chatterbox_manual = QCheckBox("S·ª≠ d·ª•ng c·∫•u h√¨nh th·ªß c√¥ng cho Chatterbox TTS")
        self.enable_chatterbox_manual.toggled.connect(self.toggle_chatterbox_manual_controls)
        chatterbox_controls_layout.addWidget(self.enable_chatterbox_manual)
        
        # Auto emotion mapping toggle
        self.enable_emotion_mapping = QCheckBox("üé≠ T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh c·∫£m x√∫c theo script")
        self.enable_emotion_mapping.setChecked(True)  # Default enabled
        self.enable_emotion_mapping.setToolTip("T·ª± ƒë·ªông map emotion labels (happy, sad, excited...) th√†nh emotion exaggeration values")
        chatterbox_controls_layout.addWidget(self.enable_emotion_mapping)
        
        chatterbox_controls_layout.addStretch()
        chatterbox_layout.addLayout(chatterbox_controls_layout)
        
        # Manual controls container
        self.chatterbox_manual_widget = QWidget()
        chatterbox_manual_layout = QVBoxLayout()
        chatterbox_manual_layout.setContentsMargins(20, 10, 10, 10)
        
        # Global settings v·ªõi input fields v√† sliders
        global_settings_layout = QGridLayout()
        global_settings_layout.setSpacing(8)
        
        # Emotion exaggeration row
        global_settings_layout.addWidget(QLabel("üé≠ Emotion Exaggeration:"), 0, 0)
        
        # Emotion slider
        self.emotion_slider = QSlider(Qt.Horizontal)
        self.emotion_slider.setRange(0, 300)  # 0.0 to 3.0
        self.emotion_slider.setValue(100)  # Default 1.0
        self.emotion_slider.valueChanged.connect(self.update_emotion_from_slider)
        global_settings_layout.addWidget(self.emotion_slider, 0, 1)
        
        # Emotion input field
        self.emotion_input = QLineEdit()
        self.emotion_input.setText("1.0")
        self.emotion_input.setMaximumWidth(60)
        self.emotion_input.setAlignment(Qt.AlignCenter)
        self.emotion_input.setStyleSheet("""
            QLineEdit {
                background-color: white;
                border: 1px solid #ccc;
                border-radius: 4px;
                padding: 2px;
                color: black;
            }
            QLineEdit:focus {
                border: 2px solid #007AFF;
            }
        """)
        self.emotion_input.textChanged.connect(self.update_emotion_from_input)
        global_settings_layout.addWidget(self.emotion_input, 0, 2)
        
        global_settings_layout.addWidget(QLabel("(0.0-3.0)"), 0, 3)
        
        # Speed row
        global_settings_layout.addWidget(QLabel("‚ö° Speed:"), 1, 0)
        
        # Speed slider
        self.speed_slider = QSlider(Qt.Horizontal)
        self.speed_slider.setRange(50, 200)  # 0.5 to 2.0
        self.speed_slider.setValue(100)  # Default 1.0
        self.speed_slider.valueChanged.connect(self.update_speed_from_slider)
        global_settings_layout.addWidget(self.speed_slider, 1, 1)
        
        # Speed input field
        self.speed_input = QLineEdit()
        self.speed_input.setText("1.0")
        self.speed_input.setMaximumWidth(60)
        self.speed_input.setAlignment(Qt.AlignCenter)
        self.speed_input.setStyleSheet("""
            QLineEdit {
                background-color: white;
                border: 1px solid #ccc;
                border-radius: 4px;
                padding: 2px;
                color: black;
            }
            QLineEdit:focus {
                border: 2px solid #007AFF;
            }
        """)
        self.speed_input.textChanged.connect(self.update_speed_from_input)
        global_settings_layout.addWidget(self.speed_input, 1, 2)
        
        global_settings_layout.addWidget(QLabel("(0.5-2.0)"), 1, 3)
        
        # CFG Weight row (NEW)
        global_settings_layout.addWidget(QLabel("üéöÔ∏è CFG Weight:"), 2, 0)
        
        # CFG Weight slider
        self.cfg_weight_slider = QSlider(Qt.Horizontal)
        self.cfg_weight_slider.setRange(0, 100)  # 0.0 to 1.0
        self.cfg_weight_slider.setValue(50)  # Default 0.5
        self.cfg_weight_slider.valueChanged.connect(self.update_cfg_weight_from_slider)
        global_settings_layout.addWidget(self.cfg_weight_slider, 2, 1)
        
        # CFG Weight input field
        self.cfg_weight_input = QLineEdit()
        self.cfg_weight_input.setText("0.5")
        self.cfg_weight_input.setMaximumWidth(60)
        self.cfg_weight_input.setAlignment(Qt.AlignCenter)
        self.cfg_weight_input.setStyleSheet("""
            QLineEdit {
                background-color: white;
                border: 1px solid #ccc;
                border-radius: 4px;
                padding: 2px;
                color: black;
            }
            QLineEdit:focus {
                border: 2px solid #007AFF;
            }
        """)
        self.cfg_weight_input.textChanged.connect(self.update_cfg_weight_from_input)
        global_settings_layout.addWidget(self.cfg_weight_input, 2, 2)
        
        global_settings_layout.addWidget(QLabel("(0.0-1.0)"), 2, 3)
        
        # Voice selection row (NEW)
        global_settings_layout.addWidget(QLabel("üó£Ô∏è Default Voice:"), 3, 0)
        
        # Voice combo
        self.default_voice_combo = QComboBox()
        self.default_voice_combo.setStyleSheet("""
            QComboBox {
                background-color: white;
                border: 1px solid #ccc;
                border-radius: 4px;
                padding: 2px;
                color: black;
            }
            QComboBox::drop-down {
                background-color: white;
            }
            QComboBox::down-arrow {
                color: black;
            }
            QComboBox QAbstractItemView {
                background-color: white;
                color: black;
                selection-background-color: #007AFF;
                selection-color: white;
            }
        """)
        self.update_default_voice_options()
        global_settings_layout.addWidget(self.default_voice_combo, 3, 1, 1, 2)
        
        # Voice preview button
        self.preview_default_voice_btn = QPushButton("üéß")
        self.preview_default_voice_btn.setMaximumWidth(40)
        self.preview_default_voice_btn.setToolTip("Preview default voice")
        self.preview_default_voice_btn.clicked.connect(self.preview_default_voice)
        global_settings_layout.addWidget(self.preview_default_voice_btn, 3, 3)
        
        chatterbox_manual_layout.addLayout(global_settings_layout)
        
        # Character-specific settings
        char_specific_label = QLabel("üé≠ C·∫•u h√¨nh ri√™ng cho t·ª´ng nh√¢n v·∫≠t:")
        char_specific_label.setStyleSheet("font-weight: bold; margin-top: 10px;")
        chatterbox_manual_layout.addWidget(char_specific_label)
        
        # Character settings table
        self.character_settings_table = QTableWidget()
        self.character_settings_table.setColumnCount(9)  # TƒÉng l√™n 9 columns (th√™m Voice Mode)
        self.character_settings_table.setHorizontalHeaderLabels([
            "Nh√¢n v·∫≠t", "Emotion", "Speed", "CFG Weight", "Mode", "Voice/Prompt/Clone", "Quick", "Status", "Preview"
        ])
        self.character_settings_table.horizontalHeader().setStretchLastSection(False)
        self.character_settings_table.setMaximumHeight(150)
        
        # Set column widths
        header = self.character_settings_table.horizontalHeader()
        header.resizeSection(0, 120)  # Character name
        header.resizeSection(1, 80)   # Emotion
        header.resizeSection(2, 80)   # Speed  
        header.resizeSection(3, 80)   # CFG Weight
        header.resizeSection(4, 150)  # Voice
        header.resizeSection(5, 80)   # Preview
        
        chatterbox_manual_layout.addWidget(self.character_settings_table)
        
        # Voice cloning section
        voice_clone_layout = QHBoxLayout()
        voice_clone_layout.addWidget(QLabel("üéôÔ∏è Voice Cloning:"))
        
        self.enable_voice_cloning = QCheckBox("B·∫≠t voice cloning")
        self.enable_voice_cloning.toggled.connect(self.toggle_voice_cloning)
        voice_clone_layout.addWidget(self.enable_voice_cloning)
        
        self.voice_clone_folder_btn = QPushButton("üìÅ Ch·ªçn th∆∞ m·ª•c voice samples")
        self.voice_clone_folder_btn.clicked.connect(self.select_voice_clone_folder)
        self.voice_clone_folder_btn.setEnabled(False)
        voice_clone_layout.addWidget(self.voice_clone_folder_btn)
        
        voice_clone_layout.addStretch()
        chatterbox_manual_layout.addLayout(voice_clone_layout)
        
        self.voice_clone_path_label = QLabel("Ch∆∞a ch·ªçn th∆∞ m·ª•c voice samples")
        self.voice_clone_path_label.setStyleSheet("color: gray; font-style: italic; margin-left: 20px;")
        chatterbox_manual_layout.addWidget(self.voice_clone_path_label)
        
        # üí° VOICE GENERATION HELP
        help_layout = QVBoxLayout()
        help_layout.addWidget(QLabel("üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:"))
        
        help_text = QLabel("""
‚Ä¢ <b>Voice Prompt</b>: Nh·∫≠p m√¥ t·∫£ gi·ªçng n√≥i cho t·ª´ng nh√¢n v·∫≠t ri√™ng bi·ªát trong b·∫£ng d∆∞·ªõi
‚Ä¢ <b>Voice Clone</b>: Ch·ªçn th∆∞ m·ª•c ch·ª©a audio samples ƒë·ªÉ clone gi·ªçng cho t·ª´ng nh√¢n v·∫≠t  
‚Ä¢ <b>Priority</b>: Voice Prompt > Voice Clone > Voice Selection
‚Ä¢ <b>Preview</b>: Nh·∫•n n√∫t üéß ƒë·ªÉ nghe th·ª≠ gi·ªçng v·ªõi settings hi·ªán t·∫°i
        """)
        help_text.setWordWrap(True)
        help_text.setStyleSheet("color: #666; font-size: 12px; padding: 8px; background-color: #f8f8f8; border-radius: 4px;")
        help_layout.addWidget(help_text)
        
        chatterbox_manual_layout.addLayout(help_layout)
        
        # Preset buttons
        preset_layout = QHBoxLayout()
        preset_layout.addWidget(QLabel("üé® Presets:"))
        
        self.preset_natural_btn = QPushButton("üåø Natural")
        self.preset_natural_btn.clicked.connect(lambda: self.apply_preset("natural"))
        preset_layout.addWidget(self.preset_natural_btn)
        
        self.preset_dramatic_btn = QPushButton("üé≠ Dramatic")
        self.preset_dramatic_btn.clicked.connect(lambda: self.apply_preset("dramatic"))
        preset_layout.addWidget(self.preset_dramatic_btn)
        
        self.preset_fast_btn = QPushButton("‚ö° Fast Speech")
        self.preset_fast_btn.clicked.connect(lambda: self.apply_preset("fast"))
        preset_layout.addWidget(self.preset_fast_btn)
        
        self.preset_slow_btn = QPushButton("üêå Slow & Clear")
        self.preset_slow_btn.clicked.connect(lambda: self.apply_preset("slow"))
        preset_layout.addWidget(self.preset_slow_btn)
        
        preset_layout.addStretch()
        chatterbox_manual_layout.addLayout(preset_layout)
        
        self.chatterbox_manual_widget.setLayout(chatterbox_manual_layout)
        self.chatterbox_manual_widget.setVisible(False)  # Hidden by default
        chatterbox_layout.addWidget(self.chatterbox_manual_widget)
        
        chatterbox_group.setLayout(chatterbox_layout)
        layout.addWidget(chatterbox_group)
        
        # Group 5: Generation Controls
        generation_group = QGroupBox("üéôÔ∏è T·∫°o Audio")
        generation_layout = QVBoxLayout()
        generation_layout.setSpacing(8)
        
        # TTS Provider - CH·ªà CHATTERBOX
        provider_layout = QHBoxLayout()
        provider_layout.addWidget(QLabel("TTS Provider:"))
        
        provider_info = QLabel("ü§ñ Chatterbox TTS (AI Voice Cloning)")
        provider_info.setStyleSheet("font-weight: bold; color: #007AFF; padding: 4px;")
        provider_layout.addWidget(provider_info)
        
        provider_layout.addStretch()
        generation_layout.addLayout(provider_layout)
        
        # Output settings
        output_layout = QHBoxLayout()
        output_layout.addWidget(QLabel("Th∆∞ m·ª•c output:"))
        
        self.voice_output_input = QLineEdit()
        self.voice_output_input.setPlaceholderText("./voice_studio_output/")
        self.voice_output_input.setReadOnly(True)
        output_layout.addWidget(self.voice_output_input)
        
        self.select_voice_output_btn = QPushButton("üìÅ")
        self.select_voice_output_btn.clicked.connect(self.select_voice_output_folder)
        self.select_voice_output_btn.setMaximumWidth(40)
        output_layout.addWidget(self.select_voice_output_btn)
        
        generation_layout.addLayout(output_layout)
        
        # Generation buttons
        generation_buttons_layout = QHBoxLayout()
        
        self.generate_selected_btn = QPushButton("üé§ T·∫°o voice cho nh√¢n v·∫≠t ƒë√£ ch·ªçn")
        self.generate_selected_btn.clicked.connect(self.generate_selected_character_voice)
        self.generate_selected_btn.setEnabled(False)
        generation_buttons_layout.addWidget(self.generate_selected_btn)
        
        self.generate_all_btn = QPushButton("üé≠ T·∫°o voice cho t·∫•t c·∫£ nh√¢n v·∫≠t")
        self.generate_all_btn.clicked.connect(self.generate_all_voices)
        self.generate_all_btn.setEnabled(False)
        generation_buttons_layout.addWidget(self.generate_all_btn)
        
        generation_layout.addLayout(generation_buttons_layout)
        
        generation_group.setLayout(generation_layout)
        layout.addWidget(generation_group)
        
        # Group 6: Progress & Results
        progress_group = QGroupBox("üìä Ti·∫øn tr√¨nh & K·∫øt qu·∫£")
        progress_layout = QVBoxLayout()
        progress_layout.setSpacing(8)
        
        # Progress bar
        self.voice_progress_bar = QProgressBar()
        self.voice_progress_bar.setVisible(False)
        progress_layout.addWidget(self.voice_progress_bar)
        
        # Progress text
        self.voice_progress_text = QLabel("S·∫µn s√†ng t·∫°o voice")
        self.voice_progress_text.setStyleSheet("color: #666; font-style: italic;")
        progress_layout.addWidget(self.voice_progress_text)
        
        # Results area
        self.voice_results_text = QTextEdit()
        self.voice_results_text.setMaximumHeight(100)
        self.voice_results_text.setReadOnly(True)
        self.voice_results_text.setPlaceholderText("K·∫øt qu·∫£ t·∫°o voice s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y...")
        progress_layout.addWidget(self.voice_results_text)
        
        # Action buttons
        action_buttons_layout = QHBoxLayout()
        
        self.open_voice_folder_btn = QPushButton("üìÅ M·ªü th∆∞ m·ª•c output")
        self.open_voice_folder_btn.clicked.connect(self.open_voice_output_folder)
        action_buttons_layout.addWidget(self.open_voice_folder_btn)
        
        self.clear_voice_results_btn = QPushButton("üßπ X√≥a k·∫øt qu·∫£")
        self.clear_voice_results_btn.clicked.connect(self.clear_voice_results)
        action_buttons_layout.addWidget(self.clear_voice_results_btn)
        
        action_buttons_layout.addStretch()
        progress_layout.addLayout(action_buttons_layout)
        
        progress_group.setLayout(progress_layout)
        layout.addWidget(progress_group)
        
        # Initialize data
        self.voice_studio_script_data = None
        self.voice_mapping = {}
        self.character_chatterbox_settings = {}  # Store per-character settings
        self.voice_clone_folder = None
        
        # Set content and add to scroll
        scroll.setWidget(content_widget)
        
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(scroll)
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "üéôÔ∏è Voice Studio")
    
    def create_projects_tab(self):
        """Tab qu·∫£n l√Ω projects v·ªõi layout t·ªëi ∆∞u cho MacOS"""
        tab = QWidget()
        
        # S·ª≠ d·ª•ng splitter ƒë·ªÉ chia ƒë√¥i m√†n h√¨nh
        splitter = QSplitter(Qt.Horizontal)
        
        # Panel tr√°i: Danh s√°ch projects
        left_panel = QWidget()
        left_layout = QVBoxLayout()
        left_layout.setContentsMargins(8, 8, 8, 8)
        left_layout.setSpacing(8)
        
        # Header v·ªõi n√∫t refresh
        header_layout = QHBoxLayout()
        header_layout.addWidget(QLabel("üìÅ Danh s√°ch d·ª± √°n"))
        header_layout.addStretch()
        refresh_btn = QPushButton("üîÑ")
        refresh_btn.setToolTip("L√†m m·ªõi danh s√°ch")
        refresh_btn.setMaximumWidth(40)
        refresh_btn.clicked.connect(self.refresh_projects)
        header_layout.addWidget(refresh_btn)
        left_layout.addLayout(header_layout)
        
        # Danh s√°ch projects
        self.projects_list = QListWidget()
        self.projects_list.itemClicked.connect(self.load_project_details)
        left_layout.addWidget(self.projects_list)
        
        left_panel.setLayout(left_layout)
        splitter.addWidget(left_panel)
        
        # Panel ph·∫£i: Chi ti·∫øt project
        right_panel = QWidget()
        right_layout = QVBoxLayout()
        right_layout.setContentsMargins(8, 8, 8, 8)
        right_layout.setSpacing(8)
        
        # Header chi ti·∫øt
        right_layout.addWidget(QLabel("üìã Chi ti·∫øt d·ª± √°n"))
        
        # Chi ti·∫øt project v·ªõi scroll
        details_scroll = QScrollArea()
        details_scroll.setWidgetResizable(True)
        details_scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        self.project_details = QTextEdit()
        self.project_details.setReadOnly(True)
        details_scroll.setWidget(self.project_details)
        right_layout.addWidget(details_scroll)
        
        # N√∫t actions
        actions_group = QGroupBox("üõ†Ô∏è Thao t√°c")
        actions_layout = QGridLayout()
        actions_layout.setSpacing(8)
        
        self.open_folder_btn = QPushButton("üìÅ M·ªü th∆∞ m·ª•c")
        self.open_folder_btn.clicked.connect(self.open_project_folder)
        actions_layout.addWidget(self.open_folder_btn, 0, 0)
        
        self.delete_project_btn = QPushButton("üóëÔ∏è X√≥a d·ª± √°n")
        self.delete_project_btn.clicked.connect(self.delete_project)
        self.delete_project_btn.setProperty("class", "danger")
        actions_layout.addWidget(self.delete_project_btn, 0, 1)
        
        actions_group.setLayout(actions_layout)
        right_layout.addWidget(actions_group)
        
        right_panel.setLayout(right_layout)
        splitter.addWidget(right_panel)
        
        # Thi·∫øt l·∫≠p t·ª∑ l·ªá splitter (40% - 60%)
        splitter.setSizes([400, 600])
        
        # Layout ch√≠nh c·ªßa tab
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(splitter)
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "üìÅ D·ª± √°n")
        
        # Load projects khi kh·ªüi t·∫°o
        self.refresh_projects()
    
    def create_settings_tab(self):
        """Tab c√†i ƒë·∫∑t v·ªõi layout t·ªëi ∆∞u cho MacOS"""
        tab = QWidget()
        
        # S·ª≠ d·ª•ng scroll area cho settings
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        content_widget = QWidget()
        layout = QVBoxLayout()
        layout.setSpacing(12)
        layout.setContentsMargins(16, 16, 16, 16)
        content_widget.setLayout(layout)
        
        # Group 1: API Keys cho AI Content
        ai_content_group = QGroupBox("üìù AI Sinh n·ªôi dung")
        ai_content_layout = QGridLayout()
        ai_content_layout.setSpacing(8)
        
        ai_content_layout.addWidget(QLabel("OpenAI API Key (GPT-4):"), 0, 0)
        self.openai_key_input = QLineEdit()
        self.openai_key_input.setEchoMode(QLineEdit.Password)
        self.openai_key_input.setPlaceholderText("sk-...")
        ai_content_layout.addWidget(self.openai_key_input, 0, 1)
        
        ai_content_layout.addWidget(QLabel("Claude API Key:"), 1, 0)
        self.claude_key_input = QLineEdit()
        self.claude_key_input.setEchoMode(QLineEdit.Password)
        self.claude_key_input.setPlaceholderText("sk-ant-...")
        ai_content_layout.addWidget(self.claude_key_input, 1, 1)
        
        ai_content_layout.addWidget(QLabel("DeepSeek API Key:"), 2, 0)
        self.deepseek_key_input = QLineEdit()
        self.deepseek_key_input.setEchoMode(QLineEdit.Password)
        self.deepseek_key_input.setPlaceholderText("sk-...")
        ai_content_layout.addWidget(self.deepseek_key_input, 2, 1)
        
        ai_content_group.setLayout(ai_content_layout)
        layout.addWidget(ai_content_group)
        
        # Group 2: API Keys cho Image Generation
        image_gen_group = QGroupBox("üé® AI T·∫°o ·∫£nh")
        image_gen_layout = QGridLayout()
        image_gen_layout.setSpacing(8)
        
        # DALL-E info
        dalle_info = QLabel("DALL-E (OpenAI) - d√πng chung key OpenAI")
        dalle_info.setStyleSheet("color: #666; font-style: italic; font-size: 11px;")
        image_gen_layout.addWidget(dalle_info, 0, 0, 1, 2)
        
        image_gen_layout.addWidget(QLabel("Midjourney API Key:"), 1, 0)
        self.midjourney_key_input = QLineEdit()
        self.midjourney_key_input.setEchoMode(QLineEdit.Password)
        image_gen_layout.addWidget(self.midjourney_key_input, 1, 1)
        
        image_gen_layout.addWidget(QLabel("Stability AI Key:"), 2, 0)
        self.stability_key_input = QLineEdit()
        self.stability_key_input.setEchoMode(QLineEdit.Password)
        self.stability_key_input.setPlaceholderText("sk-...")
        image_gen_layout.addWidget(self.stability_key_input, 2, 1)
        
        image_gen_group.setLayout(image_gen_layout)
        layout.addWidget(image_gen_group)
        
        # Group 3: API Keys cho Text-to-Speech
        tts_group = QGroupBox("üé§ Text-to-Speech")
        tts_layout = QGridLayout()
        tts_layout.setSpacing(8)
        
        tts_layout.addWidget(QLabel("ElevenLabs API Key:"), 0, 0)
        self.elevenlabs_key_input = QLineEdit()
        self.elevenlabs_key_input.setEchoMode(QLineEdit.Password)
        self.elevenlabs_key_input.setPlaceholderText("sk_...")
        tts_layout.addWidget(self.elevenlabs_key_input, 0, 1)
        
        tts_layout.addWidget(QLabel("Google Cloud TTS Key:"), 1, 0)
        self.google_tts_key_input = QLineEdit()
        self.google_tts_key_input.setEchoMode(QLineEdit.Password)
        tts_layout.addWidget(self.google_tts_key_input, 1, 1)
        
        tts_layout.addWidget(QLabel("Azure Speech Key:"), 2, 0)
        self.azure_speech_key_input = QLineEdit()
        self.azure_speech_key_input.setEchoMode(QLineEdit.Password)
        tts_layout.addWidget(self.azure_speech_key_input, 2, 1)
        
        # Chatterbox TTS Device Info
        chatterbox_info = QLabel("ü§ñ Chatterbox TTS: Auto-detect CUDA/MPS/CPU")
        chatterbox_info.setStyleSheet("color: #007AFF; font-weight: bold; font-size: 12px;")
        tts_layout.addWidget(chatterbox_info, 3, 0, 1, 2)
        
        # Device status button
        self.chatterbox_device_btn = QPushButton("üì± Ki·ªÉm tra Device")
        self.chatterbox_device_btn.clicked.connect(self.show_chatterbox_device_info)
        tts_layout.addWidget(self.chatterbox_device_btn, 4, 0)
        
        # Clear cache button
        self.chatterbox_clear_btn = QPushButton("üßπ X√≥a Cache")
        self.chatterbox_clear_btn.clicked.connect(self.clear_chatterbox_cache)
        tts_layout.addWidget(self.chatterbox_clear_btn, 4, 1)
        
        tts_group.setLayout(tts_layout)
        layout.addWidget(tts_group)
        
        # Group 4: Provider Selection
        providers_group = QGroupBox("‚öôÔ∏è Ch·ªçn nh√† cung c·∫•p")
        providers_layout = QGridLayout()
        providers_layout.setSpacing(8)
        
        providers_layout.addWidget(QLabel("AI Sinh n·ªôi dung:"), 0, 0)
        self.content_provider_combo = QComboBox()
        self.content_provider_combo.addItems(self.api_manager.get_available_content_providers())
        providers_layout.addWidget(self.content_provider_combo, 0, 1)
        
        providers_layout.addWidget(QLabel("AI T·∫°o ·∫£nh:"), 1, 0)
        self.image_provider_combo = QComboBox()
        self.image_provider_combo.addItems(self.api_manager.get_available_image_providers())
        providers_layout.addWidget(self.image_provider_combo, 1, 1)
        
        providers_layout.addWidget(QLabel("Text-to-Speech:"), 2, 0)
        self.tts_provider_combo = QComboBox()
        self.tts_provider_combo.addItems(self.api_manager.get_available_tts_providers())
        providers_layout.addWidget(self.tts_provider_combo, 2, 1)
        
        providers_group.setLayout(providers_layout)
        layout.addWidget(providers_group)
        
        # Group 5: Video Settings
        video_group = QGroupBox("üé¨ C√†i ƒë·∫∑t Video")
        video_layout = QGridLayout()
        video_layout.setSpacing(8)
        
        video_layout.addWidget(QLabel("ƒê·ªô ph√¢n gi·∫£i:"), 0, 0)
        self.resolution_combo = QComboBox()
        self.resolution_combo.addItems(["1920x1080", "1280x720", "1080x1080"])
        video_layout.addWidget(self.resolution_combo, 0, 1)
        
        video_layout.addWidget(QLabel("FPS:"), 1, 0)
        self.fps_spinbox = QSpinBox()
        self.fps_spinbox.setRange(15, 60)
        self.fps_spinbox.setValue(25)
        video_layout.addWidget(self.fps_spinbox, 1, 1)
        
        video_group.setLayout(video_layout)
        layout.addWidget(video_group)
        
        # Group 6: Actions
        actions_group = QGroupBox("üõ†Ô∏è Thao t√°c")
        actions_layout = QGridLayout()
        actions_layout.setSpacing(8)
        
        save_settings_btn = QPushButton("üíæ L∆∞u c√†i ƒë·∫∑t")
        save_settings_btn.clicked.connect(self.save_settings)
        actions_layout.addWidget(save_settings_btn, 0, 0)
        
        check_api_btn = QPushButton("üîç Ki·ªÉm tra API")
        check_api_btn.clicked.connect(self.check_api_status)
        actions_layout.addWidget(check_api_btn, 0, 1)
        
        refresh_providers_btn = QPushButton("üîÑ L√†m m·ªõi")
        refresh_providers_btn.clicked.connect(self.refresh_providers)
        actions_layout.addWidget(refresh_providers_btn, 1, 0, 1, 2)
        
        actions_group.setLayout(actions_layout)
        layout.addWidget(actions_group)
        
        # Th√™m stretch ƒë·ªÉ ƒë·∫©y n·ªôi dung l√™n tr√™n
        layout.addStretch()
        
        scroll.setWidget(content_widget)
        
        # Layout ch√≠nh c·ªßa tab
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(scroll)
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "‚öôÔ∏è C√†i ƒë·∫∑t")
        
        # Load c√†i ƒë·∫∑t hi·ªán t·∫°i t·ª´ file config.env
        self.load_current_settings()
        
        # Update API status when settings change (safe call)
        self.update_api_status_indicator()
    
    def start_video_generation(self):
        """B·∫Øt ƒë·∫ßu t·∫°o video"""
        prompt = self.prompt_input.toPlainText().strip()
        if not prompt:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng nh·∫≠p prompt!")
            return
        
        project_name = self.project_name_input.text().strip() or "video_project"
        
        # L·∫•y preset hi·ªáu ·ª©ng
        preset_key = self.effects_preset_combo.currentData()
        if preset_key:
            effects = EffectsPresets.get_preset_by_name(preset_key)
        else:
            # Fallback to manual settings
            effects = {
                "zoom": self.zoom_checkbox.isChecked(),
                "transitions": {"crossfade": True} if self.transitions_checkbox.isChecked() else None
            }
        
        # Disable n√∫t v√† hi·ªán progress
        self.generate_video_btn.setEnabled(False)
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 8)
        
        # Ki·ªÉm tra ch·∫ø ƒë·ªô ·∫£nh th·ªß c√¥ng
        use_custom_images = self.manual_images_radio.isChecked()
        custom_images_folder = getattr(self, 'selected_images_folder', None) if use_custom_images else None
        
        if use_custom_images and not custom_images_folder:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng ch·ªçn th∆∞ m·ª•c ch·ª©a ·∫£nh!")
            return
        
        # L·∫•y th√¥ng tin gi·ªçng ƒë·ªçc v√† th∆∞ m·ª•c
        voice_name = self.voice_combo.currentText().split(' ')[0]  # L·∫•y t√™n gi·ªçng (vd: vi-VN-Standard-A)
        project_folder = self.project_folder_input.text() or None
        
        # T·∫°o thread
        self.generation_thread = VideoGenerationThread(
            prompt, project_name, effects, use_custom_images, custom_images_folder,
            voice_name, project_folder
        )
        self.generation_thread.progress_updated.connect(self.update_progress)
        self.generation_thread.finished.connect(self.generation_finished)
        self.generation_thread.start()
    
    def update_progress(self, step, message):
        """C·∫≠p nh·∫≠t progress"""
        self.progress_group.setVisible(True)
        self.progress_bar.setVisible(True)
        self.progress_label.setVisible(True)
        self.progress_bar.setValue(step)
        self.progress_label.setText(message)
    
    def generation_finished(self, result):
        """Ho√†n th√†nh t·∫°o video"""
        self.generate_video_btn.setEnabled(True)
        self.progress_bar.setVisible(False)
        
        if result["success"]:
            self.progress_label.setText(f"Ho√†n th√†nh! Video: {result['final_video_path']}")
            QMessageBox.information(self, "Th√†nh c√¥ng", 
                                  f"Video ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!\nProject: {result['project_id']}\nƒê∆∞·ªùng d·∫´n: {result['final_video_path']}")
            self.refresh_projects()
        else:
            self.progress_label.setText(f"L·ªói: {result['error']}")
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ t·∫°o video:\n{result['error']}")
    
    def refresh_projects(self):
        """L√†m m·ªõi danh s√°ch projects"""
        self.projects_list.clear()
        result = self.pipeline.project_manager.list_projects()
        if result["success"]:
            for project in result["projects"]:
                item_text = f"{project['name']} ({project['status']}) - {project['created_at'][:10]}"
                self.projects_list.addItem(item_text)
                # L∆∞u project_id v√†o item
                item = self.projects_list.item(self.projects_list.count() - 1)
                item.setData(1, project['id'])
    
    def load_project_details(self, item):
        """Load chi ti·∫øt project"""
        project_id = item.data(1)
        self.current_project_id = project_id
        
        result = self.pipeline.project_manager.load_project(project_id)
        if result["success"]:
            data = result["data"]
            details = f"""
Project: {data['name']}
ID: {data['id']}
Prompt: {data['prompt']}
Status: {data['status']}
Segments: {len(data['segments'])}
Created: {data['created_at']}
            """
            self.project_details.setText(details.strip())
    
    def open_project_folder(self):
        """M·ªü th∆∞ m·ª•c project"""
        if not self.current_project_id:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng ch·ªçn project!")
            return
        
        project_path = self.pipeline.project_manager.get_project_path(self.current_project_id)
        os.system(f"open '{project_path}'" if sys.platform == "darwin" else f"explorer '{project_path}'")
    
    def delete_project(self):
        """X√≥a project"""
        if not self.current_project_id:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng ch·ªçn project!")
            return
        
        reply = QMessageBox.question(self, "X√°c nh·∫≠n", "B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a project n√†y?")
        if reply == QMessageBox.Yes:
            result = self.pipeline.project_manager.delete_project(self.current_project_id)
            if result["success"]:
                QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ x√≥a project!")
                self.refresh_projects()
                self.project_details.clear()
                self.current_project_id = None
            else:
                QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ x√≥a: {result['error']}")
    
    def save_settings(self):
        """L∆∞u c√†i ƒë·∫∑t"""
        try:
            # ƒê·ªçc file config.env hi·ªán t·∫°i
            config_path = 'config.env'
            config_data = {}
            
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if '=' in line and not line.startswith('#'):
                            key, value = line.split('=', 1)
                            config_data[key.strip()] = value.strip()
            
            # C·∫≠p nh·∫≠t API keys t·ª´ UI
            if self.openai_key_input.text().strip():
                config_data['OPENAI_API_KEY'] = self.openai_key_input.text().strip()
            if self.claude_key_input.text().strip():
                config_data['CLAUDE_API_KEY'] = self.claude_key_input.text().strip()
            if self.deepseek_key_input.text().strip():
                config_data['DEEPSEEK_API_KEY'] = self.deepseek_key_input.text().strip()
            if self.midjourney_key_input.text().strip():
                config_data['MIDJOURNEY_API_KEY'] = self.midjourney_key_input.text().strip()
            if self.stability_key_input.text().strip():
                config_data['STABILITY_AI_KEY'] = self.stability_key_input.text().strip()
            if self.elevenlabs_key_input.text().strip():
                config_data['ELEVENLABS_API_KEY'] = self.elevenlabs_key_input.text().strip()
            if self.google_tts_key_input.text().strip():
                config_data['GOOGLE_TTS_API_KEY'] = self.google_tts_key_input.text().strip()
            if self.azure_speech_key_input.text().strip():
                config_data['AZURE_SPEECH_KEY'] = self.azure_speech_key_input.text().strip()
            
            # C·∫≠p nh·∫≠t provider preferences
            config_data['CONTENT_PROVIDER'] = self.content_provider_combo.currentText()
            config_data['IMAGE_PROVIDER'] = self.image_provider_combo.currentText()
            config_data['TTS_PROVIDER'] = self.tts_provider_combo.currentText()
            
            # C·∫≠p nh·∫≠t video settings
            config_data['VIDEO_RESOLUTION'] = self.resolution_combo.currentText()
            config_data['VIDEO_FPS'] = str(self.fps_spinbox.value())
            
            # Ghi l·∫°i file config.env
            with open(config_path, 'w', encoding='utf-8') as f:
                f.write("# ===========================================\n")
                f.write("# API KEYS - Auto-generated from settings\n")
                f.write("# ===========================================\n\n")
                
                f.write("# AI Content Generation\n")
                f.write(f"OPENAI_API_KEY={config_data.get('OPENAI_API_KEY', '')}\n")
                f.write(f"CLAUDE_API_KEY={config_data.get('CLAUDE_API_KEY', '')}\n")
                f.write(f"DEEPSEEK_API_KEY={config_data.get('DEEPSEEK_API_KEY', '')}\n\n")
                
                f.write("# Image Generation\n")
                f.write(f"MIDJOURNEY_API_KEY={config_data.get('MIDJOURNEY_API_KEY', '')}\n")
                f.write(f"STABILITY_AI_KEY={config_data.get('STABILITY_AI_KEY', '')}\n\n")
                
                f.write("# Text-to-Speech\n")
                f.write(f"ELEVENLABS_API_KEY={config_data.get('ELEVENLABS_API_KEY', '')}\n")
                f.write(f"GOOGLE_TTS_API_KEY={config_data.get('GOOGLE_TTS_API_KEY', '')}\n")
                f.write(f"AZURE_SPEECH_KEY={config_data.get('AZURE_SPEECH_KEY', '')}\n")
                f.write(f"AZURE_SPEECH_REGION={config_data.get('AZURE_SPEECH_REGION', 'eastus')}\n\n")
                
                f.write("# ===========================================\n")
                f.write("# PROVIDER PREFERENCES\n")
                f.write("# ===========================================\n")
                f.write(f"CONTENT_PROVIDER={config_data.get('CONTENT_PROVIDER', 'OpenAI GPT-4')}\n")
                f.write(f"IMAGE_PROVIDER={config_data.get('IMAGE_PROVIDER', 'DALL-E (OpenAI)')}\n")
                f.write(f"TTS_PROVIDER={config_data.get('TTS_PROVIDER', 'Google TTS (Free)')}\n\n")
                
                f.write("# ===========================================\n")
                f.write("# SETTINGS\n")
                f.write("# ===========================================\n")
                f.write(f"DEFAULT_VOICE=alloy\n")
                f.write(f"DEFAULT_LANGUAGE=vi\n")
                f.write(f"VIDEO_RESOLUTION={config_data.get('VIDEO_RESOLUTION', '1920x1080')}\n")
                f.write(f"VIDEO_FPS={config_data.get('VIDEO_FPS', '25')}\n")
            
            # Reload API manager ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi
            self.api_manager = APIManager()
            self.refresh_providers()
            
            QMessageBox.information(self, "Th√†nh c√¥ng", "C√†i ƒë·∫∑t ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng!\nAPI keys ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t v√†o config.env")
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ l∆∞u c√†i ƒë·∫∑t:\n{str(e)}")
    
    def load_current_settings(self):
        """Load c√†i ƒë·∫∑t hi·ªán t·∫°i t·ª´ file config.env"""
        try:
            config_path = 'config.env'
            if not os.path.exists(config_path):
                return
            
            with open(config_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if '=' in line and not line.startswith('#'):
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        
                        # Load API keys
                        if key == 'OPENAI_API_KEY' and value and value != 'your_openai_api_key_here':
                            self.openai_key_input.setText(value)
                        elif key == 'CLAUDE_API_KEY' and value and value != 'your_claude_api_key_here':
                            self.claude_key_input.setText(value)
                        elif key == 'DEEPSEEK_API_KEY' and value and value != 'your_deepseek_api_key_here':
                            self.deepseek_key_input.setText(value)
                        elif key == 'MIDJOURNEY_API_KEY' and value and value != 'your_midjourney_api_key_here':
                            self.midjourney_key_input.setText(value)
                        elif key == 'STABILITY_AI_KEY' and value and value != 'your_stability_ai_key_here':
                            self.stability_key_input.setText(value)
                        elif key == 'ELEVENLABS_API_KEY' and value and value != 'your_elevenlabs_api_key_here':
                            self.elevenlabs_key_input.setText(value)
                        elif key == 'GOOGLE_TTS_API_KEY' and value and value != 'your_google_tts_api_key_here':
                            self.google_tts_key_input.setText(value)
                        elif key == 'AZURE_SPEECH_KEY' and value and value != 'your_azure_speech_key_here':
                            self.azure_speech_key_input.setText(value)
                        
                        # Load provider preferences
                        elif key == 'CONTENT_PROVIDER' and value:
                            index = self.content_provider_combo.findText(value)
                            if index >= 0:
                                self.content_provider_combo.setCurrentIndex(index)
                        elif key == 'IMAGE_PROVIDER' and value:
                            index = self.image_provider_combo.findText(value)
                            if index >= 0:
                                self.image_provider_combo.setCurrentIndex(index)
                        elif key == 'TTS_PROVIDER' and value:
                            index = self.tts_provider_combo.findText(value)
                            if index >= 0:
                                self.tts_provider_combo.setCurrentIndex(index)
                        
                        # Load video settings
                        elif key == 'VIDEO_RESOLUTION' and value:
                            index = self.resolution_combo.findText(value)
                            if index >= 0:
                                self.resolution_combo.setCurrentIndex(index)
                        elif key == 'VIDEO_FPS' and value:
                            try:
                                fps = int(value)
                                self.fps_spinbox.setValue(fps)
                            except ValueError:
                                pass
        except Exception as e:
            print(f"L·ªói load c√†i ƒë·∫∑t: {str(e)}")
    
    def load_prompt_suggestions(self):
        """Load prompt suggestions theo danh m·ª•c"""
        self.prompt_suggestions_list.clear()
        self.prompt_suggestions_list.addItem("-- Ch·ªçn prompt m·∫´u --")
        
        current_data = self.category_combo.currentData()
        if current_data:
            categories = PromptTemplates.get_all_categories()
            if current_data in categories:
                prompts = categories[current_data]["prompts"]
                for prompt in prompts:
                    # Truncate long prompts for display
                    display_text = prompt[:80] + "..." if len(prompt) > 80 else prompt
                    self.prompt_suggestions_list.addItem(display_text, prompt)
    
    def use_suggested_prompt(self):
        """S·ª≠ d·ª•ng prompt ƒë∆∞·ª£c g·ª£i √Ω"""
        current_data = self.prompt_suggestions_list.currentData()
        if current_data:
            self.prompt_input.setPlainText(current_data)
    
    def get_random_prompt(self):
        """L·∫•y prompt ng·∫´u nhi√™n"""
        random_prompt = PromptTemplates.get_random_prompt()
        self.prompt_input.setPlainText(random_prompt)
    
    def toggle_image_mode(self):
        """Chuy·ªÉn ƒë·ªïi ch·∫ø ƒë·ªô t·∫°o ·∫£nh"""
        manual_mode = self.manual_images_radio.isChecked()
        self.select_images_btn.setEnabled(manual_mode)
        
        if manual_mode:
            self.auto_generate_radio.setChecked(False)
        else:
            self.auto_generate_radio.setChecked(True)
    
    def select_images_folder(self):
        """Ch·ªçn th∆∞ m·ª•c ch·ª©a ·∫£nh"""
        folder_path = QFileDialog.getExistingDirectory(
            self, "Ch·ªçn th∆∞ m·ª•c ch·ª©a ·∫£nh", ""
        )
        
        if folder_path:
            # Ki·ªÉm tra ·∫£nh trong th∆∞ m·ª•c
            image_files = self.get_image_files_in_folder(folder_path)
            
            if image_files:
                self.selected_images_folder = folder_path
                self.selected_images_label.setText(
                    f"ƒê√£ ch·ªçn: {folder_path} ({len(image_files)} ·∫£nh)"
                )
                self.selected_images_label.setStyleSheet("color: green;")
            else:
                QMessageBox.warning(
                    self, "C·∫£nh b√°o", 
                    "Th∆∞ m·ª•c kh√¥ng ch·ª©a ·∫£nh h·ª£p l·ªá!\nH·ªó tr·ª£: .jpg, .jpeg, .png, .bmp, .gif, .webp"
                )
    
    def get_image_files_in_folder(self, folder_path):
        """L·∫•y danh s√°ch file ·∫£nh trong th∆∞ m·ª•c"""
        valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp']
        image_files = []
        
        try:
            for file in os.listdir(folder_path):
                if any(file.lower().endswith(ext) for ext in valid_extensions):
                    image_files.append(os.path.join(folder_path, file))
        except Exception:
            pass
        
        return sorted(image_files)
    
    def check_api_status(self):
        """Ki·ªÉm tra tr·∫°ng th√°i t·∫•t c·∫£ API"""
        status = self.api_manager.get_provider_status()
        
        status_text = "üîç TR·∫†NG TH√ÅI API:\n\n"
        
        # Content providers
        status_text += "üìù AI Sinh n·ªôi dung:\n"
        for provider, available in status['content_providers'].items():
            icon = "‚úÖ" if available else "‚ùå"
            status_text += f"  {icon} {provider}\n"
        
        # Image providers
        status_text += "\nüé® AI T·∫°o ·∫£nh:\n"
        for provider, available in status['image_providers'].items():
            icon = "‚úÖ" if available else "‚ùå"
            status_text += f"  {icon} {provider}\n"
        
        # TTS providers
        status_text += "\nüé§ Text-to-Speech:\n"
        for provider, available in status['tts_providers'].items():
            icon = "‚úÖ" if available else "‚ùå"
            status_text += f"  {icon} {provider}\n"
        
        QMessageBox.information(self, "Tr·∫°ng th√°i API", status_text)
    
    def refresh_providers(self):
        """L√†m m·ªõi danh s√°ch providers"""
        # Reload API manager
        self.api_manager = APIManager()
        
        # Update combo boxes
        self.content_provider_combo.clear()
        self.content_provider_combo.addItems(self.api_manager.get_available_content_providers())
        
        self.image_provider_combo.clear()
        self.image_provider_combo.addItems(self.api_manager.get_available_image_providers())
        
        self.tts_provider_combo.clear()
        self.tts_provider_combo.addItems(self.api_manager.get_available_tts_providers())
        
        QMessageBox.information(self, "Th√¥ng b√°o", "ƒê√£ l√†m m·ªõi danh s√°ch providers!")
        
        # Update API status indicator
        self.update_api_status_indicator()
    
    def generate_story_only(self):
        """Ch·ªâ t·∫°o c√¢u chuy·ªán/k·ªãch b·∫£n t·ª´ prompt"""
        prompt = self.prompt_input.toPlainText().strip()
        if not prompt:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng nh·∫≠p prompt!")
            return
        
        # Disable n√∫t ƒë·ªÉ tr√°nh spam
        self.generate_story_btn.setEnabled(False)
        self.progress_group.setVisible(True)
        self.progress_label.setVisible(True)
        self.progress_label.setText("ƒêang t·∫°o c√¢u chuy·ªán...")
        
        try:
            # L·∫•y provider ƒë∆∞·ª£c ch·ªçn
            content_provider = self.content_provider_combo.currentText()
            
            # T·∫°o c√¢u chuy·ªán
            result = self.pipeline.content_gen.generate_script_from_prompt(prompt, provider=content_provider)
            
            if "error" in result:
                QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ t·∫°o c√¢u chuy·ªán:\n{result['error']}")
                self.progress_label.setText("L·ªói t·∫°o c√¢u chuy·ªán")
            else:
                # Store script data for audio generation
                self.current_script_data = result
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi format m·ªõi
                story_text = "üé¨ C√ÇU CHUY·ªÜN ƒê√É T·∫†O:\n\n"
                
                # Show characters if available
                characters = result.get("characters", [])
                if characters:
                    story_text += "üé≠ NH√ÇN V·∫¨T:\n"
                    for char in characters:
                        story_text += f"‚Ä¢ {char.get('name', char['id'])} ({char.get('gender', 'neutral')}) - {char.get('suggested_voice', 'N/A')}\n"
                    story_text += "\n"
                
                for i, segment in enumerate(result["segments"], 1):
                    story_text += f"üìù ƒêO·∫†N {i} ({segment.get('duration', 10)}s):\n"
                    story_text += f"K·ªãch b·∫£n: {segment.get('script', '')}\n"
                    
                    # Show dialogues if available
                    dialogues = segment.get('dialogues', [])
                    if dialogues:
                        story_text += "Dialogues:\n"
                        for dialogue in dialogues:
                            speaker = dialogue.get('speaker', 'unknown')
                            text = dialogue.get('text', '')
                            emotion = dialogue.get('emotion', 'neutral')
                            story_text += f"  - {speaker} ({emotion}): {text}\n"
                    else:
                        # Fallback for old format
                        story_text += f"L·ªùi tho·∫°i: {segment.get('narration', '')}\n"
                    
                    story_text += f"M√¥ t·∫£ ·∫£nh: {segment.get('image_prompt', '')}\n"
                    story_text += "-" * 50 + "\n\n"
                
                # Enable audio generation button
                self.generate_audio_btn.setEnabled(True)
                
                # T·∫°o dialog hi·ªÉn th·ªã
                dialog = QDialog(self)
                dialog.setWindowTitle(f"C√¢u chuy·ªán t·ª´ prompt - {content_provider}")
                dialog.setModal(True)
                dialog.resize(800, 600)
                
                layout = QVBoxLayout()
                dialog.setLayout(layout)
                
                # Text area hi·ªÉn th·ªã story
                story_display = QTextEdit()
                story_display.setPlainText(story_text)
                story_display.setReadOnly(True)
                layout.addWidget(story_display)
                
                # N√∫t actions
                buttons_layout = QHBoxLayout()
                
                copy_btn = QPushButton("üìã Copy")
                copy_btn.clicked.connect(lambda: self.copy_to_clipboard(story_text))
                buttons_layout.addWidget(copy_btn)
                
                save_btn = QPushButton("üíæ L∆∞u v√†o file")
                save_btn.clicked.connect(lambda: self.save_story_to_file(story_text, prompt))
                buttons_layout.addWidget(save_btn)
                
                close_btn = QPushButton("‚ùå ƒê√≥ng")
                close_btn.clicked.connect(dialog.close)
                buttons_layout.addWidget(close_btn)
                
                layout.addLayout(buttons_layout)
                
                dialog.exec_()
                self.progress_label.setText("ƒê√£ t·∫°o c√¢u chuy·ªán th√†nh c√¥ng!")
                
                # Hi·ªÉn th·ªã preview ngay trong ·ª©ng d·ª•ng
                preview_text = ""
                for i, segment in enumerate(result["segments"], 1):
                    # Handle both old and new format
                    narration = segment.get('narration', '')
                    if not narration and 'dialogues' in segment:
                        # New format with dialogues
                        narration = " ".join([d.get('text', '') for d in segment['dialogues']])
                    preview_text += f"ƒêO·∫†N {i}: {narration}\n"
                self.content_preview.setPlainText(preview_text)
                
                # Show progress group
                self.progress_group.setVisible(True)
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói kh√¥ng x√°c ƒë·ªãnh:\n{str(e)}")
            self.progress_label.setText("L·ªói t·∫°o c√¢u chuy·ªán")
        finally:
            self.generate_story_btn.setEnabled(True)
    
    def copy_to_clipboard(self, text):
        """Copy text v√†o clipboard"""
        try:
            from PySide6.QtGui import QClipboard, QGuiApplication
            clipboard = QGuiApplication.clipboard()
            clipboard.setText(text)
            QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ copy v√†o clipboard!")
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ copy: {str(e)}")
    
    def save_story_to_file(self, story_text, prompt):
        """L∆∞u c√¢u chuy·ªán v√†o file"""
        try:
            from PySide6.QtWidgets import QFileDialog
            from datetime import datetime
            
            # T·∫°o t√™n file m·∫∑c ƒë·ªãnh
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            default_filename = f"story_{timestamp}.txt"
            
            # M·ªü dialog l∆∞u file
            file_path, _ = QFileDialog.getSaveFileName(
                self, "L∆∞u c√¢u chuy·ªán", default_filename, 
                "Text Files (*.txt);;All Files (*)"
            )
            
            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(f"PROMPT G·ªêC:\n{prompt}\n\n")
                    f.write("=" * 60 + "\n\n")
                    f.write(story_text)
                    
                QMessageBox.information(self, "Th√†nh c√¥ng", f"ƒê√£ l∆∞u c√¢u chuy·ªán v√†o:\n{file_path}")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ l∆∞u file:\n{str(e)}")
    
    def select_project_folder(self):
        """Ch·ªçn th∆∞ m·ª•c ƒë·ªÉ l∆∞u d·ª± √°n"""
        folder_path = QFileDialog.getExistingDirectory(
            self, "Ch·ªçn th∆∞ m·ª•c l∆∞u d·ª± √°n", "./projects"
        )
        
        if folder_path:
            self.project_folder_input.setText(folder_path)
            self.progress_label.setText(f"ƒê√£ ch·ªçn th∆∞ m·ª•c: {folder_path}")
    
    def generate_audio_only(self):
        """T·∫°o audio t·ª´ script data c√≥ s·∫µn v·ªõi Enhanced Voice Setup"""
        if not self.current_script_data:
            QMessageBox.warning(self, "C·∫£nh b√°o", 
                "Ch∆∞a c√≥ script data! H√£y t·∫°o story tr∆∞·ªõc.")
            return
        
        # Import Enhanced Voice Setup Dialog
        from ui.manual_voice_setup_dialog import ManualVoiceSetupDialog
        from tts.voice_generator import VoiceGenerator
        
        # Initialize voice generator
        voice_gen = VoiceGenerator()
        
        # Create Enhanced dialog
        dialog = ManualVoiceSetupDialog(voice_gen, self)
        
        # Pre-populate dialog v·ªõi characters t·ª´ script data
        dialog.populate_from_script_characters(self.current_script_data)
        
        # Show dialog and get configuration
        if dialog.exec_() == QDialog.Accepted:
            characters, voice_mapping = dialog.get_characters_and_mapping()
            
            # Update current script with new character configs
            self.current_script_data["characters"] = characters
            
            # Generate audio v·ªõi Enhanced voice mapping
            self.generate_audio_with_mapping(voice_mapping)
    
    def open_audio_folder(self):
        """M·ªü th∆∞ m·ª•c ch·ª©a audio ƒë√£ t·∫°o"""
        if self.last_audio_output_dir and os.path.exists(self.last_audio_output_dir):
            # Cross-platform folder opening
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', self.last_audio_output_dir])
            elif platform.system() == "Windows":
                subprocess.Popen(['explorer', self.last_audio_output_dir])
            else:  # Linux
                subprocess.Popen(['xdg-open', self.last_audio_output_dir])
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", "Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c audio!")
    
    def play_final_audio(self):
        """Ph√°t audio ho√†n ch·ªânh"""
        if self.last_final_audio_path and os.path.exists(self.last_final_audio_path):
            # Cross-platform audio playing
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', self.last_final_audio_path])
            elif platform.system() == "Windows":
                os.system(f'start "" "{self.last_final_audio_path}"')
            else:  # Linux
                subprocess.Popen(['xdg-open', self.last_final_audio_path])
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", "Kh√¥ng t√¨m th·∫•y file audio!")
    
    def show_manual_voice_setup(self):
        """Hi·ªÉn th·ªã dialog c·∫•u h√¨nh gi·ªçng ƒë·ªçc th·ªß c√¥ng"""
        from tts.voice_generator import VoiceGenerator
        voice_gen = VoiceGenerator()
        
        dialog = ManualVoiceSetupDialog(voice_gen, self)
        if dialog.exec_() == QDialog.Accepted:
            characters, voice_mapping = dialog.get_characters_and_mapping()
            
            # Create manual script data
            manual_script_data = {
                "segments": [
                    {
                        "id": 1,
                        "script": "Audio ƒë∆∞·ª£c t·∫°o t·ª´ c·∫•u h√¨nh th·ªß c√¥ng",
                        "image_prompt": "H√¨nh ·∫£nh minh h·ªça",
                        "dialogues": [
                            {
                                "speaker": char['id'],
                                "text": f"Xin ch√†o, t√¥i l√† {char['name']}. ƒê√¢y l√† gi·ªçng n√≥i {char['suggested_voice']} c·ªßa t√¥i.",
                                "emotion": "friendly"
                            }
                            for char in characters
                        ],
                        "duration": 10
                    }
                ],
                "characters": characters
            }
            
            # Generate audio immediately
            self.current_script_data = manual_script_data
            self.generate_audio_with_mapping(voice_mapping)
    
    def generate_audio_with_mapping(self, voice_mapping):
        """T·∫°o audio v·ªõi voice mapping ƒë√£ c√≥"""
        if not self.current_script_data:
            return
        
        # Import voice generator
        from tts.voice_generator import VoiceGenerator
        voice_gen = VoiceGenerator()
        
        # Disable button during generation
        self.generate_audio_btn.setEnabled(False)
        self.generate_audio_btn.setText("‚è≥ ƒêang t·∫°o...")
        self.progress_label.setText("ƒêang t·∫°o audio...")
        
        try:
            # Get project folder
            project_folder = self.project_folder_input.text() or "./projects"
            project_name = self.project_name_input.text() or "manual_audio_project"
            
            # Create audio output directory
            audio_output_dir = os.path.join(project_folder, project_name, "audio")
            os.makedirs(audio_output_dir, exist_ok=True)
            
            # Generate audio by characters
            result = voice_gen.generate_audio_by_characters(
                self.current_script_data, 
                audio_output_dir, 
                voice_mapping
            )
            
            if result["success"]:
                # Store paths for buttons
                self.last_audio_output_dir = result["output_dir"]
                self.last_final_audio_path = result["final_audio_path"]
                
                # Enable audio control buttons
                self.open_audio_folder_btn.setEnabled(True)
                self.play_final_audio_btn.setEnabled(True)
                
                # Show success message
                message = f"‚úÖ ƒê√£ t·∫°o audio th√†nh c√¥ng!\n\n"
                message += f"üìÅ Th∆∞ m·ª•c: {result['output_dir']}\n"
                message += f"üéµ File cu·ªëi: {os.path.basename(result['final_audio_path'])}\n\n"
                message += f"üìä Chi ti·∫øt:\n"
                for character, files in result["character_audio_files"].items():
                    message += f"  ‚Ä¢ {character}: {len(files)} file(s)\n"
                
                QMessageBox.information(self, "Th√†nh c√¥ng", message)
                self.progress_label.setText("ƒê√£ t·∫°o audio th√†nh c√¥ng!")
                
            else:
                QMessageBox.critical(self, "L·ªói", f"L·ªói t·∫°o audio:\n{result.get('error', 'Unknown error')}")
                self.progress_label.setText("L·ªói t·∫°o audio")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói kh√¥ng x√°c ƒë·ªãnh:\n{str(e)}")
            self.progress_label.setText("L·ªói t·∫°o audio")
        finally:
            self.generate_audio_btn.setEnabled(True)
            self.generate_audio_btn.setText("üéµ T·∫°o Audio")
    
    def show_chatterbox_device_info(self):
        """Hi·ªÉn th·ªã th√¥ng tin device c·ªßa Chatterbox TTS"""
        try:
            device_info = self.voice_generator.get_chatterbox_device_info()
            providers = self.voice_generator.get_available_tts_providers()
            
            # Find Chatterbox provider info
            chatterbox_info = None
            for provider in providers:
                if provider['id'] == 'chatterbox':
                    chatterbox_info = provider
                    break
            
            # Create info message
            message = "ü§ñ **Chatterbox TTS Device Information**\n\n"
            
            if device_info.get('available'):
                message += f"‚úÖ **Status**: {device_info.get('initialized', False) and 'Initialized' or 'Available but not initialized'}\n"
                message += f"üì± **Device**: {device_info.get('device_name', 'Unknown')}\n"
                message += f"üîß **Device Type**: {device_info.get('device', 'Unknown')}\n\n"
                
                # GPU specific info
                if 'cuda_version' in device_info:
                    message += f"üéØ **CUDA Version**: {device_info['cuda_version']}\n"
                    message += f"üíæ **GPU Memory**: {device_info.get('gpu_memory_total', 'Unknown')} GB total\n"
                    message += f"üü¢ **Available Memory**: {device_info.get('gpu_memory_available', 'Unknown')} GB\n\n"
                
                # Provider features
                if chatterbox_info:
                    message += f"üåç **Languages**: {', '.join(chatterbox_info['languages'])}\n"
                    message += f"‚ú® **Features**:\n"
                    for feature in chatterbox_info['features']:
                        message += f"   ‚Ä¢ {feature}\n"
                
                # Memory usage if available
                memory_info = self.voice_generator.chatterbox_provider.get_memory_usage() if self.voice_generator.chatterbox_provider else {}
                if memory_info:
                    message += f"\nüìä **Current Memory Usage**:\n"
                    if 'gpu_allocated' in memory_info:
                        message += f"   ‚Ä¢ GPU Allocated: {memory_info['gpu_allocated']} MB\n"
                        message += f"   ‚Ä¢ GPU Cached: {memory_info['gpu_cached']} MB\n"
                    if 'cpu_memory_mb' in memory_info:
                        message += f"   ‚Ä¢ CPU Memory: {memory_info['cpu_memory_mb']} MB ({memory_info.get('cpu_memory_percent', 0):.1f}%)\n"
            else:
                message += f"‚ùå **Status**: Not available\n"
                message += f"üö´ **Reason**: {device_info.get('error', 'Unknown error')}\n\n"
                message += f"üí° **Possible solutions**:\n"
                message += f"   ‚Ä¢ Install PyTorch with CUDA support for GPU acceleration\n"
                message += f"   ‚Ä¢ Update graphics drivers\n"
                message += f"   ‚Ä¢ Ensure sufficient memory available\n"
            
            # Show dialog
            msg_box = QMessageBox(self)
            msg_box.setWindowTitle("Chatterbox TTS Device Info")
            msg_box.setText(message)
            msg_box.setIcon(QMessageBox.Information)
            msg_box.exec_()
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ l·∫•y th√¥ng tin device:\n{str(e)}")
    
    def clear_chatterbox_cache(self):
        """X√≥a cache c·ªßa Chatterbox TTS"""
        try:
            if self.voice_generator.chatterbox_provider:
                # Get memory info before clearing
                memory_before = self.voice_generator.chatterbox_provider.get_memory_usage()
                
                # Clear cache
                self.voice_generator.cleanup_chatterbox()
                
                # Get memory info after clearing
                memory_after = self.voice_generator.chatterbox_provider.get_memory_usage() if self.voice_generator.chatterbox_provider else {}
                
                # Show result
                message = "üßπ **Chatterbox TTS Cache Cleared**\n\n"
                
                if memory_before and memory_after:
                    message += f"**Memory Usage Before/After**:\n"
                    if 'gpu_allocated' in memory_before:
                        gpu_freed = memory_before.get('gpu_allocated', 0) - memory_after.get('gpu_allocated', 0)
                        message += f"   ‚Ä¢ GPU: {memory_before['gpu_allocated']} ‚Üí {memory_after['gpu_allocated']} MB (freed: {gpu_freed} MB)\n"
                    if 'cpu_memory_mb' in memory_before:
                        cpu_freed = memory_before.get('cpu_memory_mb', 0) - memory_after.get('cpu_memory_mb', 0)
                        message += f"   ‚Ä¢ CPU: {memory_before['cpu_memory_mb']} ‚Üí {memory_after['cpu_memory_mb']} MB (freed: {cpu_freed} MB)\n"
                else:
                    message += "‚úÖ Voice cloning cache cleared\n"
                    message += "‚úÖ GPU cache cleared (if applicable)\n"
                    message += "‚úÖ Memory resources freed\n"
                
                QMessageBox.information(self, "Th√†nh c√¥ng", message)
            else:
                QMessageBox.warning(self, "C·∫£nh b√°o", "Chatterbox TTS ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o!")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ x√≥a cache:\n{str(e)}")
    
    # ===== VOICE STUDIO TAB METHODS =====
    
    def switch_data_source(self):
        """Chuy·ªÉn ƒë·ªïi ngu·ªìn d·ªØ li·ªáu trong Voice Studio"""
        source = self.data_source_combo.currentData()
        
        # Hide all widgets first
        self.file_import_widget.setVisible(False)
        self.generated_data_widget.setVisible(False)
        self.manual_input_widget.setVisible(False)
        
        # Show appropriate widget
        if source == "file":
            self.file_import_widget.setVisible(True)
        elif source == "generated":
            self.generated_data_widget.setVisible(True)
        elif source == "manual":
            self.manual_input_widget.setVisible(True)
    
    def import_script_file(self):
        """Import script t·ª´ file JSON"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Ch·ªçn file JSON script",
            "",
            "JSON files (*.json);;All files (*.*)"
        )
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    script_data = json.load(f)
                
                # Validate script data
                if self.validate_script_data(script_data):
                    self.voice_studio_script_data = script_data
                    self.imported_file_label.setText(os.path.basename(file_path))
                    self.imported_file_label.setStyleSheet("color: #007AFF; font-weight: bold;")
                    self.update_voice_studio_overview()
                    QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ import script th√†nh c√¥ng!")
                else:
                    QMessageBox.warning(self, "L·ªói", "File JSON kh√¥ng ƒë√∫ng format!")
                    
            except Exception as e:
                QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ ƒë·ªçc file:\n{str(e)}")
    
    def load_generated_script_data(self):
        """Load script data t·ª´ tab T·∫°o Video"""
        if self.current_script_data:
            self.voice_studio_script_data = self.current_script_data
            self.update_voice_studio_overview()
            QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ load script data t·ª´ tab T·∫°o Video!")
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", "Ch∆∞a c√≥ script data n√†o ƒë∆∞·ª£c t·∫°o trong tab T·∫°o Video!")
    
    def parse_manual_script(self):
        """Parse JSON script ƒë∆∞·ª£c nh·∫≠p th·ªß c√¥ng"""
        try:
            script_text = self.manual_script_input.toPlainText().strip()
            if not script_text:
                QMessageBox.warning(self, "C·∫£nh b√°o", "Vui l√≤ng nh·∫≠p JSON script!")
                return
            
            script_data = json.loads(script_text)
            
            if self.validate_script_data(script_data):
                self.voice_studio_script_data = script_data
                self.update_voice_studio_overview()
                QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ parse JSON script th√†nh c√¥ng!")
            else:
                QMessageBox.warning(self, "L·ªói", "JSON script kh√¥ng ƒë√∫ng format!")
                
        except json.JSONDecodeError as e:
            QMessageBox.critical(self, "L·ªói JSON", f"JSON kh√¥ng h·ª£p l·ªá:\n{str(e)}")
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ parse script:\n{str(e)}")
    
    def validate_script_data(self, script_data):
        """Validate format c·ªßa script data"""
        try:
            # Check required fields
            if not isinstance(script_data, dict):
                return False
            
            if 'segments' not in script_data or 'characters' not in script_data:
                return False
            
            # Check segments
            segments = script_data['segments']
            if not isinstance(segments, list) or len(segments) == 0:
                return False
            
            # Check characters
            characters = script_data['characters']
            if not isinstance(characters, list) or len(characters) == 0:
                return False
            
            # Basic structure validation
            for segment in segments:
                if not all(key in segment for key in ['id', 'dialogues']):
                    return False
                
                for dialogue in segment['dialogues']:
                    if not all(key in dialogue for key in ['speaker', 'text']):
                        return False
            
            for character in characters:
                if not all(key in character for key in ['id', 'name']):
                    return False
            
            return True
            
        except Exception:
            return False
    
    def update_voice_studio_overview(self):
        """C·∫≠p nh·∫≠t overview c·ªßa script trong Voice Studio"""
        if not self.voice_studio_script_data:
            return
        
        try:
            segments = self.voice_studio_script_data['segments']
            characters = self.voice_studio_script_data['characters']
            
            # Update info labels
            total_dialogues = sum(len(segment['dialogues']) for segment in segments)
            self.script_info_label.setText(
                f"‚úÖ Script loaded: {len(segments)} segments, {total_dialogues} dialogues"
            )
            self.script_info_label.setStyleSheet("color: #007AFF; font-weight: bold;")
            
            # Update characters
            character_names = [char['name'] for char in characters]
            self.characters_label.setText(", ".join(character_names))
            
            # Update segments count
            self.segments_count_label.setText(str(len(segments)))
            
            # Update voice mapping table
            self.populate_voice_mapping_table()
            
            # Enable generation buttons
            self.generate_selected_btn.setEnabled(True)
            self.generate_all_btn.setEnabled(True)
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t overview:\n{str(e)}")
    
    def populate_voice_mapping_table(self):
        """Populate character settings table - FIXED METHOD"""
        if not self.voice_studio_script_data:
            return
        
        # Call the correct method for character settings table
        self.populate_character_settings_table()
        
        # Enable generation buttons
        self.generate_selected_btn.setEnabled(True)
        self.generate_all_btn.setEnabled(True)
        
        print("‚úÖ Character settings table populated successfully")
        return

    
    def reset_voice_mapping(self):
        """Reset voice mapping v·ªÅ m·∫∑c ƒë·ªãnh"""
        if not self.voice_studio_script_data:
            return
        
        # Reset table
        self.populate_character_settings_table()
        from PySide6.QtWidgets import QMessageBox
        QMessageBox.information(self, "Th√¥ng b√°o", "ƒê√£ reset voice mapping v·ªÅ m·∫∑c ƒë·ªãnh!")
    
    def preview_selected_voice(self):
        """Preview gi·ªçng n√≥i c·ªßa nh√¢n v·∫≠t ƒë∆∞·ª£c ch·ªçn - CH·ªà CHATTERBOX TTS"""
        current_row = self.character_settings_table.currentRow()
        if current_row < 0:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(self, "C·∫£nh b√°o", "Vui l√≤ng ch·ªçn m·ªôt nh√¢n v·∫≠t!")
            return
        
        try:
            # Get character info
            character_id = self.character_settings_table.item(current_row, 0).text()
            voice_combo = self.character_settings_table.cellWidget(current_row, 4)  # Voice column
            selected_voice = voice_combo.currentData()  # Get Chatterbox voice ID
            
            # Get settings from character_settings_table
            emotion_input = self.character_settings_table.cellWidget(current_row, 1)
            speed_input = self.character_settings_table.cellWidget(current_row, 2)
            cfg_weight_input = self.character_settings_table.cellWidget(current_row, 3)
            
            emotion = float(emotion_input.text()) if emotion_input else 1.0
            speed = float(speed_input.text()) if speed_input else 1.0
            cfg_weight = float(cfg_weight_input.text()) if cfg_weight_input else 0.5
            
            # Preview text
            preview_text = f"Xin ch√†o, t√¥i l√† {character_id}. ƒê√¢y l√† gi·ªçng n√≥i {voice_combo.currentText().split(' ')[1]} c·ªßa t√¥i v·ªõi emotion {emotion:.1f}, speed {speed:.1f}x."
            
            # Generate preview audio
            import tempfile
            temp_dir = tempfile.mkdtemp()
            preview_path = os.path.join(temp_dir, f"preview_{character_id}.mp3")
            
            # Check if prompt-based voice is enabled for preview
            voice_prompt = None
            if self.enable_prompt_voice.isChecked() and self.voice_prompt_input.text().strip():
                voice_prompt = self.voice_prompt_input.text().strip()
                print(f"üéß Preview with PROMPT: '{voice_prompt}'")
                preview_text = f"Xin ch√†o, t√¥i l√† {character_id}. ƒê√¢y l√† gi·ªçng ƒë∆∞·ª£c t·∫°o t·ª´ prompt: {voice_prompt[:50]}..."
            else:
                print(f"üéß Preview Settings for {character_id}:")
                print(f"   Voice: {selected_voice}")
                print(f"   Emotion: {emotion:.1f}")
                print(f"   Speed: {speed:.1f}x")
                print(f"   CFG Weight: {cfg_weight:.2f}")
                
            result = self.voice_generator.generate_voice_chatterbox(
                text=preview_text,
                save_path=preview_path,
                voice_sample_path=None,
                emotion_exaggeration=emotion,
                speed=speed,
                voice_name=selected_voice if not voice_prompt else None,  # Skip voice_name if using prompt
                cfg_weight=cfg_weight,
                voice_prompt=voice_prompt  # NEW: Pass voice prompt for preview
            )
            
            if result.get('success'):
                # Play preview
                self.play_audio_file(preview_path)
                from PySide6.QtWidgets import QMessageBox
                QMessageBox.information(self, "üéß Preview Voice", 
                    f"Character: {character_id}\n"
                    f"Voice: {voice_combo.currentText()}\n"
                    f"Emotion: {emotion:.1f}\n"
                    f"Speed: {speed:.1f}x\n"
                    f"CFG Weight: {cfg_weight:.2f}\n"
                    f"\nü§ñ Generated by Chatterbox TTS")
            else:
                from PySide6.QtWidgets import QMessageBox
                QMessageBox.warning(self, "‚ùå L·ªói Preview", f"Kh√¥ng th·ªÉ t·∫°o preview Chatterbox TTS:\n{result.get('error', 'Unknown error')}")
                
        except Exception as e:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.critical(self, "‚ùå L·ªói Critical", f"L·ªói preview voice:\n{str(e)}")
    
    def play_audio_file(self, file_path):
        """Play audio file"""
        try:
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', file_path])
            elif platform.system() == "Windows":
                os.startfile(file_path)
            else:  # Linux
                subprocess.Popen(['xdg-open', file_path])
        except Exception as e:
            print(f"Kh√¥ng th·ªÉ play audio: {e}")
    
    def select_voice_output_folder(self):
        """Ch·ªçn th∆∞ m·ª•c output cho voice"""
        folder = QFileDialog.getExistingDirectory(self, "Ch·ªçn th∆∞ m·ª•c output")
        if folder:
            self.voice_output_input.setText(folder)
    
    def generate_selected_character_voice(self):
        """T·∫°o voice cho nh√¢n v·∫≠t ƒë∆∞·ª£c ch·ªçn"""
        current_row = self.character_settings_table.currentRow()
        if current_row < 0:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(self, "C·∫£nh b√°o", "Vui l√≤ng ch·ªçn m·ªôt nh√¢n v·∫≠t!")
            return
        
        # Get character ID
        character_id = self.character_settings_table.item(current_row, 0).text()
        
        # Generate for single character
        self.generate_voices_for_characters([character_id])
    
    def generate_all_voices(self):
        """T·∫°o voice cho t·∫•t c·∫£ nh√¢n v·∫≠t"""
        if not self.voice_studio_script_data:
            return
        
        # Get all character IDs
        character_ids = [char['id'] for char in self.voice_studio_script_data['characters']]
        
        # Generate for all characters
        self.generate_voices_for_characters(character_ids)
    
    def generate_voices_for_characters(self, character_ids):
        """T·∫°o voice cho danh s√°ch character IDs"""
        try:
            # Show progress
            self.voice_progress_bar.setVisible(True)
            self.voice_progress_bar.setRange(0, 0)  # Indeterminate progress
            self.voice_progress_text.setText("ƒêang t·∫°o voice...")
            
            # Get output directory
            output_dir = self.voice_output_input.text() or "./voice_studio_output"
            os.makedirs(output_dir, exist_ok=True)
            
            # CH·ªà S·ª¨ D·ª§NG CHATTERBOX TTS
            # provider = "chatterbox"  # Fixed provider
            
            # Collect voice mapping from character_settings_table
            current_voice_mapping = {}
            for i in range(self.character_settings_table.rowCount()):
                char_id = self.character_settings_table.item(i, 0).text()
                voice_combo = self.character_settings_table.cellWidget(i, 4)  # Voice column
                emotion_input = self.character_settings_table.cellWidget(i, 1)
                speed_input = self.character_settings_table.cellWidget(i, 2)
                cfg_weight_input = self.character_settings_table.cellWidget(i, 3)
                
                current_voice_mapping[char_id] = {
                    'name': char_id,
                    'suggested_voice': voice_combo.currentData() if voice_combo else 'female_young',
                    'emotion': float(emotion_input.text()) if emotion_input and emotion_input.text() else 1.0,
                    'speed': float(speed_input.text()) if speed_input and speed_input.text() else 1.0,
                    'cfg_weight': float(cfg_weight_input.text()) if cfg_weight_input and cfg_weight_input.text() else 0.5
                }
            
            # Generate audio
            total_generated = 0
            total_failed = 0
            results_text = ""
            
            for segment in self.voice_studio_script_data['segments']:
                for dialogue in segment['dialogues']:
                    speaker = dialogue['speaker']
                    
                    # Skip if not in selected characters
                    if speaker not in character_ids:
                        continue
                    
                    text = dialogue['text']
                    emotion = dialogue.get('emotion', 'neutral')
                    
                    # Get voice settings from character_settings_table
                    voice_settings = current_voice_mapping.get(speaker, {})
                    voice_name = voice_settings.get('suggested_voice', 'female_young')
                    emotion_exaggeration = voice_settings.get('emotion', 1.0)
                    speed = voice_settings.get('speed', 1.0)
                    cfg_weight = voice_settings.get('cfg_weight', 0.5)
                    
                    # Get per-character settings t·ª´ character_chatterbox_settings
                    char_settings = self.character_chatterbox_settings.get(speaker, {})
                    voice_prompt = char_settings.get('voice_prompt', '').strip()
                    voice_clone_path = char_settings.get('voice_clone_path', None)
                    
                    # Generate filename
                    segment_id = segment['id']
                    dialogue_idx = segment['dialogues'].index(dialogue) + 1
                    filename = f"segment_{segment_id}_dialogue_{dialogue_idx}_{speaker}.mp3"
                    file_path = os.path.join(output_dir, filename)
                    
                    # Generate voice - CH·ªà S·ª¨ D·ª§NG CHATTERBOX TTS v·ªõi per-character settings
                    try:
                        # Apply emotion mapping if enabled
                        if self.enable_emotion_mapping.isChecked():
                            mapped_emotion, mapped_cfg = self.map_emotion_to_parameters(emotion, emotion_exaggeration)
                            emotion_exaggeration = mapped_emotion
                            cfg_weight = mapped_cfg
                        
                        # Validate voice settings v√† log generation info
                        voice_mode = self.validate_character_voice_settings(speaker)
                        
                        # CH·ªà S·ª¨ D·ª§NG CHATTERBOX TTS v·ªõi optimized parameter passing
                        result = self.voice_generator.generate_voice_chatterbox(
                            text=text,
                            save_path=file_path,
                            voice_sample_path=voice_clone_path if voice_mode == 'clone' else None,
                            emotion_exaggeration=emotion_exaggeration,
                            speed=speed,
                            voice_name=voice_name if voice_mode == 'selection' else None,
                            cfg_weight=cfg_weight,
                            voice_prompt=voice_prompt if voice_mode == 'prompt' else None
                        )
                        
                        if result.get('success'):
                            total_generated += 1
                            results_text += f"‚úÖ {filename}\n"
                        else:
                            total_failed += 1
                            results_text += f"‚ùå {filename}: {result.get('error', 'Unknown error')}\n"
                            
                    except Exception as e:
                        total_failed += 1
                        results_text += f"‚ùå {filename}: {str(e)}\n"
            
            # Update results
            self.voice_results_text.setText(results_text)
            
            # Show summary
            summary = f"üéØ Ho√†n th√†nh!\n\n"
            summary += f"‚úÖ Th√†nh c√¥ng: {total_generated} files\n"
            summary += f"‚ùå Th·∫•t b·∫°i: {total_failed} files\n"
            summary += f"üìÅ Output: {output_dir}"
            
            QMessageBox.information(self, "K·∫øt qu·∫£", summary)
            
            # Update progress
            self.voice_progress_text.setText(f"Ho√†n th√†nh: {total_generated} th√†nh c√¥ng, {total_failed} th·∫•t b·∫°i")
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói t·∫°o voice:\n{str(e)}")
            self.voice_progress_text.setText("L·ªói t·∫°o voice")
        finally:
            self.voice_progress_bar.setVisible(False)
    
    def open_voice_output_folder(self):
        """M·ªü th∆∞ m·ª•c output voice"""
        output_dir = self.voice_output_input.text() or "./voice_studio_output"
        
        if os.path.exists(output_dir):
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', output_dir])
            elif platform.system() == "Windows":
                os.startfile(output_dir)
            else:  # Linux
                subprocess.Popen(['xdg-open', output_dir])
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {output_dir}")
    
    def clear_voice_results(self):
        """X√≥a k·∫øt qu·∫£ voice generation"""
        self.voice_results_text.clear()
        self.voice_progress_text.setText("S·∫µn s√†ng t·∫°o voice")
        QMessageBox.information(self, "Th√¥ng b√°o", "ƒê√£ x√≥a k·∫øt qu·∫£!")
    
    # ========== CHATTERBOX MANUAL CONTROLS ==========
    
    def toggle_chatterbox_manual_controls(self, enabled):
        """Toggle hi·ªÉn th·ªã manual controls cho Chatterbox"""
        self.chatterbox_manual_widget.setVisible(enabled)
        if enabled:
            self.populate_character_settings_table()
    
    def update_emotion_label(self, value):
        """C·∫≠p nh·∫≠t label emotion t·ª´ slider"""
        emotion_value = value / 100.0  # Convert 0-300 to 0.0-3.0
        self.emotion_label.setText(f"{emotion_value:.1f}")
    
    def update_speed_label(self, value):
        """C·∫≠p nh·∫≠t label speed t·ª´ slider"""
        speed_value = value / 100.0  # Convert 50-200 to 0.5-2.0
        self.speed_label.setText(f"{speed_value:.1f}x")
    
    def populate_character_settings_table(self):
        """Populate b·∫£ng settings cho t·ª´ng nh√¢n v·∫≠t v·ªõi CFG Weight v√† Voice selection"""
        if not self.voice_studio_script_data:
            return
        
        characters = self.voice_studio_script_data['characters']
        # Th√™m 2 c·ªôt m·ªõi cho Voice Prompt v√† Voice Clone
        self.character_settings_table.setRowCount(len(characters))
        
        for i, character in enumerate(characters):
            char_id = character['id']
            
            # Character name
            name_item = QTableWidgetItem(character['name'])
            name_item.setFlags(name_item.flags() & ~Qt.ItemIsEditable)
            self.character_settings_table.setItem(i, 0, name_item)
            
            # Emotion input field (thay v√¨ slider) - Fix m√†u ƒëen
            emotion_input = QLineEdit()
            emotion_input.setText("1.0")
            emotion_input.setAlignment(Qt.AlignCenter)
            emotion_input.setMaximumWidth(60)
            emotion_input.setStyleSheet("""
                QLineEdit {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QLineEdit:focus {
                    border: 2px solid #007AFF;
                }
            """)
            emotion_input.textChanged.connect(
                lambda text, cid=char_id: self.update_character_emotion_from_input(cid, text)
            )
            self.character_settings_table.setCellWidget(i, 1, emotion_input)
            
            # Speed input field (thay v√¨ slider) - Fix m√†u ƒëen
            speed_input = QLineEdit()
            speed_input.setText("1.0")
            speed_input.setAlignment(Qt.AlignCenter)
            speed_input.setMaximumWidth(60)
            speed_input.setStyleSheet("""
                QLineEdit {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QLineEdit:focus {
                    border: 2px solid #007AFF;
                }
            """)
            speed_input.textChanged.connect(
                lambda text, cid=char_id: self.update_character_speed_from_input(cid, text)
            )
            self.character_settings_table.setCellWidget(i, 2, speed_input)
            
            # CFG Weight input field (NEW) - Fix m√†u ƒëen
            cfg_weight_input = QLineEdit()
            cfg_weight_input.setText("0.5")
            cfg_weight_input.setAlignment(Qt.AlignCenter)
            cfg_weight_input.setMaximumWidth(60)
            cfg_weight_input.setStyleSheet("""
                QLineEdit {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QLineEdit:focus {
                    border: 2px solid #007AFF;
                }
            """)
            cfg_weight_input.textChanged.connect(
                lambda text, cid=char_id: self.update_character_cfg_weight_from_input(cid, text)
            )
            self.character_settings_table.setCellWidget(i, 3, cfg_weight_input)
            
            # Voice selection combo (NEW) - Fix dropdown ƒëen
            voice_combo = QComboBox()
            voice_combo.setStyleSheet("""
                QComboBox {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QComboBox::drop-down {
                    background-color: white;
                }
                QComboBox::down-arrow {
                    color: black;
                }
                QComboBox QAbstractItemView {
                    background-color: white;
                    color: black;
                    selection-background-color: #007AFF;
                    selection-color: white;
                }
            """)
            
            # Always use fallback voices ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ data
            fallback_voices = [
                ("üë© Young Female (female)", "female_young"),
                ("üë® Young Male (male)", "male_young"),
                ("üó£Ô∏è Narrator (neutral)", "neutral_narrator"),
                ("üë© Mature Female (female)", "female_mature"),
                ("üë® Mature Male (male)", "male_mature"),
                ("üë© Gentle Female (female)", "female_gentle"),
                ("üë® Deep Male (male)", "male_deep"),
                ("üë∂ Child Voice (neutral)", "child_voice"),
                ("üë¥ Elder Voice (neutral)", "elder_voice"),
                ("üé§ Voice Cloning (variable)", "cloned")
            ]
            
            for display, voice_id in fallback_voices:
                voice_combo.addItem(display, voice_id)
            
            # Set default selection
            voice_combo.setCurrentIndex(0)  # Default to Young Female
            
            voice_combo.currentIndexChanged.connect(
                lambda index, cid=char_id, combo=voice_combo: self.update_character_voice(cid, combo.currentData())
            )
            
            # Voice Mode selector (NEW) - Ch·ªçn gi·ªØa Voice Selection vs Voice Clone
            # NOTE: Voice Prompt b·ªã lo·∫°i b·ªè v√¨ ChatterboxTTS kh√¥ng h·ªó tr·ª£ text prompt
            mode_combo = QComboBox()
            mode_combo.setMaximumWidth(120)
            mode_combo.addItem("üó£Ô∏è Voice", "voice_selection")
            mode_combo.addItem("üé§ Clone", "voice_clone")
            mode_combo.setCurrentIndex(0)  # Default to voice selection
            mode_combo.setStyleSheet("""
                QComboBox {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QComboBox::drop-down {
                    border: none;
                }
                QComboBox::down-arrow {
                    color: black;
                }
                QComboBox QAbstractItemView {
                    background-color: white;
                    color: black;
                    selection-background-color: #007AFF;
                    selection-color: white;
                }
            """)
            mode_combo.currentIndexChanged.connect(
                lambda index, cid=char_id, combo=mode_combo: self.update_character_voice_mode(cid, combo.currentData())
            )
            self.character_settings_table.setCellWidget(i, 4, mode_combo)

            # Stacked widget ƒë·ªÉ chuy·ªÉn ƒë·ªïi gi·ªØa Voice/Prompt/Clone
            stacked_widget = QStackedWidget()
            stacked_widget.setMaximumHeight(30)
            
            # 1. Voice Selection Widget
            voice_widget = QWidget()
            voice_layout = QHBoxLayout(voice_widget)
            voice_layout.setContentsMargins(2, 2, 2, 2)
            voice_layout.addWidget(voice_combo)
            
            # 2. Voice Clone Widget (moved up, prompt removed)
            
            clone_widget = QWidget()
            clone_layout = QHBoxLayout(clone_widget)
            clone_layout.setContentsMargins(2, 2, 2, 2)
            clone_layout.setSpacing(4)
            
            voice_clone_btn = QPushButton("üìÅ Select")
            voice_clone_btn.setMaximumWidth(80)
            voice_clone_btn.setToolTip(f"Ch·ªçn voice samples cho {character['name']}")
            voice_clone_btn.clicked.connect(lambda checked, cid=char_id: self.select_character_voice_clone_folder(cid))
            clone_layout.addWidget(voice_clone_btn)
            
            # Add widgets to stack (only 2 now)
            stacked_widget.addWidget(voice_widget)     # Index 0 - Voice Selection
            stacked_widget.addWidget(clone_widget)     # Index 1 - Voice Clone
            stacked_widget.setCurrentIndex(0)  # Default to voice selection
            
            self.character_settings_table.setCellWidget(i, 5, stacked_widget)
            
            # Quick action button (test for clone, etc.)
            quick_btn = QPushButton("üîß")
            quick_btn.setMaximumWidth(30)
            quick_btn.setToolTip("Quick actions")
            quick_btn.clicked.connect(lambda checked, cid=char_id: self.show_voice_quick_actions(cid))
            self.character_settings_table.setCellWidget(i, 6, quick_btn)
            
            # Status indicator
            status_label = QLabel("üó£Ô∏è")
            status_label.setMaximumWidth(30)
            status_label.setAlignment(Qt.AlignCenter)
            status_label.setToolTip("Voice Selection mode")
            self.character_settings_table.setCellWidget(i, 7, status_label)
            
            # Preview button
            preview_btn = QPushButton("üéß")
            preview_btn.setMaximumWidth(40)
            preview_btn.setToolTip(f"Preview {character['name']}")
            preview_btn.clicked.connect(lambda checked, cid=char_id: self.preview_character_with_settings(cid))
            self.character_settings_table.setCellWidget(i, 8, preview_btn)
            
            # Initialize character settings v·ªõi voice mode
            self.character_chatterbox_settings[char_id] = {
                'emotion': 1.0,
                'speed': 1.0,
                'cfg_weight': 0.5,
                'voice_mode': 'voice_selection',  # NEW: voice_selection | voice_clone
                'voice_id': 'female_young',  # For voice_selection mode
                'voice_clone_path': None,  # For voice_clone mode
                'voice_clone_status': 'none'  # Track clone status
            }
            
            # Store widget references for mode switching
            if not hasattr(self, 'character_widgets'):
                self.character_widgets = {}
            self.character_widgets[char_id] = {
                'mode_combo': mode_combo,
                'stacked_widget': stacked_widget,
                'voice_combo': voice_combo,
                'voice_clone_btn': voice_clone_btn,
                'status_label': status_label,
                'quick_btn': quick_btn
            }
    
    def update_character_emotion_from_input(self, char_id, text):
        """C·∫≠p nh·∫≠t emotion cho nh√¢n v·∫≠t c·ª• th·ªÉ t·ª´ input"""
        try:
            value = float(text)
            value = max(0.0, min(3.0, value))  # Clamp to 0.0-3.0
            if char_id not in self.character_chatterbox_settings:
                self.character_chatterbox_settings[char_id] = {}
            self.character_chatterbox_settings[char_id]['emotion'] = value
        except ValueError:
            pass  # Ignore invalid input
    
    def update_character_speed_from_input(self, char_id, text):
        """C·∫≠p nh·∫≠t speed cho nh√¢n v·∫≠t c·ª• th·ªÉ t·ª´ input"""
        try:
            value = float(text)
            value = max(0.5, min(2.0, value))  # Clamp to 0.5-2.0
            if char_id not in self.character_chatterbox_settings:
                self.character_chatterbox_settings[char_id] = {}
            self.character_chatterbox_settings[char_id]['speed'] = value
        except ValueError:
            pass  # Ignore invalid input
    
    def update_character_cfg_weight_from_input(self, char_id, text):
        """C·∫≠p nh·∫≠t CFG weight cho nh√¢n v·∫≠t c·ª• th·ªÉ t·ª´ input"""
        try:
            value = float(text)
            value = max(0.0, min(1.0, value))  # Clamp to 0.0-1.0
            if char_id not in self.character_chatterbox_settings:
                self.character_chatterbox_settings[char_id] = {}
            self.character_chatterbox_settings[char_id]['cfg_weight'] = value
        except ValueError:
            pass  # Ignore invalid input
    
    def update_character_voice(self, char_id, voice_id):
        """C·∫≠p nh·∫≠t voice cho nh√¢n v·∫≠t c·ª• th·ªÉ v√† t·ª± ƒë·ªông adjust parameters theo gender"""
        if char_id not in self.character_chatterbox_settings:
            self.character_chatterbox_settings[char_id] = {}
        
        # L∆∞u voice_id
        self.character_chatterbox_settings[char_id]['voice_id'] = voice_id
        
        # üéØ AUTO-ADJUST PARAMETERS d·ª±a tr√™n voice gender (nh∆∞ AI Gender Analysis)
        voice_gender_params = self._get_voice_gender_parameters(voice_id)
        
        # C·∫≠p nh·∫≠t parameters trong settings
        self.character_chatterbox_settings[char_id]['emotion'] = voice_gender_params['emotion']
        self.character_chatterbox_settings[char_id]['speed'] = voice_gender_params['speed'] 
        self.character_chatterbox_settings[char_id]['cfg_weight'] = voice_gender_params['cfg_weight']
        
        # üîÑ C·∫¨P NH·∫¨T UI: T√¨m v√† update input fields trong table
        for row in range(self.character_settings_table.rowCount()):
            name_item = self.character_settings_table.item(row, 0)
            if name_item and name_item.text() == char_id:
                # Update emotion input
                emotion_input = self.character_settings_table.cellWidget(row, 1)
                if emotion_input:
                    emotion_input.setText(f"{voice_gender_params['emotion']:.1f}")
                
                # Update speed input  
                speed_input = self.character_settings_table.cellWidget(row, 2)
                if speed_input:
                    speed_input.setText(f"{voice_gender_params['speed']:.1f}")
                
                # Update cfg weight input
                cfg_weight_input = self.character_settings_table.cellWidget(row, 3)
                if cfg_weight_input:
                    cfg_weight_input.setText(f"{voice_gender_params['cfg_weight']:.2f}")
                
                break
        
        print(f"üé≠ Voice changed for {char_id}: {voice_id}")
        print(f"   ‚ú® Auto-adjusted: emotion={voice_gender_params['emotion']:.1f}, speed={voice_gender_params['speed']:.1f}, cfg_weight={voice_gender_params['cfg_weight']:.2f}")
    
    def update_character_voice_mode(self, char_id, voice_mode):
        """C·∫≠p nh·∫≠t voice mode cho nh√¢n v·∫≠t v√† switch UI accordingly"""
        if char_id not in self.character_chatterbox_settings:
            self.character_chatterbox_settings[char_id] = {}
        
        # Update voice mode
        self.character_chatterbox_settings[char_id]['voice_mode'] = voice_mode
        
        # Get widget references
        if hasattr(self, 'character_widgets') and char_id in self.character_widgets:
            widgets = self.character_widgets[char_id]
            stacked_widget = widgets['stacked_widget']
            status_label = widgets['status_label']
            quick_btn = widgets['quick_btn']
            
            # Switch stacked widget and update status
            if voice_mode == 'voice_selection':
                stacked_widget.setCurrentIndex(0)  # Voice combo
                status_label.setText("üó£Ô∏è")
                status_label.setToolTip("Voice Selection mode - ch·ªçn gi·ªçng c√≥ s·∫µn")
                quick_btn.setToolTip("Voice options")
                print(f"üó£Ô∏è {char_id}: Switched to VOICE SELECTION mode")
                
            elif voice_mode == 'voice_clone':
                stacked_widget.setCurrentIndex(1)  # Voice clone button
                status_label.setText("üé§")
                status_label.setToolTip("Voice Clone mode - nh√¢n b·∫£n gi·ªçng t·ª´ m·∫´u audio")
                quick_btn.setToolTip("Test voice clone")
                print(f"üé§ {char_id}: Switched to VOICE CLONE mode")
    
    def _get_voice_gender_parameters(self, voice_id):
        """L·∫•y parameters t·ªëi ∆∞u cho voice d·ª±a tr√™n gender (nh∆∞ AI Gender Analysis system)"""
        
        # üë© FEMALE VOICES - nh·∫π nh√†ng, bi·ªÉu c·∫£m h∆°n
        female_voices = ['female_young', 'female_mature', 'female_gentle']
        if voice_id in female_voices:
            return {
                'emotion': 1.2,     # Bi·ªÉu c·∫£m h∆°n
                'speed': 0.95,      # Ch·∫≠m h∆°n m·ªôt ch√∫t  
                'cfg_weight': 0.6   # Ch·∫•t l∆∞·ª£ng cao
            }
        
        # üë® MALE VOICES - m·∫°nh m·∫Ω, √≠t bi·ªÉu c·∫£m
        male_voices = ['male_young', 'male_mature', 'male_deep'] 
        if voice_id in male_voices:
            return {
                'emotion': 0.8,     # √çt bi·ªÉu c·∫£m, m·∫°nh m·∫Ω
                'speed': 1.05,      # Nhanh h∆°n m·ªôt ch√∫t
                'cfg_weight': 0.4   # C√¢n b·∫±ng
            }
        
        # üó£Ô∏è NEUTRAL VOICES - c√¢n b·∫±ng
        neutral_voices = ['neutral_narrator', 'neutral_child', 'neutral_elder']
        if voice_id in neutral_voices:
            return {
                'emotion': 1.0,     # C√¢n b·∫±ng
                'speed': 1.0,       # B√¨nh th∆∞·ªùng  
                'cfg_weight': 0.5   # C√¢n b·∫±ng
            }
        
        # üé§ VOICE CLONING - default balanced
        if voice_id == 'cloned':
            return {
                'emotion': 1.0,     # C√¢n b·∫±ng
                'speed': 1.0,       # B√¨nh th∆∞·ªùng
                'cfg_weight': 0.5   # C√¢n b·∫±ng
            }
        
        # Default fallback
        return {
            'emotion': 1.0,
            'speed': 1.0, 
            'cfg_weight': 0.5
        }
    
    def preview_character_with_settings(self, char_id):
        """Preview gi·ªçng v·ªõi settings c·ª• th·ªÉ c·ªßa nh√¢n v·∫≠t"""
        try:
            # Validate v√† hi·ªÉn th·ªã priority logic
            voice_mode = self.validate_character_voice_settings(char_id)
            
            settings = self.character_chatterbox_settings.get(char_id, {})
            emotion = settings.get('emotion', 1.0)
            speed = settings.get('speed', 1.0) 
            cfg_weight = settings.get('cfg_weight', 0.5)
            voice_id = settings.get('voice_id', 'female_young')
            voice_clone_path = settings.get('voice_clone_path', None)
            voice_prompt = settings.get('voice_prompt', '').strip()
            
            char_name = self.get_character_name_by_id(char_id)
            
            # T·∫°o preview text d·ª±a tr√™n voice mode
            if voice_mode == 'clone':
                preview_text = f"Xin ch√†o, t√¥i l√† {char_name}. ƒê√¢y l√† gi·ªçng ƒë∆∞·ª£c clone t·ª´ voice samples."
            else:
                # T√¨m voice display name
                voice_display_name = voice_id
                fallback_voices = [
                    ("üë© Young Female (female)", "female_young"),
                    ("üë® Young Male (male)", "male_young"),
                    ("üó£Ô∏è Narrator (neutral)", "neutral_narrator"),
                    ("üë© Mature Female (female)", "female_mature"),
                    ("üë® Mature Male (male)", "male_mature"),
                    ("üë© Gentle Female (female)", "female_gentle"),
                    ("üë® Deep Male (male)", "male_deep"),
                    ("üë∂ Child Voice (neutral)", "child_voice"),
                    ("üë¥ Elder Voice (neutral)", "elder_voice"),
                    ("üé§ Voice Cloning (variable)", "cloned")
                ]
                
                for display, vid in fallback_voices:
                    if vid == voice_id:
                        voice_display_name = display
                        break
                
                preview_text = f"Xin ch√†o, t√¥i l√† {char_name}. ƒê√¢y l√† gi·ªçng {voice_display_name} v·ªõi emotion {emotion:.1f}, speed {speed:.1f}x v√† CFG weight {cfg_weight:.2f}"
            
            # Generate preview
            import tempfile
            temp_dir = tempfile.mkdtemp()
            preview_path = os.path.join(temp_dir, f"preview_{char_id}.mp3")
                
            result = self.voice_generator.generate_voice_chatterbox(
                text=preview_text,
                save_path=preview_path,
                voice_sample_path=voice_clone_path if voice_mode == 'clone' else None,
                emotion_exaggeration=emotion,
                speed=speed,
                voice_name=voice_id if voice_mode == 'selection' else None,
                cfg_weight=cfg_weight
            )
            
            if result.get('success'):
                self.play_audio_file(preview_path)
                from PySide6.QtWidgets import QMessageBox
                
                # T·∫°o message v·ªõi priority info
                message = f"Character: {char_name}\n"
                message += f"Mode: {voice_mode.upper()}\n\n"
                
                if voice_mode == 'clone':
                    message += f"Voice Clone: {voice_clone_path}\n"
                else:
                    message += f"Voice: {voice_display_name}\n"
                
                message += f"Emotion: {emotion:.1f}\n"
                message += f"Speed: {speed:.1f}x\n"
                message += f"CFG Weight: {cfg_weight:.2f}\n"
                message += f"\nü§ñ Generated by Chatterbox TTS"
                
                QMessageBox.information(self, "üéß Preview Voice", message)
            else:
                from PySide6.QtWidgets import QMessageBox
                QMessageBox.warning(self, "‚ùå L·ªói Preview", f"Kh√¥ng th·ªÉ t·∫°o preview:\n{result.get('error', 'Unknown error')}")
                
        except Exception as e:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.critical(self, "‚ùå L·ªói Critical", f"L·ªói preview voice:\n{str(e)}")
    
    def update_character_voice_prompt(self, char_id, prompt_text):
        """C·∫≠p nh·∫≠t voice prompt cho nh√¢n v·∫≠t c·ª• th·ªÉ"""
        if char_id not in self.character_chatterbox_settings:
            self.character_chatterbox_settings[char_id] = {}
        
        self.character_chatterbox_settings[char_id]['voice_prompt'] = prompt_text
        
        if prompt_text.strip():
            print(f"üí¨ Voice prompt updated for {self.get_character_name_by_id(char_id)}: '{prompt_text[:50]}...'")
        else:
            print(f"üí¨ Voice prompt cleared for {self.get_character_name_by_id(char_id)}")
    
    def show_voice_quick_actions(self, char_id):
        """Hi·ªÉn th·ªã quick actions cho voice mode hi·ªán t·∫°i"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_mode = settings.get('voice_mode', 'voice_selection')
        char_name = self.get_character_name_by_id(char_id)
        
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, QMessageBox
        
        dialog = QDialog(self)
        dialog.setWindowTitle(f"Quick Actions - {char_name}")
        dialog.setFixedSize(400, 300)
        
        layout = QVBoxLayout()
        
        if voice_mode == 'voice_selection':
            layout.addWidget(QLabel(f"üó£Ô∏è Voice Selection Mode - {char_name}"))
            layout.addWidget(QLabel("Quick actions for voice selection:"))
            
            # Auto-optimize button
            optimize_btn = QPushButton("üéØ Auto-optimize Parameters")
            optimize_btn.clicked.connect(lambda: self.auto_optimize_voice_params(char_id, dialog))
            layout.addWidget(optimize_btn)
            
            # Reset to defaults
            reset_btn = QPushButton("üîÑ Reset to Defaults")
            reset_btn.clicked.connect(lambda: self.reset_voice_params(char_id, dialog))
            layout.addWidget(reset_btn)
            
        elif voice_mode == 'voice_clone':
            layout.addWidget(QLabel(f"üé§ Voice Clone Mode - {char_name}"))
            layout.addWidget(QLabel("Quick actions for voice cloning:"))
            
            # Test clone button
            test_btn = QPushButton("üß™ Test Voice Clone")
            test_btn.clicked.connect(lambda: self.test_voice_clone(char_id, dialog))
            layout.addWidget(test_btn)
            
            # Clear clone path
            clear_btn = QPushButton("üóëÔ∏è Clear Clone Path")
            clear_btn.clicked.connect(lambda: self.clear_voice_clone_path(char_id, dialog))
            layout.addWidget(clear_btn)
        
        # Close button
        close_btn = QPushButton("‚ùå Close")
        close_btn.clicked.connect(dialog.close)
        layout.addWidget(close_btn)
        
        dialog.setLayout(layout)
        dialog.exec()
    
    def auto_optimize_voice_params(self, char_id, dialog):
        """T·ª± ƒë·ªông t·ªëi ∆∞u parameters cho voice"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_id = settings.get('voice_id', 'female_young')
        
        # Get optimized params
        optimized_params = self._get_voice_gender_parameters(voice_id)
        
        # Update settings
        self.character_chatterbox_settings[char_id].update(optimized_params)
        
        # Update UI
        self.populate_character_settings_table()
        
        from PySide6.QtWidgets import QMessageBox
        QMessageBox.information(dialog, "‚úÖ Optimized", 
                              f"Parameters optimized for {voice_id}:\n"
                              f"Emotion: {optimized_params['emotion']:.1f}\n"
                              f"Speed: {optimized_params['speed']:.1f}\n"
                              f"CFG Weight: {optimized_params['cfg_weight']:.2f}")
        dialog.close()
    
    def reset_voice_params(self, char_id, dialog):
        """Reset voice parameters v·ªÅ defaults"""
        self.character_chatterbox_settings[char_id].update({
            'emotion': 1.0,
            'speed': 1.0,
            'cfg_weight': 0.5
        })
        
        # Update UI
        self.populate_character_settings_table()
        
        from PySide6.QtWidgets import QMessageBox
        QMessageBox.information(dialog, "üîÑ Reset", "Parameters reset to defaults")
        dialog.close()
    
    def test_voice_clone(self, char_id, dialog):
        """Test voice clone v·ªõi sample text"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_clone_path = settings.get('voice_clone_path')
        
        if not voice_clone_path:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(dialog, "‚ö†Ô∏è Warning", "No voice clone path selected!")
            return
        
        # Test v·ªõi sample text
        char_name = self.get_character_name_by_id(char_id)
        test_text = f"Xin ch√†o, t√¥i l√† {char_name}. ƒê√¢y l√† test voice cloning."
        
        import tempfile
        temp_dir = tempfile.mkdtemp()
        test_path = os.path.join(temp_dir, f"test_clone_{char_id}.mp3")
        
        result = self.voice_generator.generate_voice_chatterbox(
            text=test_text,
            save_path=test_path,
            voice_sample_path=voice_clone_path,
            emotion_exaggeration=settings.get('emotion', 1.0),
            speed=settings.get('speed', 1.0),
            cfg_weight=settings.get('cfg_weight', 0.5)
        )
        
        if result.get('success'):
            self.play_audio_file(test_path)
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.information(dialog, "‚úÖ Test Success", "Voice clone test completed!")
        else:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(dialog, "‚ùå Test Failed", f"Test failed: {result.get('error', 'Unknown error')}")
    
    def clear_voice_clone_path(self, char_id, dialog):
        """Clear voice clone path"""
        self.character_chatterbox_settings[char_id]['voice_clone_path'] = None
        self.character_chatterbox_settings[char_id]['voice_clone_status'] = 'none'
        
        # Update UI
        self._update_voice_clone_status_ui(char_id, 'none', "No voice samples")
        
        from PySide6.QtWidgets import QMessageBox
        QMessageBox.information(dialog, "üóëÔ∏è Cleared", "Voice clone path cleared")
        dialog.close()
    
    def show_voice_prompt_examples(self, char_id, input_field):
        """Hi·ªÉn th·ªã dialog v·ªõi voice prompt examples"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QHBoxLayout, QPushButton, QLabel
        
        dialog = QDialog(self)
        dialog.setWindowTitle(f"Voice Prompt Examples - {self.get_character_name_by_id(char_id)}")
        dialog.setFixedSize(500, 400)
        
        layout = QVBoxLayout()
        layout.addWidget(QLabel("Ch·ªçn example ho·∫∑c t·ª± vi·∫øt prompt:"))
        
        examples = [
            ("üë© MC Radio", "Gi·ªçng n·ªØ tr·∫ª, vui v·∫ª, nƒÉng ƒë·ªông nh∆∞ MC radio, n√≥i nhanh v√† c√≥ intonation r√µ r√†ng"),
            ("üë® Tin t·ª©c", "Gi·ªçng nam tr·∫ßm, nghi√™m t√∫c, uy t√≠n nh∆∞ ng∆∞·ªùi d·∫´n ch∆∞∆°ng tr√¨nh tin t·ª©c"),
            ("üë∂ Tr·∫ª em", "Gi·ªçng tr·∫ª em vui v·∫ª, trong tr·∫ªo, h·ªìn nhi√™n nh∆∞ trong truy·ªán c·ªï t√≠ch"),
            ("üë© Gentle", "Gi·ªçng n·ªØ nh·∫π nh√†ng, d·ªãu d√†ng, ·∫•m √°p nh∆∞ ng∆∞·ªùi m·∫π k·ªÉ chuy·ªán"),
            ("üë® Hero", "Gi·ªçng nam m·∫°nh m·∫Ω, quy·∫øt ƒëo√°n, anh h√πng nh∆∞ trong phim h√†nh ƒë·ªông"),
            ("üé≠ Dramatic", "Gi·ªçng k·ªãch t√≠nh, c·∫£m x√∫c m·∫°nh, nh∆∞ di·ªÖn vi√™n s√¢n kh·∫•u"),
            ("üòÑ Happy", "Gi·ªçng vui v·∫ª, t∆∞∆°i t·∫Øn, lu√¥n c∆∞·ªùi, t√≠ch c·ª±c"),
            ("üò¢ Sad", "Gi·ªçng bu·ªìn b√£, u s·∫ßu, ch·∫≠m r√£i, ƒë·∫ßy c·∫£m x√∫c"),
            ("üò† Angry", "Gi·ªçng t·ª©c gi·∫≠n, quy·∫øt li·ªát, m·∫°nh m·∫Ω, c√≥ s·ª©c thuy·∫øt ph·ª•c"),
            ("ü§´ Mysterious", "Gi·ªçng b√≠ ·∫©n, th·∫ßm th√¨, huy·ªÅn b√≠ nh∆∞ trong phim trinh th√°m")
        ]
        
        for title, prompt in examples:
            btn = QPushButton(f"{title}")
            btn.setToolTip(prompt)
            btn.clicked.connect(lambda checked, p=prompt: self.apply_voice_prompt_example(input_field, p, dialog))
            layout.addWidget(btn)
        
        # Buttons
        button_layout = QHBoxLayout()
        cancel_btn = QPushButton("H·ªßy")
        cancel_btn.clicked.connect(dialog.reject)
        button_layout.addWidget(cancel_btn)
        
        layout.addLayout(button_layout)
        dialog.setLayout(layout)
        dialog.exec()
    
    def apply_voice_prompt_example(self, input_field, prompt, dialog):
        """Apply voice prompt example to input field"""
        input_field.setText(prompt)
        dialog.accept()
    
    def select_character_voice_clone_folder(self, char_id):
        """Ch·ªçn th∆∞ m·ª•c voice samples cho nh√¢n v·∫≠t c·ª• th·ªÉ v·ªõi progress tracking"""
        from PySide6.QtWidgets import QFileDialog, QMessageBox, QProgressDialog
        from PySide6.QtCore import QTimer
        
        character_name = self.get_character_name_by_id(char_id)
        folder = QFileDialog.getExistingDirectory(
            self, 
            f"Ch·ªçn th∆∞ m·ª•c voice samples cho {character_name}",
            "",
            QFileDialog.ShowDirsOnly | QFileDialog.DontResolveSymlinks
        )
        
        if folder:
            # Show progress dialog
            progress = QProgressDialog(f"ƒêang x·ª≠ l√Ω voice samples cho {character_name}...", "H·ªßy", 0, 100, self)
            progress.setWindowModality(Qt.WindowModal)
            progress.show()
            
            # Update status to processing
            self._update_voice_clone_status_ui(char_id, 'processing', 'ƒêang x·ª≠ l√Ω...')
            
            # Ki·ªÉm tra xem folder c√≥ audio files kh√¥ng
            import os
            audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']
            audio_files = []
            
            progress.setValue(20)
            
            try:
                for file in os.listdir(folder):
                    if any(file.lower().endswith(ext) for ext in audio_extensions):
                        audio_files.append(file)
                
                progress.setValue(50)
                
                if not audio_files:
                    progress.close()
                    self._update_voice_clone_status_ui(char_id, 'error', 'Kh√¥ng t√¨m th·∫•y audio files')
                    QMessageBox.warning(
                        self, 
                        "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y audio files", 
                        f"Th∆∞ m·ª•c '{folder}' kh√¥ng ch·ª©a file audio n√†o (.wav, .mp3, .flac, .ogg, .m4a)"
                    )
                    return
                
                progress.setValue(80)
                
                # L∆∞u path v√† update status
                if char_id not in self.character_chatterbox_settings:
                    self.character_chatterbox_settings[char_id] = {}
                
                self.character_chatterbox_settings[char_id]['voice_clone_path'] = folder
                self.character_chatterbox_settings[char_id]['voice_clone_status'] = 'ready'
                
                progress.setValue(100)
                progress.close()
                
                # Update UI status
                self._update_voice_clone_status_ui(char_id, 'ready', f"{len(audio_files)} files s·∫µn s√†ng")
                
                print(f"üìÅ Voice clone folder set for {character_name}: {folder}")
                print(f"   üéµ Found {len(audio_files)} audio files: {', '.join(audio_files[:3])}{'...' if len(audio_files) > 3 else ''}")
                
                QMessageBox.information(
                    self,
                    "‚úÖ Voice Clone Setup",
                    f"ƒê√£ thi·∫øt l·∫≠p voice cloning cho {character_name}\n"
                    f"Th∆∞ m·ª•c: {folder}\n"
                    f"T√¨m th·∫•y: {len(audio_files)} audio files"
                )
                
            except Exception as e:
                progress.close()
                self._update_voice_clone_status_ui(char_id, 'error', f'L·ªói: {str(e)}')
                QMessageBox.critical(
                    self,
                    "‚ùå L·ªói Voice Clone Setup",
                    f"Kh√¥ng th·ªÉ thi·∫øt l·∫≠p voice cloning:\n{str(e)}"
                )
    
    def _update_voice_clone_status_ui(self, char_id, status, tooltip_text=""):
        """C·∫≠p nh·∫≠t UI status cho voice clone c·ªßa nh√¢n v·∫≠t"""
        status_icons = {
            'none': '‚ùå',
            'ready': '‚úÖ', 
            'processing': '‚è≥',
            'error': '‚ùå'
        }
        
        status_colors = {
            'none': 'color: red;',
            'ready': 'color: green;',
            'processing': 'color: orange;',
            'error': 'color: red;'
        }
        
        # T√¨m row c·ªßa character n√†y
        for i in range(self.character_settings_table.rowCount()):
            name_item = self.character_settings_table.item(i, 0)
            if name_item and name_item.text() == self.get_character_name_by_id(char_id):
                # L·∫•y voice clone container
                voice_clone_container = self.character_settings_table.cellWidget(i, 6)
                if voice_clone_container:
                    # T√¨m status label (widget th·ª© 2 trong layout)
                    layout = voice_clone_container.layout()
                    if layout and layout.count() > 1:
                        status_label = layout.itemAt(1).widget()
                        if status_label:
                            status_label.setText(status_icons.get(status, '‚ùì'))
                            status_label.setStyleSheet(status_colors.get(status, ''))
                            status_label.setToolTip(tooltip_text or f"Status: {status}")
                break
    
    def get_character_name_by_id(self, char_id):
        """Helper ƒë·ªÉ l·∫•y t√™n nh√¢n v·∫≠t t·ª´ ID"""
        if self.voice_studio_script_data:
            for character in self.voice_studio_script_data['characters']:
                if character['id'] == char_id:
                    return character['name']
        return f"Character {char_id}"
    
    def toggle_voice_cloning(self, enabled):
        """Toggle voice cloning controls"""
        self.voice_clone_folder_btn.setEnabled(enabled)
    
    def select_voice_clone_folder(self):
        """Ch·ªçn th∆∞ m·ª•c ch·ª©a voice samples"""
        from PySide6.QtWidgets import QFileDialog
        folder = QFileDialog.getExistingDirectory(self, "Ch·ªçn th∆∞ m·ª•c voice samples")
        if folder:
            self.voice_clone_folder = folder
            self.voice_clone_path_label.setText(f"üìÅ {folder}")
            self.voice_clone_path_label.setStyleSheet("color: green; font-weight: bold; margin-left: 20px;")
    
    def validate_character_voice_settings(self, char_id):
        """Validate character voice settings d·ª±a tr√™n voice mode ƒë∆∞·ª£c ch·ªçn"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_mode = settings.get('voice_mode', 'voice_selection')
        char_name = self.get_character_name_by_id(char_id)
        
        if voice_mode == 'voice_clone':
            voice_clone_path = settings.get('voice_clone_path')
            if voice_clone_path and os.path.exists(voice_clone_path):
                print(f"üéØ {char_name}: Using VOICE CLONE - {voice_clone_path}")
                return 'clone'
            else:
                # Fallback to voice selection if no clone
                print(f"‚ö†Ô∏è {char_name}: Voice clone mode selected but no samples provided, fallback to voice selection")
                voice_id = settings.get('voice_id', 'female_young')
                print(f"üéØ {char_name}: Using VOICE SELECTION (fallback) - {voice_id}")
                return 'selection'
                
        else:  # voice_selection mode
            voice_id = settings.get('voice_id', 'female_young')
            print(f"üéØ {char_name}: Using VOICE SELECTION - {voice_id}")
            return 'selection'
    
    def apply_preset(self, preset_type):
        """√Åp d·ª•ng preset settings"""
        presets = {
            "natural": {"emotion": 1.0, "speed": 1.0},
            "dramatic": {"emotion": 2.5, "speed": 0.9},
            "fast": {"emotion": 1.2, "speed": 1.5},
            "slow": {"emotion": 0.8, "speed": 0.7}
        }
        
        if preset_type in presets:
            preset = presets[preset_type]
            
            # Update global sliders
            emotion_value = int(preset["emotion"] * 100)
            speed_value = int(preset["speed"] * 100)
            
            self.emotion_slider.setValue(emotion_value)
            self.speed_slider.setValue(speed_value)
            
            # Update all character settings
            for char_id in self.character_chatterbox_settings:
                self.character_chatterbox_settings[char_id]['emotion'] = preset["emotion"]
                self.character_chatterbox_settings[char_id]['speed'] = preset["speed"]
            
            # Update character table sliders
            for i in range(self.character_settings_table.rowCount()):
                emotion_slider = self.character_settings_table.cellWidget(i, 1)
                speed_slider = self.character_settings_table.cellWidget(i, 2)
                if emotion_slider:
                    emotion_slider.setValue(emotion_value)
                if speed_slider:
                    speed_slider.setValue(speed_value)
            
            QMessageBox.information(self, "Preset", f"ƒê√£ √°p d·ª•ng preset '{preset_type.title()}'!")
    
    def get_character_chatterbox_settings(self, char_id):
        """L·∫•y settings cho character khi manual mode enabled"""
        if self.enable_chatterbox_manual.isChecked():
            return self.character_chatterbox_settings.get(char_id, {
                'emotion': self.emotion_slider.value() / 100.0,
                'speed': self.speed_slider.value() / 100.0,
                'voice_clone_path': None
            })
        else:
            return {'emotion': 1.0, 'speed': 1.0, 'voice_clone_path': None}
    
    def map_emotion_to_parameters(self, emotion_label, base_exaggeration=1.0):
        """Map emotion label th√†nh emotion exaggeration + cfg_weight cho ch·∫•t l∆∞·ª£ng t·ªëi ∆∞u"""
        
        # Enhanced emotion mapping table v·ªõi c·∫£ exaggeration v√† cfg_weight
        emotion_mapping = {
            # M·ª•c ƒë√≠ch: T·ª± nhi√™n, gi·ªçng k·ªÉ chuy·ªán
            'neutral': {'exaggeration_mult': 0.4, 'cfg_weight': 0.5},
            
            # Gi·ªçng nh√¢n m·∫°nh (h√πng bi·ªán, t·ª©c gi·∫≠n) 
            'angry': {'exaggeration_mult': 1.2, 'cfg_weight': 0.35},
            'threatening': {'exaggeration_mult': 1.2, 'cfg_weight': 0.35},
            'confident': {'exaggeration_mult': 1.1, 'cfg_weight': 0.35},
            'proud': {'exaggeration_mult': 1.1, 'cfg_weight': 0.35},
            'dramatic': {'exaggeration_mult': 1.3, 'cfg_weight': 0.35},
            'shout': {'exaggeration_mult': 1.3, 'cfg_weight': 0.30},
            
            # C·∫£m x√∫c nh·∫π nh√†ng, n·ªØ t√≠nh
            'happy': {'exaggeration_mult': 0.7, 'cfg_weight': 0.45},
            'excited': {'exaggeration_mult': 0.8, 'cfg_weight': 0.45},
            'friendly': {'exaggeration_mult': 0.7, 'cfg_weight': 0.45},
            'romantic': {'exaggeration_mult': 0.7, 'cfg_weight': 0.45},
            'surprised': {'exaggeration_mult': 0.7, 'cfg_weight': 0.45},
            'pleading': {'exaggeration_mult': 0.8, 'cfg_weight': 0.45},
            
            # C·∫£m x√∫c ƒë·∫∑c bi·ªát
            'sad': {'exaggeration_mult': 0.6, 'cfg_weight': 0.45},
            'fear': {'exaggeration_mult': 0.7, 'cfg_weight': 0.40},
            'calm': {'exaggeration_mult': 0.4, 'cfg_weight': 0.50},
            'whisper': {'exaggeration_mult': 0.3, 'cfg_weight': 0.50},
            'shy': {'exaggeration_mult': 0.4, 'cfg_weight': 0.45},
            'mysterious': {'exaggeration_mult': 0.5, 'cfg_weight': 0.40},
            'sarcastic': {'exaggeration_mult': 1.0, 'cfg_weight': 0.35},
        }
        
        # Get mapping cho emotion label
        mapping = emotion_mapping.get(emotion_label.lower(), {'exaggeration_mult': 1.0, 'cfg_weight': 0.5})
        
        # Calculate final parameters
        final_exaggeration = base_exaggeration * mapping['exaggeration_mult']
        cfg_weight = mapping['cfg_weight']
        
        # Clamp exaggeration v√†o range 0.0-2.0
        final_exaggeration = max(0.0, min(2.0, final_exaggeration))
        
        # Clamp cfg_weight v√†o range 0.0-1.0  
        cfg_weight = max(0.0, min(1.0, cfg_weight))
        
        # Log ƒë·ªÉ user th·∫•y emotion ƒë∆∞·ª£c √°p d·ª•ng
        if emotion_label.lower() != 'neutral':
            print(f"   üé≠ Emotion Auto-Mapping: '{emotion_label}' ‚Üí exaggeration={final_exaggeration:.2f}, cfg_weight={cfg_weight:.2f}")
        
        return final_exaggeration, cfg_weight
    
    def update_emotion_from_slider(self, value):
        """C·∫≠p nh·∫≠t emotion input t·ª´ slider"""
        emotion_value = value / 100.0  # Convert 0-300 to 0.0-3.0
        self.emotion_input.setText(f"{emotion_value:.1f}")
    
    def update_emotion_from_input(self):
        """C·∫≠p nh·∫≠t emotion slider t·ª´ input"""
        try:
            value = float(self.emotion_input.text())
            value = max(0.0, min(3.0, value))  # Clamp to 0.0-3.0
            slider_value = int(value * 100)  # Convert to 0-300
            self.emotion_slider.setValue(slider_value)
        except ValueError:
            pass  # Ignore invalid input
    
    def update_speed_from_slider(self, value):
        """C·∫≠p nh·∫≠t speed input t·ª´ slider"""
        speed_value = value / 100.0  # Convert 50-200 to 0.5-2.0
        self.speed_input.setText(f"{speed_value:.1f}")
    
    def update_speed_from_input(self):
        """C·∫≠p nh·∫≠t speed slider t·ª´ input"""
        try:
            value = float(self.speed_input.text())
            value = max(0.5, min(2.0, value))  # Clamp to 0.5-2.0
            slider_value = int(value * 100)  # Convert to 50-200
            self.speed_slider.setValue(slider_value)
        except ValueError:
            pass  # Ignore invalid input
    
    def update_cfg_weight_from_slider(self, value):
        """C·∫≠p nh·∫≠t CFG weight input t·ª´ slider"""
        cfg_value = value / 100.0  # Convert 0-100 to 0.0-1.0
        self.cfg_weight_input.setText(f"{cfg_value:.2f}")
    
    def update_cfg_weight_from_input(self):
        """C·∫≠p nh·∫≠t CFG weight slider t·ª´ input"""
        try:
            value = float(self.cfg_weight_input.text())
            value = max(0.0, min(1.0, value))  # Clamp to 0.0-1.0
            slider_value = int(value * 100)  # Convert to 0-100
            self.cfg_weight_slider.setValue(slider_value)
        except ValueError:
            pass  # Ignore invalid input
    
    def update_default_voice_options(self):
        """C·∫≠p nh·∫≠t danh s√°ch gi·ªçng default"""
        self.default_voice_combo.clear()
        
        # L·∫•y voices t·ª´ Chatterbox provider
        if self.voice_generator.chatterbox_provider:
            available_voices = self.voice_generator.chatterbox_provider.get_available_voices()
            for voice in available_voices:
                display_text = f"{voice['name']} ({voice['gender']})"
                self.default_voice_combo.addItem(display_text, voice['id'])
        else:
            # Fallback voices
            fallback_voices = [
                ("Young Female (female)", "female_young"),
                ("Young Male (male)", "male_young"),
                ("Narrator (neutral)", "neutral_narrator"),
                ("Voice Cloning (variable)", "cloned")
            ]
            for display, voice_id in fallback_voices:
                self.default_voice_combo.addItem(display, voice_id)
    
    def preview_default_voice(self):
        """Preview gi·ªçng default v·ªõi settings hi·ªán t·∫°i"""
        try:
            # Get current settings
            emotion = float(self.emotion_input.text())
            speed = float(self.speed_input.text())
            cfg_weight = float(self.cfg_weight_input.text())
            voice_id = self.default_voice_combo.currentData()
            voice_name = self.default_voice_combo.currentText()
            
            # Preview text
            preview_text = f"ƒê√¢y l√† gi·ªçng {voice_name} v·ªõi emotion {emotion}, speed {speed}, v√† CFG weight {cfg_weight}."
            
            # Generate preview audio
            import tempfile
            temp_dir = tempfile.mkdtemp()
            preview_path = os.path.join(temp_dir, "preview_default_voice.mp3")
            
            result = self.voice_generator.generate_voice_chatterbox(
                text=preview_text,
                save_path=preview_path,
                voice_sample_path=None,
                emotion_exaggeration=emotion,
                speed=speed,
                voice_name=voice_id,
                cfg_weight=cfg_weight
            )
            
            if result.get('success'):
                self.play_audio_file(preview_path)
                from PyQt5.QtWidgets import QMessageBox
                QMessageBox.information(self, "Preview", f"Preview: {voice_name}\nEmotion: {emotion}\nSpeed: {speed}\nCFG Weight: {cfg_weight}")
            else:
                from PyQt5.QtWidgets import QMessageBox
                QMessageBox.warning(self, "L·ªói", f"Kh√¥ng th·ªÉ t·∫°o preview:\\n{result.get('error', 'Unknown error')}")
                
        except Exception as e:
            from PyQt5.QtWidgets import QMessageBox
            QMessageBox.critical(self, "L·ªói", f"L·ªói preview voice:\\n{str(e)}")