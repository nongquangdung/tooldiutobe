from PySide6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, 
    QTextEdit, QPushButton, QLabel, QTabWidget, QListWidget, 
    QListWidgetItem, QMessageBox, QProgressBar, QComboBox, 
    QLineEdit, QCheckBox, QSplitter, QScrollArea, QFrame, QGroupBox,
    QGridLayout, QSlider, QSpinBox, QFileDialog, QStatusBar, QDialog,
    QTableWidget, QTableWidgetItem, QStackedWidget, QProgressDialog
)
from PySide6.QtCore import Qt, QThread, Signal, QTimer, QSize
from PySide6.QtGui import QTextCursor, QFont, QIcon, QAction, QPixmap
import os
import sys
import json
import subprocess
import tempfile
import platform
import traceback
import shutil
import glob
from .manual_voice_setup_dialog import ManualVoiceSetupDialog

# Import pipeline
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from core.video_pipeline import VideoPipeline
from video.effects_presets import EffectsPresets
from ai.prompt_templates import PromptTemplates
from core.api_manager import APIManager
from tts.voice_generator import VoiceGenerator

class VideoGenerationThread(QThread):
    progress_updated = Signal(int, str)
    finished = Signal(dict)
    
    def __init__(self, prompt, project_name, effects, use_custom_images=False, custom_images_folder=None,
                 voice_name="vi-VN-Standard-A", project_folder=None):
        super().__init__()
        self.prompt = prompt
        self.project_name = project_name
        self.effects = effects
        self.use_custom_images = use_custom_images
        self.custom_images_folder = custom_images_folder
        self.voice_name = voice_name
        self.project_folder = project_folder
        self.pipeline = VideoPipeline()
    
    def run(self):
        def progress_callback(step, message):
            self.progress_updated.emit(step, message)
        
        # T·∫°o video v·ªõi ho·∫∑c kh√¥ng c√≥ ·∫£nh th·ªß c√¥ng
        if self.use_custom_images and self.custom_images_folder:
            result = self.pipeline.create_video_with_custom_images(
                self.prompt, self.project_name, self.custom_images_folder, 
                self.effects, progress_callback
            )
        else:
            result = self.pipeline.create_video_from_prompt(
                self.prompt, self.project_name, self.effects, progress_callback,
                self.voice_name, self.project_folder
            )
        self.finished.emit(result)

class AdvancedMainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("AI Video Generator - Advanced")
        
        # T·ªëi ∆∞u k√≠ch th∆∞·ªõc cho MacOS 13 inch
        if platform.system() == "Darwin":  # macOS
            window_size = get_macos_window_size()
            self.setGeometry(50, 50, window_size['default_width'], window_size['default_height'])
            self.setMinimumSize(window_size['min_width'], window_size['min_height'])
            self.setMaximumSize(window_size['max_width'], window_size['max_height'])
        else:
            self.setGeometry(100, 100, 1000, 700)
        
        # Kh·ªüi t·∫°o pipeline v√† API manager
        self.pipeline = VideoPipeline()
        self.api_manager = APIManager()
        self.voice_generator = VoiceGenerator()
        self.current_project_id = None
        self.current_script_data = None  # Store generated script data
        
        # Thi·∫øt l·∫≠p style cho macOS
        self.setup_macos_style()
        
        # Widget trung t√¢m v·ªõi tabs
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        layout = QVBoxLayout()
        layout.setContentsMargins(10, 10, 10, 10)  # Gi·∫£m margin
        central_widget.setLayout(layout)
        
        # Tab widget
        self.tabs = QTabWidget()
        layout.addWidget(self.tabs)
        
        # T·∫°o c√°c tabs
        self.create_video_tab()
        self.create_voice_studio_tab()
        self.create_projects_tab()
        self.create_settings_tab()
        
        # T·∫°o status bar
        self.create_status_bar()
    
    def create_status_bar(self):
        """T·∫°o status bar v·ªõi th√¥ng tin h·ªá th·ªëng"""
        status_bar = self.statusBar()
        
        # Status text ch√≠nh
        self.status_text = "‚úÖ S·∫µn s√†ng"
        status_bar.showMessage(self.status_text)
        
        # API status indicator
        self.api_status_label = QLabel("üîë API: Checking...")
        status_bar.addPermanentWidget(self.api_status_label)
        
        # Ki·ªÉm tra API status ngay khi kh·ªüi ƒë·ªông
        self.update_api_status_indicator()
    
    def update_api_status_indicator(self):
        """C·∫≠p nh·∫≠t ch·ªâ b√°o tr·∫°ng th√°i API"""
        # Ki·ªÉm tra xem api_status_label ƒë√£ ƒë∆∞·ª£c t·∫°o ch∆∞a
        if not hasattr(self, 'api_status_label'):
            return
            
        try:
            status = self.api_manager.get_provider_status()
            
            # ƒê·∫øm s·ªë API available
            content_available = sum(status['content_providers'].values())
            image_available = sum(status['image_providers'].values()) 
            tts_available = sum(status['tts_providers'].values())
            
            total_available = content_available + image_available + tts_available
            
            if total_available >= 3:
                self.api_status_label.setText("üü¢ API: ƒê·∫ßy ƒë·ªß")
            elif total_available >= 1:
                self.api_status_label.setText("üü° API: M·ªôt ph·∫ßn")
            else:
                self.api_status_label.setText("üî¥ API: Ch∆∞a c·∫•u h√¨nh")
                
        except Exception:
            if hasattr(self, 'api_status_label'):
                self.api_status_label.setText("‚ö†Ô∏è API: L·ªói")
    
    def setup_macos_style(self):
        """Thi·∫øt l·∫≠p style ph√π h·ª£p v·ªõi macOS"""
        if platform.system() == "Darwin":
            # Font system c·ªßa macOS
            font = QFont("-apple-system", 13)  # macOS system font
            self.setFont(font)
            
            # S·ª≠ d·ª•ng stylesheet t·ª´ file ri√™ng
            self.setStyleSheet(get_macos_stylesheet())
    
    def create_video_tab(self):
        """Tab t·∫°o video m·ªõi v·ªõi layout t·ªëi ∆∞u cho MacOS"""
        tab = QWidget()
        
        # S·ª≠ d·ª•ng scroll area ƒë·ªÉ tr√°nh tr√†n m√†n h√¨nh
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        content_widget = QWidget()
        layout = QVBoxLayout()
        layout.setSpacing(8)  # Gi·∫£m spacing
        content_widget.setLayout(layout)
        
        # Group 1: Prompt v√† g·ª£i √Ω
        prompt_group = QGroupBox("üìù N·ªôi dung video")
        prompt_layout = QVBoxLayout()
        prompt_layout.setSpacing(6)
        
        # G·ª£i √Ω prompt - layout compact
        suggestions_layout = QGridLayout()
        suggestions_layout.addWidget(QLabel("Danh m·ª•c:"), 0, 0)
        
        self.category_combo = QComboBox()
        categories = PromptTemplates.get_all_categories()
        self.category_combo.addItem("-- Ch·ªçn danh m·ª•c --", "")
        for key, value in categories.items():
            self.category_combo.addItem(value["category"], key)
        self.category_combo.currentTextChanged.connect(self.load_prompt_suggestions)
        suggestions_layout.addWidget(self.category_combo, 0, 1)
        
        self.random_prompt_btn = QPushButton("üé≤ Ng·∫´u nhi√™n")
        self.random_prompt_btn.clicked.connect(self.get_random_prompt)
        suggestions_layout.addWidget(self.random_prompt_btn, 0, 2)
        
        prompt_layout.addLayout(suggestions_layout)
        
        # Danh s√°ch prompt g·ª£i √Ω
        self.prompt_suggestions_list = QComboBox()
        self.prompt_suggestions_list.addItem("-- Ch·ªçn prompt m·∫´u --")
        self.prompt_suggestions_list.currentTextChanged.connect(self.use_suggested_prompt)
        prompt_layout.addWidget(self.prompt_suggestions_list)
        
        # Nh·∫≠p prompt - gi·∫£m chi·ªÅu cao
        self.prompt_input = QTextEdit()
        self.prompt_input.setPlaceholderText("V√≠ d·ª•: T·∫°o video gi·ªõi thi·ªáu v·ªÅ du l·ªãch Vi·ªát Nam v·ªõi 5 ƒëi·ªÉm ƒë·∫øn n·ªïi ti·∫øng...")
        self.prompt_input.setMaximumHeight(80)  # Gi·∫£m t·ª´ 100 xu·ªëng 80
        prompt_layout.addWidget(self.prompt_input)
        
        prompt_group.setLayout(prompt_layout)
        layout.addWidget(prompt_group)
        
        # Group 2: C√†i ƒë·∫∑t d·ª± √°n
        project_group = QGroupBox("‚öôÔ∏è C√†i ƒë·∫∑t d·ª± √°n")
        project_layout = QGridLayout()
        project_layout.setSpacing(6)
        
        # T√™n project
        project_layout.addWidget(QLabel("T√™n d·ª± √°n:"), 0, 0)
        self.project_name_input = QLineEdit()
        self.project_name_input.setPlaceholderText("video_project")
        project_layout.addWidget(self.project_name_input, 0, 1, 1, 2)
        
        # Th∆∞ m·ª•c d·ª± √°n
        project_layout.addWidget(QLabel("Th∆∞ m·ª•c:"), 1, 0)
        self.project_folder_input = QLineEdit()
        self.project_folder_input.setPlaceholderText("M·∫∑c ƒë·ªãnh: ./projects/")
        self.project_folder_input.setReadOnly(True)
        project_layout.addWidget(self.project_folder_input, 1, 1)
        
        self.select_project_folder_btn = QPushButton("üìÅ")
        self.select_project_folder_btn.clicked.connect(self.select_project_folder)
        self.select_project_folder_btn.setMaximumWidth(40)
        project_layout.addWidget(self.select_project_folder_btn, 1, 2)
        
        project_group.setLayout(project_layout)
        layout.addWidget(project_group)
        
        # Group 3: T√πy ch·ªçn ·∫£nh
        image_group = QGroupBox("üñºÔ∏è T√πy ch·ªçn ·∫£nh")
        image_layout = QVBoxLayout()
        image_layout.setSpacing(6)
        
        # Radio buttons trong layout ngang
        image_options_layout = QHBoxLayout()
        self.auto_generate_radio = QCheckBox("T·ª± ƒë·ªông t·∫°o ·∫£nh AI")
        self.auto_generate_radio.setChecked(True)
        self.manual_images_radio = QCheckBox("Ch·ªçn ·∫£nh th·ªß c√¥ng")
        image_options_layout.addWidget(self.auto_generate_radio)
        image_options_layout.addWidget(self.manual_images_radio)
        image_layout.addLayout(image_options_layout)
        
        # Ch·ªçn th∆∞ m·ª•c ·∫£nh
        folder_layout = QHBoxLayout()
        self.select_images_btn = QPushButton("üìÅ Ch·ªçn th∆∞ m·ª•c ·∫£nh")
        self.select_images_btn.clicked.connect(self.select_images_folder)
        self.select_images_btn.setEnabled(False)
        folder_layout.addWidget(self.select_images_btn)
        
        self.selected_images_label = QLabel("Ch∆∞a ch·ªçn th∆∞ m·ª•c ·∫£nh")
        self.selected_images_label.setStyleSheet("color: gray; font-style: italic; font-size: 11px;")
        folder_layout.addWidget(self.selected_images_label)
        image_layout.addLayout(folder_layout)
        
        # K·∫øt n·ªëi s·ª± ki·ªán
        self.manual_images_radio.toggled.connect(self.toggle_image_mode)
        
        image_group.setLayout(image_layout)
        layout.addWidget(image_group)
        
        # Group 4: Hi·ªáu ·ª©ng
        effects_group = QGroupBox("‚ú® Hi·ªáu ·ª©ng")
        effects_layout = QVBoxLayout()
        effects_layout.setSpacing(6)
        
        # Preset hi·ªáu ·ª©ng
        preset_layout = QHBoxLayout()
        preset_layout.addWidget(QLabel("Preset:"))
        self.effects_preset_combo = QComboBox()
        presets = EffectsPresets.get_all_presets()
        for key, preset in presets.items():
            self.effects_preset_combo.addItem(f"{preset['name']} - {preset['description']}", key)
        self.effects_preset_combo.setCurrentText("NƒÉng ƒë·ªông")
        preset_layout.addWidget(self.effects_preset_combo)
        effects_layout.addLayout(preset_layout)
        
        # C√†i ƒë·∫∑t hi·ªáu ·ª©ng t√πy ch·ªânh
        custom_effects_layout = QHBoxLayout()
        self.zoom_checkbox = QCheckBox("Hi·ªáu ·ª©ng zoom")
        self.zoom_checkbox.setChecked(True)
        self.transitions_checkbox = QCheckBox("Chuy·ªÉn c·∫£nh")
        self.transitions_checkbox.setChecked(True)
        custom_effects_layout.addWidget(self.zoom_checkbox)
        custom_effects_layout.addWidget(self.transitions_checkbox)
        effects_layout.addLayout(custom_effects_layout)
        
        effects_group.setLayout(effects_layout)
        layout.addWidget(effects_group)
        
        # Group 5: Actions
        actions_group = QGroupBox("üé¨ T·∫°o video")
        actions_layout = QGridLayout()
        actions_layout.setSpacing(8)
        
        self.generate_story_btn = QPushButton("üìù T·∫°o c√¢u chuy·ªán")
        self.generate_story_btn.clicked.connect(self.generate_story_only)
        self.generate_story_btn.setToolTip("T·∫°o k·ªãch b·∫£n video t·ª´ prompt (Cmd+1)")
        self.generate_story_btn.setShortcut("Cmd+1" if platform.system() == "Darwin" else "Ctrl+1")
        actions_layout.addWidget(self.generate_story_btn, 0, 0)
        
        self.generate_audio_btn = QPushButton("üéµ T·∫°o Audio")
        self.generate_audio_btn.clicked.connect(self.generate_audio_only)
        self.generate_audio_btn.setEnabled(False)
        self.generate_audio_btn.setToolTip("T·∫°o audio t·ª´ k·ªãch b·∫£n ƒë√£ c√≥ (Cmd+2)")
        self.generate_audio_btn.setShortcut("Cmd+2" if platform.system() == "Darwin" else "Ctrl+2")
        actions_layout.addWidget(self.generate_audio_btn, 0, 1)
        
        # N√∫t t·∫°o video ho√†n ch·ªânh
        self.generate_video_btn = QPushButton("üé¨ T·∫°o Video Ho√†n ch·ªânh")
        self.generate_video_btn.clicked.connect(self.start_video_generation)
        self.generate_video_btn.setToolTip("T·∫°o video ho√†n ch·ªânh v·ªõi ·∫£nh v√† √¢m thanh (Cmd+3)")
        self.generate_video_btn.setShortcut("Cmd+3" if platform.system() == "Darwin" else "Ctrl+3")
        actions_layout.addWidget(self.generate_video_btn, 1, 0, 1, 2)
        
        # N√∫t c·∫•u h√¨nh gi·ªçng n√≥i th·ªß c√¥ng (lu√¥n hi·ªÉn th·ªã)
        self.manual_voice_setup_btn = QPushButton("üé≠ C·∫•u h√¨nh gi·ªçng theo nh√¢n v·∫≠t")
        self.manual_voice_setup_btn.clicked.connect(self.show_manual_voice_setup)
        self.manual_voice_setup_btn.setToolTip("T·∫°o v√† c·∫•u h√¨nh gi·ªçng n√≥i cho c√°c nh√¢n v·∫≠t th·ªß c√¥ng (Cmd+4)")
        self.manual_voice_setup_btn.setShortcut("Cmd+4" if platform.system() == "Darwin" else "Ctrl+4")
        actions_layout.addWidget(self.manual_voice_setup_btn, 2, 0, 1, 2)

        
        actions_group.setLayout(actions_layout)
        layout.addWidget(actions_group)
        
        # Group 6: Progress v√† Status
        progress_group = QGroupBox("üìä Ti·∫øn tr√¨nh")
        progress_layout = QVBoxLayout()
        progress_layout.setSpacing(6)
        
        # Progress bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        progress_layout.addWidget(self.progress_bar)
        
        # Progress label
        self.progress_label = QLabel("")
        self.progress_label.setVisible(False)
        self.progress_label.setStyleSheet("color: #666; font-size: 11px;")
        progress_layout.addWidget(self.progress_label)
        
        # Status v√† preview area
        self.status_label = QLabel("")
        self.status_label.setStyleSheet("color: #007AFF; font-weight: 500;")
        progress_layout.addWidget(self.status_label)
        
        # Preview content area - compact
        preview_label = QLabel("üìÑ Xem tr∆∞·ªõc n·ªôi dung:")
        preview_label.setStyleSheet("font-weight: 600; margin-top: 8px;")
        progress_layout.addWidget(preview_label)
        
        self.content_preview = QTextEdit()
        self.content_preview.setReadOnly(True)
        self.content_preview.setMaximumHeight(120)  # Compact height
        self.content_preview.setPlaceholderText("N·ªôi dung c√¢u chuy·ªán s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y sau khi t·∫°o...")
        progress_layout.addWidget(self.content_preview)
        
        # Audio controls - compact layout
        audio_controls_layout = QGridLayout()
        audio_controls_layout.setSpacing(6)
        
        self.open_audio_folder_btn = QPushButton("üìÅ Th∆∞ m·ª•c Audio")
        self.open_audio_folder_btn.clicked.connect(self.open_audio_folder)
        self.open_audio_folder_btn.setEnabled(False)
        self.open_audio_folder_btn.setToolTip("M·ªü th∆∞ m·ª•c ch·ª©a c√°c file audio ƒë√£ t·∫°o")
        audio_controls_layout.addWidget(self.open_audio_folder_btn, 0, 0)
        
        self.play_final_audio_btn = QPushButton("‚ñ∂Ô∏è Nghe Audio")
        self.play_final_audio_btn.clicked.connect(self.play_final_audio)
        self.play_final_audio_btn.setEnabled(False)
        self.play_final_audio_btn.setToolTip("Ph√°t file audio ho√†n ch·ªânh ƒë√£ gh√©p")
        audio_controls_layout.addWidget(self.play_final_audio_btn, 0, 1)
        
        progress_layout.addLayout(audio_controls_layout)
        
        # Voice settings - compact
        voice_layout = QHBoxLayout()
        voice_layout.addWidget(QLabel("Gi·ªçng TTS:"))
        self.voice_combo = QComboBox()
        vietnamese_voices = [
            "vi-VN-Standard-A (N·ªØ)",
            "vi-VN-Standard-B (Nam)",
            "vi-VN-Standard-C (N·ªØ)",
            "vi-VN-Standard-D (Nam)",
            "vi-VN-Wavenet-A (N·ªØ)",
            "vi-VN-Wavenet-B (Nam)",
            "vi-VN-Wavenet-C (N·ªØ)",
            "vi-VN-Wavenet-D (Nam)"
        ]
        self.voice_combo.addItems(vietnamese_voices)
        voice_layout.addWidget(self.voice_combo)
        progress_layout.addLayout(voice_layout)
        
        progress_group.setLayout(progress_layout)
        progress_group.setVisible(False)  # ·∫®n ban ƒë·∫ßu, hi·ªán khi c·∫ßn
        layout.addWidget(progress_group)
        
        # Store references
        self.progress_group = progress_group
        self.last_audio_output_dir = None
        self.last_final_audio_path = None
        
        # Th√™m stretch ƒë·ªÉ ƒë·∫©y n·ªôi dung l√™n tr√™n
        layout.addStretch()
        
        scroll.setWidget(content_widget)
        
        # Layout ch√≠nh c·ªßa tab
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(scroll)
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "üé¨ T·∫°o Video")
    
    def create_voice_studio_tab(self):
        """T·∫°o tab Voice Studio v·ªõi enhanced features"""
        voice_studio_widget = QWidget()
        layout = QVBoxLayout()
        
        # Title
        title = QLabel("üé≠ Voice Studio - T·∫°o voice cho script AI")
        title.setFont(QFont("San Francisco", 16, QFont.Bold))
        title.setStyleSheet("color: #007AFF; margin: 10px;")
        layout.addWidget(title)
        
        # === ENHANCED: Multi-file Import Section ===
        import_group = QGroupBox("üì• Import Script Data (Enhanced Multi-File Support)")
        import_layout = QVBoxLayout()
        
        # Data source selection
        source_layout = QHBoxLayout()
        source_layout.addWidget(QLabel("Ngu·ªìn d·ªØ li·ªáu:"))
        
        self.data_source_combo = QComboBox()
        self.data_source_combo.addItem("üìÅ Import t·ª´ file JSON", "file")
        self.data_source_combo.addItem("üìÅ Import nhi·ªÅu file JSON (Multi-merge)", "multi_file")  # NEW
        self.data_source_combo.addItem("üîÑ S·ª≠ d·ª•ng data t·ª´ tab T·∫°o Video", "generated")
        self.data_source_combo.addItem("‚úèÔ∏è Nh·∫≠p th·ªß c√¥ng", "manual")
        self.data_source_combo.currentTextChanged.connect(self.switch_data_source)
        
        source_layout.addWidget(self.data_source_combo)
        source_layout.addStretch()
        import_layout.addLayout(source_layout)
        
        # === NEW: Template Mode Selection ===
        template_group = QGroupBox("üéØ AI Template Mode (Token Optimization)")
        template_layout = QHBoxLayout()
        
        template_layout.addWidget(QLabel("Template Mode:"))
        self.template_mode_combo = QComboBox()
        self.template_mode_combo.addItem("üèÉ‚Äç‚ôÇÔ∏è RAPID Mode (~150 tokens) - Compact", "rapid")
        self.template_mode_combo.addItem("üìù STANDARD Mode (~400 tokens) - Balanced", "standard") 
        self.template_mode_combo.addItem("üìö DETAILED Mode (~800 tokens) - Full Guide", "detailed")
        self.template_mode_combo.setCurrentText("üìù STANDARD Mode (~400 tokens) - Balanced")
        self.template_mode_combo.currentTextChanged.connect(self.update_token_preview)
        
        template_layout.addWidget(self.template_mode_combo)
        template_layout.addStretch()
        
        # Token preview
        self.token_preview_label = QLabel("üí° Ti·∫øt ki·ªám: +1100 tokens cho story content")
        self.token_preview_label.setStyleSheet("color: #28CD41; font-weight: bold;")
        template_layout.addWidget(self.token_preview_label)
        
        # === NEW: AI Request Form Button ===
        self.generate_ai_request_btn = QPushButton("üìã T·∫°o Request Form cho AI")
        self.generate_ai_request_btn.setStyleSheet("""
            QPushButton {
                background-color: #5856D6;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 6px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #4B49C8;
            }
        """)
        self.generate_ai_request_btn.clicked.connect(self.generate_ai_request_form)
        self.generate_ai_request_btn.setToolTip("T·∫°o template form theo mode ƒë√£ ch·ªçn ƒë·ªÉ request AI t·∫°o JSON script")
        template_layout.addWidget(self.generate_ai_request_btn)
        
        template_group.setLayout(template_layout)
        import_layout.addWidget(template_group)
        
        # File import controls
        file_layout = QHBoxLayout()
        self.import_file_btn = QPushButton("üìÅ Ch·ªçn file JSON")
        self.import_file_btn.clicked.connect(self.import_script_file)
        
        # === NEW: Multi-file import button ===
        self.import_multi_files_btn = QPushButton("üìÇ Import nhi·ªÅu file JSON")
        self.import_multi_files_btn.clicked.connect(self.import_multiple_script_files)
        self.import_multi_files_btn.setVisible(False)  # Hidden initially
        
        self.load_generated_btn = QPushButton("üîÑ Load t·ª´ tab T·∫°o Video")
        self.load_generated_btn.clicked.connect(self.load_generated_script_data)
        self.load_generated_btn.setVisible(False)
        
        file_layout.addWidget(self.import_file_btn)
        file_layout.addWidget(self.import_multi_files_btn)  # NEW
        file_layout.addWidget(self.load_generated_btn)
        file_layout.addStretch()
        
        import_layout.addLayout(file_layout)
        
        # File status
        file_status_layout = QHBoxLayout()
        file_status_layout.addWidget(QLabel("Imported file:"))
        self.imported_file_label = QLabel("Ch∆∞a import file n√†o")
        self.imported_file_label.setStyleSheet("color: #8E8E93;")
        file_status_layout.addWidget(self.imported_file_label)
        file_status_layout.addStretch()
        import_layout.addLayout(file_status_layout)
        
        # Generated data section
        self.generated_data_widget = QWidget()
        generated_layout = QVBoxLayout()
        generated_layout.setContentsMargins(0, 0, 0, 0)
        
        generated_info = QLabel("üîÑ S·ª≠ d·ª•ng script data ƒë√£ ƒë∆∞·ª£c t·∫°o t·ª´ tab 'T·∫°o Video'")
        generated_info.setStyleSheet("color: #007AFF; font-weight: bold;")
        generated_layout.addWidget(generated_info)
        
        self.use_generated_btn = QPushButton("üîÑ Load Data t·ª´ tab T·∫°o Video")
        self.use_generated_btn.clicked.connect(self.load_generated_script_data)
        generated_layout.addWidget(self.use_generated_btn)
        
        self.generated_data_widget.setLayout(generated_layout)
        self.generated_data_widget.setVisible(False)
        import_layout.addWidget(self.generated_data_widget)
        
        # Manual input section
        self.manual_input_widget = QWidget()
        manual_layout = QVBoxLayout()
        manual_layout.setContentsMargins(0, 0, 0, 0)
        
        manual_layout.addWidget(QLabel("‚úèÔ∏è Nh·∫≠p JSON script:"))
        self.manual_script_input = QTextEdit()
        self.manual_script_input.setPlaceholderText("Paste JSON script v√†o ƒë√¢y...")
        self.manual_script_input.setMaximumHeight(120)
        manual_layout.addWidget(self.manual_script_input)
        
        self.parse_manual_btn = QPushButton("‚úÖ Parse JSON")
        self.parse_manual_btn.clicked.connect(self.parse_manual_script)
        manual_layout.addWidget(self.parse_manual_btn)
        
        self.manual_input_widget.setLayout(manual_layout)
        self.manual_input_widget.setVisible(False)
        import_layout.addWidget(self.manual_input_widget)
        
        import_group.setLayout(import_layout)
        layout.addWidget(import_group)
        
        # === NEW: Template Usage Guide ===
        guide_group = QGroupBox("üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng Template Modes")
        guide_layout = QVBoxLayout()
        
        guide_text = QLabel("""
<b>üèÉ‚Äç‚ôÇÔ∏è RAPID Mode:</b> Cho stories ƒë∆°n gi·∫£n, t·∫≠p trung v√†o n·ªôi dung. Ti·∫øt ki·ªám token t·ªëi ƒëa.<br/>
<b>üìù STANDARD Mode:</b> C√¢n b·∫±ng gi·ªØa format v√† content. Ph√π h·ª£p cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p.<br/>
<b>üìö DETAILED Mode:</b> Cho stories ph·ª©c t·∫°p v·ªõi nhi·ªÅu t√≠nh nƒÉng cinematic v√† advanced settings.
        """)
        guide_text.setWordWrap(True)
        guide_text.setStyleSheet("color: #666; font-size: 12px; padding: 8px;")
        guide_layout.addWidget(guide_text)
        
        guide_group.setLayout(guide_layout)
        layout.addWidget(guide_group)
        
        # Group 2: Script Overview
        overview_group = QGroupBox("üìã Script Overview")
        overview_layout = QVBoxLayout()
        overview_layout.setSpacing(8)
        
        # Script info
        self.script_info_label = QLabel("Ch∆∞a load script data")
        self.script_info_label.setStyleSheet("color: #666; font-style: italic;")
        overview_layout.addWidget(self.script_info_label)
        
        # Characters list
        characters_layout = QHBoxLayout()
        characters_layout.addWidget(QLabel("Nh√¢n v·∫≠t:"))
        self.characters_label = QLabel("Ch∆∞a c√≥ data")
        self.characters_label.setStyleSheet("font-weight: bold; color: #007AFF;")
        characters_layout.addWidget(self.characters_label)
        characters_layout.addStretch()
        overview_layout.addLayout(characters_layout)
        
        # Segments count
        segments_layout = QHBoxLayout()
        segments_layout.addWidget(QLabel("S·ªë segments:"))
        self.segments_count_label = QLabel("0")
        self.segments_count_label.setStyleSheet("font-weight: bold; color: #007AFF;")
        segments_layout.addWidget(self.segments_count_label)
        segments_layout.addStretch()
        overview_layout.addLayout(segments_layout)
        
        overview_group.setLayout(overview_layout)
        layout.addWidget(overview_group)
        
        # Group 4: Advanced Chatterbox Controls (Manual Configuration)
        chatterbox_group = QGroupBox("üéõÔ∏è C·∫•u h√¨nh Chatterbox TTS chi ti·∫øt (N√¢ng cao)")
        chatterbox_layout = QVBoxLayout()
        chatterbox_layout.setSpacing(8)
        
        # Enable/disable toggle
        chatterbox_controls_layout = QHBoxLayout()
        self.enable_chatterbox_manual = QCheckBox("S·ª≠ d·ª•ng c·∫•u h√¨nh th·ªß c√¥ng cho Chatterbox TTS")
        self.enable_chatterbox_manual.toggled.connect(self.toggle_chatterbox_manual_controls)
        chatterbox_controls_layout.addWidget(self.enable_chatterbox_manual)
        
        # Auto emotion mapping toggle
        self.enable_emotion_mapping = QCheckBox("üé≠ T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh c·∫£m x√∫c theo script")
        self.enable_emotion_mapping.setChecked(True)  # Default enabled
        self.enable_emotion_mapping.setToolTip("T·ª± ƒë·ªông map emotion labels (happy, sad, excited...) th√†nh emotion exaggeration values")
        chatterbox_controls_layout.addWidget(self.enable_emotion_mapping)
        
        chatterbox_controls_layout.addStretch()
        chatterbox_layout.addLayout(chatterbox_controls_layout)
        
        # Manual controls container
        self.chatterbox_manual_widget = QWidget()
        chatterbox_manual_layout = QVBoxLayout()
        chatterbox_manual_layout.setContentsMargins(20, 10, 10, 10)
        
        # Character-specific settings ONLY (X√ìA GLOBAL CONTROLS)
        char_specific_label = QLabel("üé≠ C·∫•u h√¨nh ri√™ng cho t·ª´ng nh√¢n v·∫≠t:")
        char_specific_label.setStyleSheet("font-weight: bold; margin-top: 10px;")
        chatterbox_manual_layout.addWidget(char_specific_label)
        
        # Character settings table
        self.character_settings_table = QTableWidget()
        self.character_settings_table.setColumnCount(9)  # Gi·ªØ nguy√™n 9 columns
        self.character_settings_table.setHorizontalHeaderLabels([
            "Nh√¢n v·∫≠t", "Emotion", "Speed", "CFG Weight", "Mode", "Voice/Prompt/Clone", "Quick", "Status", "Preview"
        ])
        self.character_settings_table.horizontalHeader().setStretchLastSection(False)
        self.character_settings_table.setMaximumHeight(200)  # TƒÉng height cho table
        
        # Set column widths
        header = self.character_settings_table.horizontalHeader()
        header.resizeSection(0, 120)  # Character name
        header.resizeSection(1, 80)   # Emotion
        header.resizeSection(2, 80)   # Speed  
        header.resizeSection(3, 80)   # CFG Weight
        header.resizeSection(4, 150)  # Mode
        header.resizeSection(5, 150)  # Voice/Prompt/Clone
        header.resizeSection(6, 60)   # Quick
        header.resizeSection(7, 60)   # Status
        header.resizeSection(8, 60)   # Preview
        
        chatterbox_manual_layout.addWidget(self.character_settings_table)
        
        # üí° VOICE GENERATION HELP
        help_layout = QVBoxLayout()
        help_layout.addWidget(QLabel("üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:"))
        
        help_text = QLabel("""
‚Ä¢ <b>Per-Character Settings</b>: M·ªói nh√¢n v·∫≠t c√≥ th√¥ng s·ªë ri√™ng (Emotion, Speed, CFG Weight)
‚Ä¢ <b>Voice Mode</b>: Ch·ªçn Voice Selection ho·∫∑c Voice Clone cho t·ª´ng nh√¢n v·∫≠t
‚Ä¢ <b>Quick Actions</b>: Nh·∫•n n√∫t üîß ƒë·ªÉ t·ªëi ∆∞u th√¥ng s·ªë t·ª± ƒë·ªông
‚Ä¢ <b>Preview</b>: Nh·∫•n n√∫t üéß ƒë·ªÉ nghe th·ª≠ gi·ªçng v·ªõi settings hi·ªán t·∫°i
        """)
        help_text.setWordWrap(True)
        help_text.setStyleSheet("color: #666; font-size: 12px; padding: 8px; background-color: #f8f8f8; border-radius: 4px;")
        help_layout.addWidget(help_text)
        
        chatterbox_manual_layout.addLayout(help_layout)
        
        # Note: Removed "Apply to All Characters" preset buttons 
        # since per-character settings in table provide better control
        
        self.chatterbox_manual_widget.setLayout(chatterbox_manual_layout)
        self.chatterbox_manual_widget.setVisible(False)  # Hidden by default
        chatterbox_layout.addWidget(self.chatterbox_manual_widget)
        
        chatterbox_group.setLayout(chatterbox_layout)
        layout.addWidget(chatterbox_group)
        
        # Group 5: Generation Controls
        generation_group = QGroupBox("üéôÔ∏è T·∫°o Audio")
        generation_layout = QVBoxLayout()
        generation_layout.setSpacing(8)
        
        # TTS Provider - CH·ªà CHATTERBOX
        provider_layout = QHBoxLayout()
        provider_layout.addWidget(QLabel("TTS Provider:"))
        
        provider_info = QLabel("ü§ñ Chatterbox TTS (AI Voice Cloning)")
        provider_info.setStyleSheet("font-weight: bold; color: #007AFF; padding: 4px;")
        provider_layout.addWidget(provider_info)
        
        provider_layout.addStretch()
        generation_layout.addLayout(provider_layout)
        
        # Output settings
        output_layout = QHBoxLayout()
        output_layout.addWidget(QLabel("Th∆∞ m·ª•c output:"))
        
        self.voice_output_input = QLineEdit()
        self.voice_output_input.setPlaceholderText("./voice_studio_output/")
        self.voice_output_input.setReadOnly(True)
        output_layout.addWidget(self.voice_output_input)
        
        self.select_voice_output_btn = QPushButton("üìÅ")
        self.select_voice_output_btn.clicked.connect(self.select_voice_output_folder)
        self.select_voice_output_btn.setMaximumWidth(40)
        output_layout.addWidget(self.select_voice_output_btn)
        
        generation_layout.addLayout(output_layout)
        
        # Generation buttons
        generation_buttons_layout = QHBoxLayout()
        
        self.generate_selected_btn = QPushButton("üé§ T·∫°o voice cho nh√¢n v·∫≠t ƒë√£ ch·ªçn")
        self.generate_selected_btn.clicked.connect(self.generate_selected_character_voice)
        self.generate_selected_btn.setEnabled(False)
        generation_buttons_layout.addWidget(self.generate_selected_btn)
        
        self.generate_all_btn = QPushButton("üé≠ T·∫°o voice cho t·∫•t c·∫£ nh√¢n v·∫≠t")
        self.generate_all_btn.clicked.connect(self.generate_all_voices)
        self.generate_all_btn.setEnabled(False)
        generation_buttons_layout.addWidget(self.generate_all_btn)
        
        generation_layout.addLayout(generation_buttons_layout)
        
        generation_group.setLayout(generation_layout)
        layout.addWidget(generation_group)
        
        # Group 6: Progress & Results
        progress_group = QGroupBox("üìä Ti·∫øn tr√¨nh & K·∫øt qu·∫£")
        progress_layout = QVBoxLayout()
        progress_layout.setSpacing(8)
        
        # Progress bar
        self.voice_progress_bar = QProgressBar()
        self.voice_progress_bar.setVisible(False)
        progress_layout.addWidget(self.voice_progress_bar)
        
        # Progress text
        self.voice_progress_text = QLabel("S·∫µn s√†ng t·∫°o voice")
        self.voice_progress_text.setStyleSheet("color: #666; font-style: italic;")
        progress_layout.addWidget(self.voice_progress_text)
        
        # Results area
        self.voice_results_text = QTextEdit()
        self.voice_results_text.setMaximumHeight(100)
        self.voice_results_text.setReadOnly(True)
        self.voice_results_text.setPlaceholderText("K·∫øt qu·∫£ t·∫°o voice s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y...")
        progress_layout.addWidget(self.voice_results_text)
        
        # Action buttons
        action_buttons_layout = QHBoxLayout()
        
        self.merge_audio_btn = QPushButton("üéµ G·ªôp Audio Files")
        self.merge_audio_btn.setStyleSheet("""
            QPushButton {
                background-color: #34C759;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 6px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #248A3D;
            }
        """)
        self.merge_audio_btn.clicked.connect(self.manual_merge_audio)
        self.merge_audio_btn.setToolTip("G·ªôp t·∫•t c·∫£ file audio th√†nh 1 cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh")
        action_buttons_layout.addWidget(self.merge_audio_btn)
        
        self.play_complete_audio_btn = QPushButton("‚ñ∂Ô∏è Nghe Cu·ªôc H·ªôi Tho·∫°i")
        self.play_complete_audio_btn.setStyleSheet("""
            QPushButton {
                background-color: #FF9500;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 6px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #CC7700;
            }
        """)
        self.play_complete_audio_btn.clicked.connect(self.play_complete_conversation)
        self.play_complete_audio_btn.setToolTip("Ph√°t cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh g·∫ßn nh·∫•t")
        action_buttons_layout.addWidget(self.play_complete_audio_btn)
        
        self.open_voice_folder_btn = QPushButton("üìÅ M·ªü th∆∞ m·ª•c output")
        self.open_voice_folder_btn.clicked.connect(self.open_voice_output_folder)
        action_buttons_layout.addWidget(self.open_voice_folder_btn)
        
        self.clear_voice_results_btn = QPushButton("üßπ X√≥a k·∫øt qu·∫£")
        self.clear_voice_results_btn.clicked.connect(self.clear_voice_results)
        action_buttons_layout.addWidget(self.clear_voice_results_btn)
        
        # Force Merge button - t·ªëi ∆∞u cho tr∆∞·ªùng h·ª£p script data kh√¥ng match
        self.force_merge_btn = QPushButton("üîß Force Merge All")
        self.force_merge_btn.setStyleSheet("""
            QPushButton {
                background-color: #007ACC;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 6px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #005999;
            }
        """)
        self.force_merge_btn.clicked.connect(self.force_merge_all_segments)
        self.force_merge_btn.setToolTip("G·ªôp t·∫•t c·∫£ file segment_*.mp3 c√≥ trong th∆∞ m·ª•c output (kh√¥ng c·∫ßn script data)")
        action_buttons_layout.addWidget(self.force_merge_btn)
        
        action_buttons_layout.addStretch()
        progress_layout.addLayout(action_buttons_layout)
        
        progress_group.setLayout(progress_layout)
        layout.addWidget(progress_group)
        
        # Initialize data
        self.voice_studio_script_data = None
        self.voice_mapping = {}
        self.character_chatterbox_settings = {}  # Store per-character settings
        self.voice_clone_folder = None
        
        # === SET UP MAIN TAB LAYOUT ===
        voice_studio_widget.setLayout(layout)
        
        # Use scroll area for the full content
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        scroll.setWidget(voice_studio_widget)
        
        # Main tab layout
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(scroll)
        
        tab = QWidget()
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "üéôÔ∏è Voice Studio")
    
    def create_projects_tab(self):
        """Tab qu·∫£n l√Ω projects v·ªõi layout t·ªëi ∆∞u cho MacOS"""
        tab = QWidget()
        
        # S·ª≠ d·ª•ng splitter ƒë·ªÉ chia ƒë√¥i m√†n h√¨nh
        splitter = QSplitter(Qt.Horizontal)
        
        # Panel tr√°i: Danh s√°ch projects
        left_panel = QWidget()
        left_layout = QVBoxLayout()
        left_layout.setContentsMargins(8, 8, 8, 8)
        left_layout.setSpacing(8)
        
        # Header v·ªõi n√∫t refresh
        header_layout = QHBoxLayout()
        header_layout.addWidget(QLabel("üìÅ Danh s√°ch d·ª± √°n"))
        header_layout.addStretch()
        refresh_btn = QPushButton("üîÑ")
        refresh_btn.setToolTip("L√†m m·ªõi danh s√°ch")
        refresh_btn.setMaximumWidth(40)
        refresh_btn.clicked.connect(self.refresh_projects)
        header_layout.addWidget(refresh_btn)
        left_layout.addLayout(header_layout)
        
        # Danh s√°ch projects
        self.projects_list = QListWidget()
        self.projects_list.itemClicked.connect(self.load_project_details)
        left_layout.addWidget(self.projects_list)
        
        left_panel.setLayout(left_layout)
        splitter.addWidget(left_panel)
        
        # Panel ph·∫£i: Chi ti·∫øt project
        right_panel = QWidget()
        right_layout = QVBoxLayout()
        right_layout.setContentsMargins(8, 8, 8, 8)
        right_layout.setSpacing(8)
        
        # Header chi ti·∫øt
        right_layout.addWidget(QLabel("üìã Chi ti·∫øt d·ª± √°n"))
        
        # Chi ti·∫øt project v·ªõi scroll
        details_scroll = QScrollArea()
        details_scroll.setWidgetResizable(True)
        details_scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        self.project_details = QTextEdit()
        self.project_details.setReadOnly(True)
        details_scroll.setWidget(self.project_details)
        right_layout.addWidget(details_scroll)
        
        # N√∫t actions
        actions_group = QGroupBox("üõ†Ô∏è Thao t√°c")
        actions_layout = QGridLayout()
        actions_layout.setSpacing(8)
        
        self.open_folder_btn = QPushButton("üìÅ M·ªü th∆∞ m·ª•c")
        self.open_folder_btn.clicked.connect(self.open_project_folder)
        actions_layout.addWidget(self.open_folder_btn, 0, 0)
        
        self.delete_project_btn = QPushButton("üóëÔ∏è X√≥a d·ª± √°n")
        self.delete_project_btn.clicked.connect(self.delete_project)
        self.delete_project_btn.setProperty("class", "danger")
        actions_layout.addWidget(self.delete_project_btn, 0, 1)
        
        actions_group.setLayout(actions_layout)
        right_layout.addWidget(actions_group)
        
        right_panel.setLayout(right_layout)
        splitter.addWidget(right_panel)
        
        # Thi·∫øt l·∫≠p t·ª∑ l·ªá splitter (40% - 60%)
        splitter.setSizes([400, 600])
        
        # Layout ch√≠nh c·ªßa tab
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(splitter)
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "üìÅ D·ª± √°n")
        
        # Load projects khi kh·ªüi t·∫°o
        self.refresh_projects()
    
    def create_settings_tab(self):
        """Tab c√†i ƒë·∫∑t v·ªõi layout t·ªëi ∆∞u cho MacOS"""
        tab = QWidget()
        
        # S·ª≠ d·ª•ng scroll area cho settings
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOff)
        
        content_widget = QWidget()
        layout = QVBoxLayout()
        layout.setSpacing(12)
        layout.setContentsMargins(16, 16, 16, 16)
        content_widget.setLayout(layout)
        
        # Group 1: API Keys cho AI Content
        ai_content_group = QGroupBox("üìù AI Sinh n·ªôi dung")
        ai_content_layout = QGridLayout()
        ai_content_layout.setSpacing(8)
        
        ai_content_layout.addWidget(QLabel("OpenAI API Key (GPT-4):"), 0, 0)
        self.openai_key_input = QLineEdit()
        self.openai_key_input.setEchoMode(QLineEdit.Password)
        self.openai_key_input.setPlaceholderText("sk-...")
        ai_content_layout.addWidget(self.openai_key_input, 0, 1)
        
        ai_content_layout.addWidget(QLabel("Claude API Key:"), 1, 0)
        self.claude_key_input = QLineEdit()
        self.claude_key_input.setEchoMode(QLineEdit.Password)
        self.claude_key_input.setPlaceholderText("sk-ant-...")
        ai_content_layout.addWidget(self.claude_key_input, 1, 1)
        
        ai_content_layout.addWidget(QLabel("DeepSeek API Key:"), 2, 0)
        self.deepseek_key_input = QLineEdit()
        self.deepseek_key_input.setEchoMode(QLineEdit.Password)
        self.deepseek_key_input.setPlaceholderText("sk-...")
        ai_content_layout.addWidget(self.deepseek_key_input, 2, 1)
        
        ai_content_group.setLayout(ai_content_layout)
        layout.addWidget(ai_content_group)
        
        # Group 2: API Keys cho Image Generation
        image_gen_group = QGroupBox("üé® AI T·∫°o ·∫£nh")
        image_gen_layout = QGridLayout()
        image_gen_layout.setSpacing(8)
        
        # DALL-E info
        dalle_info = QLabel("DALL-E (OpenAI) - d√πng chung key OpenAI")
        dalle_info.setStyleSheet("color: #666; font-style: italic; font-size: 11px;")
        image_gen_layout.addWidget(dalle_info, 0, 0, 1, 2)
        
        image_gen_layout.addWidget(QLabel("Midjourney API Key:"), 1, 0)
        self.midjourney_key_input = QLineEdit()
        self.midjourney_key_input.setEchoMode(QLineEdit.Password)
        image_gen_layout.addWidget(self.midjourney_key_input, 1, 1)
        
        image_gen_layout.addWidget(QLabel("Stability AI Key:"), 2, 0)
        self.stability_key_input = QLineEdit()
        self.stability_key_input.setEchoMode(QLineEdit.Password)
        self.stability_key_input.setPlaceholderText("sk-...")
        image_gen_layout.addWidget(self.stability_key_input, 2, 1)
        
        image_gen_group.setLayout(image_gen_layout)
        layout.addWidget(image_gen_group)
        
        # Group 3: API Keys cho Text-to-Speech
        tts_group = QGroupBox("üé§ Text-to-Speech")
        tts_layout = QGridLayout()
        tts_layout.setSpacing(8)
        
        tts_layout.addWidget(QLabel("ElevenLabs API Key:"), 0, 0)
        self.elevenlabs_key_input = QLineEdit()
        self.elevenlabs_key_input.setEchoMode(QLineEdit.Password)
        self.elevenlabs_key_input.setPlaceholderText("sk_...")
        tts_layout.addWidget(self.elevenlabs_key_input, 0, 1)
        
        tts_layout.addWidget(QLabel("Google Cloud TTS Key:"), 1, 0)
        self.google_tts_key_input = QLineEdit()
        self.google_tts_key_input.setEchoMode(QLineEdit.Password)
        tts_layout.addWidget(self.google_tts_key_input, 1, 1)
        
        tts_layout.addWidget(QLabel("Azure Speech Key:"), 2, 0)
        self.azure_speech_key_input = QLineEdit()
        self.azure_speech_key_input.setEchoMode(QLineEdit.Password)
        tts_layout.addWidget(self.azure_speech_key_input, 2, 1)
        
        # Chatterbox TTS Device Info
        chatterbox_info = QLabel("ü§ñ Chatterbox TTS: Auto-detect CUDA/MPS/CPU")
        chatterbox_info.setStyleSheet("color: #007AFF; font-weight: bold; font-size: 12px;")
        tts_layout.addWidget(chatterbox_info, 3, 0, 1, 2)
        
        # Device status button
        self.chatterbox_device_btn = QPushButton("üì± Ki·ªÉm tra Device")
        self.chatterbox_device_btn.clicked.connect(self.show_chatterbox_device_info)
        tts_layout.addWidget(self.chatterbox_device_btn, 4, 0)
        
        # Clear cache button
        self.chatterbox_clear_btn = QPushButton("üßπ X√≥a Cache")
        self.chatterbox_clear_btn.clicked.connect(self.clear_chatterbox_cache)
        tts_layout.addWidget(self.chatterbox_clear_btn, 4, 1)
        
        tts_group.setLayout(tts_layout)
        layout.addWidget(tts_group)
        
        # Group 4: Provider Selection
        providers_group = QGroupBox("‚öôÔ∏è Ch·ªçn nh√† cung c·∫•p")
        providers_layout = QGridLayout()
        providers_layout.setSpacing(8)
        
        providers_layout.addWidget(QLabel("AI Sinh n·ªôi dung:"), 0, 0)
        self.content_provider_combo = QComboBox()
        self.content_provider_combo.addItems(self.api_manager.get_available_content_providers())
        providers_layout.addWidget(self.content_provider_combo, 0, 1)
        
        providers_layout.addWidget(QLabel("AI T·∫°o ·∫£nh:"), 1, 0)
        self.image_provider_combo = QComboBox()
        self.image_provider_combo.addItems(self.api_manager.get_available_image_providers())
        providers_layout.addWidget(self.image_provider_combo, 1, 1)
        
        providers_layout.addWidget(QLabel("Text-to-Speech:"), 2, 0)
        self.tts_provider_combo = QComboBox()
        self.tts_provider_combo.addItems(self.api_manager.get_available_tts_providers())
        providers_layout.addWidget(self.tts_provider_combo, 2, 1)
        
        providers_group.setLayout(providers_layout)
        layout.addWidget(providers_group)
        
        # Group 5: Video Settings
        video_group = QGroupBox("üé¨ C√†i ƒë·∫∑t Video")
        video_layout = QGridLayout()
        video_layout.setSpacing(8)
        
        video_layout.addWidget(QLabel("ƒê·ªô ph√¢n gi·∫£i:"), 0, 0)
        self.resolution_combo = QComboBox()
        self.resolution_combo.addItems(["1920x1080", "1280x720", "1080x1080"])
        video_layout.addWidget(self.resolution_combo, 0, 1)
        
        video_layout.addWidget(QLabel("FPS:"), 1, 0)
        self.fps_spinbox = QSpinBox()
        self.fps_spinbox.setRange(15, 60)
        self.fps_spinbox.setValue(25)
        video_layout.addWidget(self.fps_spinbox, 1, 1)
        
        video_group.setLayout(video_layout)
        layout.addWidget(video_group)
        
        # Group 6: Actions
        actions_group = QGroupBox("üõ†Ô∏è Thao t√°c")
        actions_layout = QGridLayout()
        actions_layout.setSpacing(8)
        
        save_settings_btn = QPushButton("üíæ L∆∞u c√†i ƒë·∫∑t")
        save_settings_btn.clicked.connect(self.save_settings)
        actions_layout.addWidget(save_settings_btn, 0, 0)
        
        check_api_btn = QPushButton("üîç Ki·ªÉm tra API")
        check_api_btn.clicked.connect(self.check_api_status)
        actions_layout.addWidget(check_api_btn, 0, 1)
        
        refresh_providers_btn = QPushButton("üîÑ L√†m m·ªõi")
        refresh_providers_btn.clicked.connect(self.refresh_providers)
        actions_layout.addWidget(refresh_providers_btn, 1, 0, 1, 2)
        
        actions_group.setLayout(actions_layout)
        layout.addWidget(actions_group)
        
        # Th√™m stretch ƒë·ªÉ ƒë·∫©y n·ªôi dung l√™n tr√™n
        layout.addStretch()
        
        scroll.setWidget(content_widget)
        
        # Layout ch√≠nh c·ªßa tab
        tab_layout = QVBoxLayout()
        tab_layout.setContentsMargins(0, 0, 0, 0)
        tab_layout.addWidget(scroll)
        tab.setLayout(tab_layout)
        
        self.tabs.addTab(tab, "‚öôÔ∏è C√†i ƒë·∫∑t")
        
        # Load c√†i ƒë·∫∑t hi·ªán t·∫°i t·ª´ file config.env
        self.load_current_settings()
        
        # Update API status when settings change (safe call)
        self.update_api_status_indicator()
    
    def start_video_generation(self):
        """B·∫Øt ƒë·∫ßu t·∫°o video"""
        prompt = self.prompt_input.toPlainText().strip()
        if not prompt:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng nh·∫≠p prompt!")
            return
        
        project_name = self.project_name_input.text().strip() or "video_project"
        
        # L·∫•y preset hi·ªáu ·ª©ng
        preset_key = self.effects_preset_combo.currentData()
        if preset_key:
            effects = EffectsPresets.get_preset_by_name(preset_key)
        else:
            # Fallback to manual settings
            effects = {
                "zoom": self.zoom_checkbox.isChecked(),
                "transitions": {"crossfade": True} if self.transitions_checkbox.isChecked() else None
            }
        
        # Disable n√∫t v√† hi·ªán progress
        self.generate_video_btn.setEnabled(False)
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 8)
        
        # Ki·ªÉm tra ch·∫ø ƒë·ªô ·∫£nh th·ªß c√¥ng
        use_custom_images = self.manual_images_radio.isChecked()
        custom_images_folder = getattr(self, 'selected_images_folder', None) if use_custom_images else None
        
        if use_custom_images and not custom_images_folder:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng ch·ªçn th∆∞ m·ª•c ch·ª©a ·∫£nh!")
            return
        
        # L·∫•y th√¥ng tin gi·ªçng ƒë·ªçc v√† th∆∞ m·ª•c
        voice_name = self.voice_combo.currentText().split(' ')[0]  # L·∫•y t√™n gi·ªçng (vd: vi-VN-Standard-A)
        project_folder = self.project_folder_input.text() or None
        
        # T·∫°o thread
        self.generation_thread = VideoGenerationThread(
            prompt, project_name, effects, use_custom_images, custom_images_folder,
            voice_name, project_folder
        )
        self.generation_thread.progress_updated.connect(self.update_progress)
        self.generation_thread.finished.connect(self.generation_finished)
        self.generation_thread.start()
    
    def update_progress(self, step, message):
        """C·∫≠p nh·∫≠t progress"""
        self.progress_group.setVisible(True)
        self.progress_bar.setVisible(True)
        self.progress_label.setVisible(True)
        self.progress_bar.setValue(step)
        self.progress_label.setText(message)
    
    def generation_finished(self, result):
        """Ho√†n th√†nh t·∫°o video"""
        self.generate_video_btn.setEnabled(True)
        self.progress_bar.setVisible(False)
        
        if result["success"]:
            self.progress_label.setText(f"Ho√†n th√†nh! Video: {result['final_video_path']}")
            QMessageBox.information(self, "Th√†nh c√¥ng", 
                                  f"Video ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!\nProject: {result['project_id']}\nƒê∆∞·ªùng d·∫´n: {result['final_video_path']}")
            self.refresh_projects()
        else:
            self.progress_label.setText(f"L·ªói: {result['error']}")
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ t·∫°o video:\n{result['error']}")
    
    def refresh_projects(self):
        """L√†m m·ªõi danh s√°ch projects"""
        self.projects_list.clear()
        result = self.pipeline.project_manager.list_projects()
        if result["success"]:
            for project in result["projects"]:
                item_text = f"{project['name']} ({project['status']}) - {project['created_at'][:10]}"
                self.projects_list.addItem(item_text)
                # L∆∞u project_id v√†o item
                item = self.projects_list.item(self.projects_list.count() - 1)
                item.setData(1, project['id'])
    
    def load_project_details(self, item):
        """Load chi ti·∫øt project"""
        project_id = item.data(1)
        self.current_project_id = project_id
        
        result = self.pipeline.project_manager.load_project(project_id)
        if result["success"]:
            data = result["data"]
            details = f"""
Project: {data['name']}
ID: {data['id']}
Prompt: {data['prompt']}
Status: {data['status']}
Segments: {len(data['segments'])}
Created: {data['created_at']}
            """
            self.project_details.setText(details.strip())
    
    def open_project_folder(self):
        """M·ªü th∆∞ m·ª•c project"""
        if not self.current_project_id:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng ch·ªçn project!")
            return
        
        project_path = self.pipeline.project_manager.get_project_path(self.current_project_id)
        os.system(f"open '{project_path}'" if sys.platform == "darwin" else f"explorer '{project_path}'")
    
    def delete_project(self):
        """X√≥a project"""
        if not self.current_project_id:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng ch·ªçn project!")
            return
        
        reply = QMessageBox.question(self, "X√°c nh·∫≠n", "B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a project n√†y?")
        if reply == QMessageBox.Yes:
            result = self.pipeline.project_manager.delete_project(self.current_project_id)
            if result["success"]:
                QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ x√≥a project!")
                self.refresh_projects()
                self.project_details.clear()
                self.current_project_id = None
            else:
                QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ x√≥a: {result['error']}")
    
    def save_settings(self):
        """L∆∞u c√†i ƒë·∫∑t"""
        try:
            # ƒê·ªçc file config.env hi·ªán t·∫°i
            config_path = 'config.env'
            config_data = {}
            
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if '=' in line and not line.startswith('#'):
                            key, value = line.split('=', 1)
                            config_data[key.strip()] = value.strip()
            
            # C·∫≠p nh·∫≠t API keys t·ª´ UI
            if self.openai_key_input.text().strip():
                config_data['OPENAI_API_KEY'] = self.openai_key_input.text().strip()
            if self.claude_key_input.text().strip():
                config_data['CLAUDE_API_KEY'] = self.claude_key_input.text().strip()
            if self.deepseek_key_input.text().strip():
                config_data['DEEPSEEK_API_KEY'] = self.deepseek_key_input.text().strip()
            if self.midjourney_key_input.text().strip():
                config_data['MIDJOURNEY_API_KEY'] = self.midjourney_key_input.text().strip()
            if self.stability_key_input.text().strip():
                config_data['STABILITY_AI_KEY'] = self.stability_key_input.text().strip()
            if self.elevenlabs_key_input.text().strip():
                config_data['ELEVENLABS_API_KEY'] = self.elevenlabs_key_input.text().strip()
            if self.google_tts_key_input.text().strip():
                config_data['GOOGLE_TTS_API_KEY'] = self.google_tts_key_input.text().strip()
            if self.azure_speech_key_input.text().strip():
                config_data['AZURE_SPEECH_KEY'] = self.azure_speech_key_input.text().strip()
            
            # C·∫≠p nh·∫≠t provider preferences
            config_data['CONTENT_PROVIDER'] = self.content_provider_combo.currentText()
            config_data['IMAGE_PROVIDER'] = self.image_provider_combo.currentText()
            config_data['TTS_PROVIDER'] = self.tts_provider_combo.currentText()
            
            # C·∫≠p nh·∫≠t video settings
            config_data['VIDEO_RESOLUTION'] = self.resolution_combo.currentText()
            config_data['VIDEO_FPS'] = str(self.fps_spinbox.value())
            
            # Ghi l·∫°i file config.env
            with open(config_path, 'w', encoding='utf-8') as f:
                f.write("# ===========================================\n")
                f.write("# API KEYS - Auto-generated from settings\n")
                f.write("# ===========================================\n\n")
                
                f.write("# AI Content Generation\n")
                f.write(f"OPENAI_API_KEY={config_data.get('OPENAI_API_KEY', '')}\n")
                f.write(f"CLAUDE_API_KEY={config_data.get('CLAUDE_API_KEY', '')}\n")
                f.write(f"DEEPSEEK_API_KEY={config_data.get('DEEPSEEK_API_KEY', '')}\n\n")
                
                f.write("# Image Generation\n")
                f.write(f"MIDJOURNEY_API_KEY={config_data.get('MIDJOURNEY_API_KEY', '')}\n")
                f.write(f"STABILITY_AI_KEY={config_data.get('STABILITY_AI_KEY', '')}\n\n")
                
                f.write("# Text-to-Speech\n")
                f.write(f"ELEVENLABS_API_KEY={config_data.get('ELEVENLABS_API_KEY', '')}\n")
                f.write(f"GOOGLE_TTS_API_KEY={config_data.get('GOOGLE_TTS_API_KEY', '')}\n")
                f.write(f"AZURE_SPEECH_KEY={config_data.get('AZURE_SPEECH_KEY', '')}\n")
                f.write(f"AZURE_SPEECH_REGION={config_data.get('AZURE_SPEECH_REGION', 'eastus')}\n\n")
                
                f.write("# ===========================================\n")
                f.write("# PROVIDER PREFERENCES\n")
                f.write("# ===========================================\n")
                f.write(f"CONTENT_PROVIDER={config_data.get('CONTENT_PROVIDER', 'OpenAI GPT-4')}\n")
                f.write(f"IMAGE_PROVIDER={config_data.get('IMAGE_PROVIDER', 'DALL-E (OpenAI)')}\n")
                f.write(f"TTS_PROVIDER={config_data.get('TTS_PROVIDER', 'Google TTS (Free)')}\n\n")
                
                f.write("# ===========================================\n")
                f.write("# SETTINGS\n")
                f.write("# ===========================================\n")
                f.write(f"DEFAULT_VOICE=alloy\n")
                f.write(f"DEFAULT_LANGUAGE=vi\n")
                f.write(f"VIDEO_RESOLUTION={config_data.get('VIDEO_RESOLUTION', '1920x1080')}\n")
                f.write(f"VIDEO_FPS={config_data.get('VIDEO_FPS', '25')}\n")
            
            # Reload API manager ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi
            self.api_manager = APIManager()
            self.refresh_providers()
            
            QMessageBox.information(self, "Th√†nh c√¥ng", "C√†i ƒë·∫∑t ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng!\nAPI keys ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t v√†o config.env")
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ l∆∞u c√†i ƒë·∫∑t:\n{str(e)}")
    
    def load_current_settings(self):
        """Load c√†i ƒë·∫∑t hi·ªán t·∫°i t·ª´ file config.env"""
        try:
            config_path = 'config.env'
            if not os.path.exists(config_path):
                return
            
            with open(config_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if '=' in line and not line.startswith('#'):
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        
                        # Load API keys
                        if key == 'OPENAI_API_KEY' and value and value != 'your_openai_api_key_here':
                            self.openai_key_input.setText(value)
                        elif key == 'CLAUDE_API_KEY' and value and value != 'your_claude_api_key_here':
                            self.claude_key_input.setText(value)
                        elif key == 'DEEPSEEK_API_KEY' and value and value != 'your_deepseek_api_key_here':
                            self.deepseek_key_input.setText(value)
                        elif key == 'MIDJOURNEY_API_KEY' and value and value != 'your_midjourney_api_key_here':
                            self.midjourney_key_input.setText(value)
                        elif key == 'STABILITY_AI_KEY' and value and value != 'your_stability_ai_key_here':
                            self.stability_key_input.setText(value)
                        elif key == 'ELEVENLABS_API_KEY' and value and value != 'your_elevenlabs_api_key_here':
                            self.elevenlabs_key_input.setText(value)
                        elif key == 'GOOGLE_TTS_API_KEY' and value and value != 'your_google_tts_api_key_here':
                            self.google_tts_key_input.setText(value)
                        elif key == 'AZURE_SPEECH_KEY' and value and value != 'your_azure_speech_key_here':
                            self.azure_speech_key_input.setText(value)
                        
                        # Load provider preferences
                        elif key == 'CONTENT_PROVIDER' and value:
                            index = self.content_provider_combo.findText(value)
                            if index >= 0:
                                self.content_provider_combo.setCurrentIndex(index)
                        elif key == 'IMAGE_PROVIDER' and value:
                            index = self.image_provider_combo.findText(value)
                            if index >= 0:
                                self.image_provider_combo.setCurrentIndex(index)
                        elif key == 'TTS_PROVIDER' and value:
                            index = self.tts_provider_combo.findText(value)
                            if index >= 0:
                                self.tts_provider_combo.setCurrentIndex(index)
                        
                        # Load video settings
                        elif key == 'VIDEO_RESOLUTION' and value:
                            index = self.resolution_combo.findText(value)
                            if index >= 0:
                                self.resolution_combo.setCurrentIndex(index)
                        elif key == 'VIDEO_FPS' and value:
                            try:
                                fps = int(value)
                                self.fps_spinbox.setValue(fps)
                            except ValueError:
                                pass
        except Exception as e:
            print(f"L·ªói load c√†i ƒë·∫∑t: {str(e)}")
    
    def load_prompt_suggestions(self):
        """Load prompt suggestions theo danh m·ª•c"""
        self.prompt_suggestions_list.clear()
        self.prompt_suggestions_list.addItem("-- Ch·ªçn prompt m·∫´u --")
        
        current_data = self.category_combo.currentData()
        if current_data:
            categories = PromptTemplates.get_all_categories()
            if current_data in categories:
                prompts = categories[current_data]["prompts"]
                for prompt in prompts:
                    # Truncate long prompts for display
                    display_text = prompt[:80] + "..." if len(prompt) > 80 else prompt
                    self.prompt_suggestions_list.addItem(display_text, prompt)
    
    def use_suggested_prompt(self):
        """S·ª≠ d·ª•ng prompt ƒë∆∞·ª£c g·ª£i √Ω"""
        current_data = self.prompt_suggestions_list.currentData()
        if current_data:
            self.prompt_input.setPlainText(current_data)
    
    def get_random_prompt(self):
        """L·∫•y prompt ng·∫´u nhi√™n"""
        random_prompt = PromptTemplates.get_random_prompt()
        self.prompt_input.setPlainText(random_prompt)
    
    def toggle_image_mode(self):
        """Chuy·ªÉn ƒë·ªïi ch·∫ø ƒë·ªô t·∫°o ·∫£nh"""
        manual_mode = self.manual_images_radio.isChecked()
        self.select_images_btn.setEnabled(manual_mode)
        
        if manual_mode:
            self.auto_generate_radio.setChecked(False)
        else:
            self.auto_generate_radio.setChecked(True)
    
    def select_images_folder(self):
        """Ch·ªçn th∆∞ m·ª•c ch·ª©a ·∫£nh"""
        folder_path = QFileDialog.getExistingDirectory(
            self, "Ch·ªçn th∆∞ m·ª•c ch·ª©a ·∫£nh", ""
        )
        
        if folder_path:
            # Ki·ªÉm tra ·∫£nh trong th∆∞ m·ª•c
            image_files = self.get_image_files_in_folder(folder_path)
            
            if image_files:
                self.selected_images_folder = folder_path
                self.selected_images_label.setText(
                    f"ƒê√£ ch·ªçn: {folder_path} ({len(image_files)} ·∫£nh)"
                )
                self.selected_images_label.setStyleSheet("color: green;")
            else:
                QMessageBox.warning(
                    self, "C·∫£nh b√°o", 
                    "Th∆∞ m·ª•c kh√¥ng ch·ª©a ·∫£nh h·ª£p l·ªá!\nH·ªó tr·ª£: .jpg, .jpeg, .png, .bmp, .gif, .webp"
                )
    
    def get_image_files_in_folder(self, folder_path):
        """L·∫•y danh s√°ch file ·∫£nh trong th∆∞ m·ª•c"""
        valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp']
        image_files = []
        
        try:
            for file in os.listdir(folder_path):
                if any(file.lower().endswith(ext) for ext in valid_extensions):
                    image_files.append(os.path.join(folder_path, file))
        except Exception:
            pass
        
        return sorted(image_files)
    
    def check_api_status(self):
        """Ki·ªÉm tra tr·∫°ng th√°i t·∫•t c·∫£ API"""
        status = self.api_manager.get_provider_status()
        
        status_text = "üîç TR·∫†NG TH√ÅI API:\n\n"
        
        # Content providers
        status_text += "üìù AI Sinh n·ªôi dung:\n"
        for provider, available in status['content_providers'].items():
            icon = "‚úÖ" if available else "‚ùå"
            status_text += f"  {icon} {provider}\n"
        
        # Image providers
        status_text += "\nüé® AI T·∫°o ·∫£nh:\n"
        for provider, available in status['image_providers'].items():
            icon = "‚úÖ" if available else "‚ùå"
            status_text += f"  {icon} {provider}\n"
        
        # TTS providers
        status_text += "\nüé§ Text-to-Speech:\n"
        for provider, available in status['tts_providers'].items():
            icon = "‚úÖ" if available else "‚ùå"
            status_text += f"  {icon} {provider}\n"
        
        QMessageBox.information(self, "Tr·∫°ng th√°i API", status_text)
    
    def refresh_providers(self):
        """L√†m m·ªõi danh s√°ch providers"""
        # Reload API manager
        self.api_manager = APIManager()
        
        # Update combo boxes
        self.content_provider_combo.clear()
        self.content_provider_combo.addItems(self.api_manager.get_available_content_providers())
        
        self.image_provider_combo.clear()
        self.image_provider_combo.addItems(self.api_manager.get_available_image_providers())
        
        self.tts_provider_combo.clear()
        self.tts_provider_combo.addItems(self.api_manager.get_available_tts_providers())
        
        QMessageBox.information(self, "Th√¥ng b√°o", "ƒê√£ l√†m m·ªõi danh s√°ch providers!")
        
        # Update API status indicator
        self.update_api_status_indicator()
    
    def generate_story_only(self):
        """Ch·ªâ t·∫°o c√¢u chuy·ªán/k·ªãch b·∫£n t·ª´ prompt"""
        prompt = self.prompt_input.toPlainText().strip()
        if not prompt:
            QMessageBox.warning(self, "L·ªói", "Vui l√≤ng nh·∫≠p prompt!")
            return
        
        # Disable n√∫t ƒë·ªÉ tr√°nh spam
        self.generate_story_btn.setEnabled(False)
        self.progress_group.setVisible(True)
        self.progress_label.setVisible(True)
        self.progress_label.setText("ƒêang t·∫°o c√¢u chuy·ªán...")
        
        try:
            # L·∫•y provider ƒë∆∞·ª£c ch·ªçn
            content_provider = self.content_provider_combo.currentText()
            
            # T·∫°o c√¢u chuy·ªán
            result = self.pipeline.content_gen.generate_script_from_prompt(prompt, provider=content_provider)
            
            if "error" in result:
                QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ t·∫°o c√¢u chuy·ªán:\n{result['error']}")
                self.progress_label.setText("L·ªói t·∫°o c√¢u chuy·ªán")
            else:
                # Store script data for audio generation
                self.current_script_data = result
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi format m·ªõi
                story_text = "üé¨ C√ÇU CHUY·ªÜN ƒê√É T·∫†O:\n\n"
                
                # Show characters if available
                characters = result.get("characters", [])
                if characters:
                    story_text += "üé≠ NH√ÇN V·∫¨T:\n"
                    for char in characters:
                        story_text += f"‚Ä¢ {char.get('name', char['id'])} ({char.get('gender', 'neutral')}) - {char.get('suggested_voice', 'N/A')}\n"
                    story_text += "\n"
                
                for i, segment in enumerate(result["segments"], 1):
                    story_text += f"üìù ƒêO·∫†N {i} ({segment.get('duration', 10)}s):\n"
                    story_text += f"K·ªãch b·∫£n: {segment.get('script', '')}\n"
                    
                    # Show dialogues if available
                    dialogues = segment.get('dialogues', [])
                    if dialogues:
                        story_text += "Dialogues:\n"
                        for dialogue in dialogues:
                            speaker = dialogue.get('speaker', 'unknown')
                            text = dialogue.get('text', '')
                            emotion = dialogue.get('emotion', 'neutral')
                            story_text += f"  - {speaker} ({emotion}): {text}\n"
                    else:
                        # Fallback for old format
                        story_text += f"L·ªùi tho·∫°i: {segment.get('narration', '')}\n"
                    
                    story_text += f"M√¥ t·∫£ ·∫£nh: {segment.get('image_prompt', '')}\n"
                    story_text += "-" * 50 + "\n\n"
                
                # Enable audio generation button
                self.generate_audio_btn.setEnabled(True)
                
                # T·∫°o dialog hi·ªÉn th·ªã
                dialog = QDialog(self)
                dialog.setWindowTitle(f"C√¢u chuy·ªán t·ª´ prompt - {content_provider}")
                dialog.setModal(True)
                dialog.resize(800, 600)
                
                layout = QVBoxLayout()
                dialog.setLayout(layout)
                
                # Text area hi·ªÉn th·ªã story
                story_display = QTextEdit()
                story_display.setPlainText(story_text)
                story_display.setReadOnly(True)
                layout.addWidget(story_display)
                
                # N√∫t actions
                buttons_layout = QHBoxLayout()
                
                copy_btn = QPushButton("üìã Copy")
                copy_btn.clicked.connect(lambda: self.copy_to_clipboard(story_text))
                buttons_layout.addWidget(copy_btn)
                
                save_btn = QPushButton("üíæ L∆∞u v√†o file")
                save_btn.clicked.connect(lambda: self.save_story_to_file(story_text, prompt))
                buttons_layout.addWidget(save_btn)
                
                close_btn = QPushButton("‚ùå ƒê√≥ng")
                close_btn.clicked.connect(dialog.close)
                buttons_layout.addWidget(close_btn)
                
                layout.addLayout(buttons_layout)
                
                dialog.exec_()
                self.progress_label.setText("ƒê√£ t·∫°o c√¢u chuy·ªán th√†nh c√¥ng!")
                
                # Hi·ªÉn th·ªã preview ngay trong ·ª©ng d·ª•ng
                preview_text = ""
                for i, segment in enumerate(result["segments"], 1):
                    # Handle both old and new format
                    narration = segment.get('narration', '')
                    if not narration and 'dialogues' in segment:
                        # New format with dialogues
                        narration = " ".join([d.get('text', '') for d in segment['dialogues']])
                    preview_text += f"ƒêO·∫†N {i}: {narration}\n"
                self.content_preview.setPlainText(preview_text)
                
                # Show progress group
                self.progress_group.setVisible(True)
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói kh√¥ng x√°c ƒë·ªãnh:\n{str(e)}")
            self.progress_label.setText("L·ªói t·∫°o c√¢u chuy·ªán")
        finally:
            self.generate_story_btn.setEnabled(True)
    
    def copy_to_clipboard(self, text):
        """Copy text v√†o clipboard"""
        try:
            from PySide6.QtGui import QClipboard, QGuiApplication
            clipboard = QGuiApplication.clipboard()
            clipboard.setText(text)
            QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ copy v√†o clipboard!")
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ copy: {str(e)}")
    
    def save_story_to_file(self, story_text, prompt):
        """L∆∞u c√¢u chuy·ªán v√†o file"""
        try:
            from PySide6.QtWidgets import QFileDialog
            from datetime import datetime
            
            # T·∫°o t√™n file m·∫∑c ƒë·ªãnh
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            default_filename = f"story_{timestamp}.txt"
            
            # M·ªü dialog l∆∞u file
            file_path, _ = QFileDialog.getSaveFileName(
                self, "L∆∞u c√¢u chuy·ªán", default_filename, 
                "Text Files (*.txt);;All Files (*)"
            )
            
            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(f"PROMPT G·ªêC:\n{prompt}\n\n")
                    f.write("=" * 60 + "\n\n")
                    f.write(story_text)
                    
                QMessageBox.information(self, "Th√†nh c√¥ng", f"ƒê√£ l∆∞u c√¢u chuy·ªán v√†o:\n{file_path}")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ l∆∞u file:\n{str(e)}")
    
    def select_project_folder(self):
        """Ch·ªçn th∆∞ m·ª•c ƒë·ªÉ l∆∞u d·ª± √°n"""
        folder_path = QFileDialog.getExistingDirectory(
            self, "Ch·ªçn th∆∞ m·ª•c l∆∞u d·ª± √°n", "./projects"
        )
        
        if folder_path:
            self.project_folder_input.setText(folder_path)
            self.progress_label.setText(f"ƒê√£ ch·ªçn th∆∞ m·ª•c: {folder_path}")
    
    def generate_audio_only(self):
        """T·∫°o audio t·ª´ script data c√≥ s·∫µn v·ªõi Enhanced Voice Setup"""
        if not self.current_script_data:
            QMessageBox.warning(self, "C·∫£nh b√°o", 
                "Ch∆∞a c√≥ script data! H√£y t·∫°o story tr∆∞·ªõc.")
            return
        
        # Import Enhanced Voice Setup Dialog
        from ui.manual_voice_setup_dialog import ManualVoiceSetupDialog
        from tts.voice_generator import VoiceGenerator
        
        # Initialize voice generator
        voice_gen = VoiceGenerator()
        
        # Create Enhanced dialog
        dialog = ManualVoiceSetupDialog(voice_gen, self)
        
        # Pre-populate dialog v·ªõi characters t·ª´ script data
        dialog.populate_from_script_characters(self.current_script_data)
        
        # Show dialog and get configuration
        if dialog.exec_() == QDialog.Accepted:
            characters, voice_mapping = dialog.get_characters_and_mapping()
            
            # Update current script with new character configs
            self.current_script_data["characters"] = characters
            
            # Generate audio v·ªõi Enhanced voice mapping
            self.generate_audio_with_mapping(voice_mapping)
    
    def open_audio_folder(self):
        """M·ªü th∆∞ m·ª•c ch·ª©a audio ƒë√£ t·∫°o"""
        if self.last_audio_output_dir and os.path.exists(self.last_audio_output_dir):
            # Cross-platform folder opening
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', self.last_audio_output_dir])
            elif platform.system() == "Windows":
                subprocess.Popen(['explorer', self.last_audio_output_dir])
            else:  # Linux
                subprocess.Popen(['xdg-open', self.last_audio_output_dir])
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", "Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c audio!")
    
    def play_final_audio(self):
        """Ph√°t audio ho√†n ch·ªânh"""
        if self.last_final_audio_path and os.path.exists(self.last_final_audio_path):
            # Cross-platform audio playing
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', self.last_final_audio_path])
            elif platform.system() == "Windows":
                os.system(f'start "" "{self.last_final_audio_path}"')
            else:  # Linux
                subprocess.Popen(['xdg-open', self.last_final_audio_path])
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", "Kh√¥ng t√¨m th·∫•y file audio!")
    
    def show_manual_voice_setup(self):
        """Hi·ªÉn th·ªã dialog c·∫•u h√¨nh gi·ªçng ƒë·ªçc th·ªß c√¥ng"""
        from tts.voice_generator import VoiceGenerator
        voice_gen = VoiceGenerator()
        
        dialog = ManualVoiceSetupDialog(voice_gen, self)
        if dialog.exec_() == QDialog.Accepted:
            characters, voice_mapping = dialog.get_characters_and_mapping()
            
            # Create manual script data
            manual_script_data = {
                "segments": [
                    {
                        "id": 1,
                        "script": "Audio ƒë∆∞·ª£c t·∫°o t·ª´ c·∫•u h√¨nh th·ªß c√¥ng",
                        "image_prompt": "H√¨nh ·∫£nh minh h·ªça",
                        "dialogues": [
                            {
                                "speaker": char['id'],
                                "text": f"Xin ch√†o, t√¥i l√† {char['name']}. ƒê√¢y l√† gi·ªçng n√≥i {char['suggested_voice']} c·ªßa t√¥i.",
                                "emotion": "friendly"
                            }
                            for char in characters
                        ],
                        "duration": 10
                    }
                ],
                "characters": characters
            }
            
            # Generate audio immediately
            self.current_script_data = manual_script_data
            self.generate_audio_with_mapping(voice_mapping)
    
    def generate_audio_with_mapping(self, voice_mapping):
        """T·∫°o audio v·ªõi voice mapping ƒë√£ c√≥"""
        if not self.current_script_data:
            return
        
        # Import voice generator
        from tts.voice_generator import VoiceGenerator
        voice_gen = VoiceGenerator()
        
        # Disable button during generation
        self.generate_audio_btn.setEnabled(False)
        self.generate_audio_btn.setText("‚è≥ ƒêang t·∫°o...")
        self.progress_label.setText("ƒêang t·∫°o audio...")
        
        try:
            # Get project folder
            project_folder = self.project_folder_input.text() or "./projects"
            project_name = self.project_name_input.text() or "manual_audio_project"
            
            # Create audio output directory
            audio_output_dir = os.path.join(project_folder, project_name, "audio")
            os.makedirs(audio_output_dir, exist_ok=True)
            
            # Generate audio by characters
            result = voice_gen.generate_audio_by_characters(
                self.current_script_data, 
                audio_output_dir, 
                voice_mapping
            )
            
            if result["success"]:
                # Store paths for buttons
                self.last_audio_output_dir = result["output_dir"]
                self.last_final_audio_path = result["final_audio_path"]
                
                # Enable audio control buttons
                self.open_audio_folder_btn.setEnabled(True)
                self.play_final_audio_btn.setEnabled(True)
                
                # Show success message
                message = f"‚úÖ ƒê√£ t·∫°o audio th√†nh c√¥ng!\n\n"
                message += f"üìÅ Th∆∞ m·ª•c: {result['output_dir']}\n"
                message += f"üéµ File cu·ªëi: {os.path.basename(result['final_audio_path'])}\n\n"
                message += f"üìä Chi ti·∫øt:\n"
                for character, files in result["character_audio_files"].items():
                    message += f"  ‚Ä¢ {character}: {len(files)} file(s)\n"
                
                QMessageBox.information(self, "Th√†nh c√¥ng", message)
                self.progress_label.setText("ƒê√£ t·∫°o audio th√†nh c√¥ng!")
                
            else:
                QMessageBox.critical(self, "L·ªói", f"L·ªói t·∫°o audio:\n{result.get('error', 'Unknown error')}")
                self.progress_label.setText("L·ªói t·∫°o audio")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói kh√¥ng x√°c ƒë·ªãnh:\n{str(e)}")
            self.progress_label.setText("L·ªói t·∫°o audio")
        finally:
            self.generate_audio_btn.setEnabled(True)
            self.generate_audio_btn.setText("üéµ T·∫°o Audio")
    
    def show_chatterbox_device_info(self):
        """Hi·ªÉn th·ªã th√¥ng tin device c·ªßa Chatterbox TTS"""
        try:
            device_info = self.voice_generator.get_chatterbox_device_info()
            providers = self.voice_generator.get_available_tts_providers()
            
            # Find Chatterbox provider info
            chatterbox_info = None
            for provider in providers:
                if provider['id'] == 'chatterbox':
                    chatterbox_info = provider
                    break
            
            # Create info message
            message = "ü§ñ **Chatterbox TTS Device Information**\n\n"
            
            if device_info.get('available'):
                message += f"‚úÖ **Status**: {device_info.get('initialized', False) and 'Initialized' or 'Available but not initialized'}\n"
                message += f"üì± **Device**: {device_info.get('device_name', 'Unknown')}\n"
                message += f"üîß **Device Type**: {device_info.get('device', 'Unknown')}\n\n"
                
                # GPU specific info
                if 'cuda_version' in device_info:
                    message += f"üéØ **CUDA Version**: {device_info['cuda_version']}\n"
                    message += f"üíæ **GPU Memory**: {device_info.get('gpu_memory_total', 'Unknown')} GB total\n"
                    message += f"üü¢ **Available Memory**: {device_info.get('gpu_memory_available', 'Unknown')} GB\n\n"
                
                # Provider features
                if chatterbox_info:
                    message += f"üåç **Languages**: {', '.join(chatterbox_info['languages'])}\n"
                    message += f"‚ú® **Features**:\n"
                    for feature in chatterbox_info['features']:
                        message += f"   ‚Ä¢ {feature}\n"
                
                # Memory usage if available
                memory_info = self.voice_generator.chatterbox_provider.get_memory_usage() if self.voice_generator.chatterbox_provider else {}
                if memory_info:
                    message += f"\nüìä **Current Memory Usage**:\n"
                    if 'gpu_allocated' in memory_info:
                        message += f"   ‚Ä¢ GPU Allocated: {memory_info['gpu_allocated']} MB\n"
                        message += f"   ‚Ä¢ GPU Cached: {memory_info['gpu_cached']} MB\n"
                    if 'cpu_memory_mb' in memory_info:
                        message += f"   ‚Ä¢ CPU Memory: {memory_info['cpu_memory_mb']} MB ({memory_info.get('cpu_memory_percent', 0):.1f}%)\n"
            else:
                message += f"‚ùå **Status**: Not available\n"
                message += f"üö´ **Reason**: {device_info.get('error', 'Unknown error')}\n\n"
                message += f"üí° **Possible solutions**:\n"
                message += f"   ‚Ä¢ Install PyTorch with CUDA support for GPU acceleration\n"
                message += f"   ‚Ä¢ Update graphics drivers\n"
                message += f"   ‚Ä¢ Ensure sufficient memory available\n"
            
            # Show dialog
            msg_box = QMessageBox(self)
            msg_box.setWindowTitle("Chatterbox TTS Device Info")
            msg_box.setText(message)
            msg_box.setIcon(QMessageBox.Information)
            msg_box.exec_()
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ l·∫•y th√¥ng tin device:\n{str(e)}")
    
    def clear_chatterbox_cache(self):
        """X√≥a cache c·ªßa Chatterbox TTS"""
        try:
            if self.voice_generator.chatterbox_provider:
                # Get memory info before clearing
                memory_before = self.voice_generator.chatterbox_provider.get_memory_usage()
                
                # Clear cache
                self.voice_generator.cleanup_chatterbox()
                
                # Get memory info after clearing
                memory_after = self.voice_generator.chatterbox_provider.get_memory_usage() if self.voice_generator.chatterbox_provider else {}
                
                # Show result
                message = "üßπ **Chatterbox TTS Cache Cleared**\n\n"
                
                if memory_before and memory_after:
                    message += f"**Memory Usage Before/After**:\n"
                    if 'gpu_allocated' in memory_before:
                        gpu_freed = memory_before.get('gpu_allocated', 0) - memory_after.get('gpu_allocated', 0)
                        message += f"   ‚Ä¢ GPU: {memory_before['gpu_allocated']} ‚Üí {memory_after['gpu_allocated']} MB (freed: {gpu_freed} MB)\n"
                    if 'cpu_memory_mb' in memory_before:
                        cpu_freed = memory_before.get('cpu_memory_mb', 0) - memory_after.get('cpu_memory_mb', 0)
                        message += f"   ‚Ä¢ CPU: {memory_before['cpu_memory_mb']} ‚Üí {memory_after['cpu_memory_mb']} MB (freed: {cpu_freed} MB)\n"
                else:
                    message += "‚úÖ Voice cloning cache cleared\n"
                    message += "‚úÖ GPU cache cleared (if applicable)\n"
                    message += "‚úÖ Memory resources freed\n"
                
                QMessageBox.information(self, "Th√†nh c√¥ng", message)
            else:
                QMessageBox.warning(self, "C·∫£nh b√°o", "Chatterbox TTS ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o!")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ x√≥a cache:\n{str(e)}")
    
    # ===== VOICE STUDIO TAB METHODS =====
    
    def update_token_preview(self):
        """Update token preview based on selected template mode"""
        mode = self.template_mode_combo.currentData()
        
        token_counts = {
            'rapid': 150,
            'standard': 400, 
            'detailed': 800
        }
        
        savings = {
            'rapid': 1350,
            'standard': 1100,
            'detailed': 700
        }
        
        current_tokens = token_counts.get(mode, 400)
        current_savings = savings.get(mode, 1100)
        
        self.token_preview_label.setText(f"üí° Ti·∫øt ki·ªám: +{current_savings} tokens cho story content")
        
        # Update color based on savings amount
        if current_savings >= 1200:
            color = "#28CD41"  # Green for high savings
        elif current_savings >= 900:
            color = "#FF6B35"  # Orange for medium savings  
        else:
            color = "#5856D6"  # Purple for lower savings
            
        self.token_preview_label.setStyleSheet(f"color: {color}; font-weight: bold;")

    def switch_data_source(self):
        """Switch between data sources v·ªõi enhanced multi-file support"""
        source = self.data_source_combo.currentData()
        
        # Hide all widgets first
        self.import_file_btn.setVisible(False)
        self.import_multi_files_btn.setVisible(False)
        self.load_generated_btn.setVisible(False)
        if hasattr(self, 'manual_script_widget'):
            self.manual_script_widget.setVisible(False)
        
        if source == "file":
            self.import_file_btn.setVisible(True)
            self.imported_file_label.setText("Ch∆∞a import file n√†o")
        elif source == "multi_file":  # NEW
            self.import_multi_files_btn.setVisible(True)
            self.imported_file_label.setText("Ch∆∞a import files n√†o")
        elif source == "generated":
            self.load_generated_btn.setVisible(True)
            self.imported_file_label.setText("S·ª≠ d·ª•ng data t·ª´ tab T·∫°o Video")
        elif source == "manual":
            if hasattr(self, 'manual_script_widget'):
                self.manual_script_widget.setVisible(True)
            self.imported_file_label.setText("Nh·∫≠p th·ªß c√¥ng JSON script")
    
    def import_script_file(self):
        """Import script t·ª´ file JSON"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Ch·ªçn file JSON script",
            "",
            "JSON files (*.json);;All files (*.*)"
        )
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    script_data = json.load(f)
                
                # Validate script data
                if self.validate_script_data(script_data):
                    self.voice_studio_script_data = script_data
                    self.imported_file_label.setText(os.path.basename(file_path))
                    self.imported_file_label.setStyleSheet("color: #007AFF; font-weight: bold;")
                    self.update_voice_studio_overview()
                    QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ import script th√†nh c√¥ng!")
                else:
                    QMessageBox.warning(self, "L·ªói", "File JSON kh√¥ng ƒë√∫ng format!")
                    
            except Exception as e:
                QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ ƒë·ªçc file:\n{str(e)}")
    
    def load_generated_script_data(self):
        """Load script data t·ª´ tab T·∫°o Video"""
        if self.current_script_data:
            self.voice_studio_script_data = self.current_script_data
            self.update_voice_studio_overview()
            QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ load script data t·ª´ tab T·∫°o Video!")
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", "Ch∆∞a c√≥ script data n√†o ƒë∆∞·ª£c t·∫°o trong tab T·∫°o Video!")
    
    def parse_manual_script(self):
        """Parse JSON script ƒë∆∞·ª£c nh·∫≠p th·ªß c√¥ng"""
        try:
            script_text = self.manual_script_input.toPlainText().strip()
            if not script_text:
                QMessageBox.warning(self, "C·∫£nh b√°o", "Vui l√≤ng nh·∫≠p JSON script!")
                return
            
            script_data = json.loads(script_text)
            
            if self.validate_script_data(script_data):
                self.voice_studio_script_data = script_data
                self.update_voice_studio_overview()
                QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ parse JSON script th√†nh c√¥ng!")
            else:
                QMessageBox.warning(self, "L·ªói", "JSON script kh√¥ng ƒë√∫ng format!")
                
        except json.JSONDecodeError as e:
            QMessageBox.critical(self, "L·ªói JSON", f"JSON kh√¥ng h·ª£p l·ªá:\n{str(e)}")
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ parse script:\n{str(e)}")
    
    def validate_script_data(self, script_data):
        """Validate format c·ªßa script data - Enhanced Format 2.0 Support"""
        try:
            # Check required fields
            if not isinstance(script_data, dict):
                return False
            
            # Support both old format and Enhanced Format 2.0
            if 'segments' not in script_data or 'characters' not in script_data:
                return False
            
            # Check segments
            segments = script_data['segments']
            if not isinstance(segments, list) or len(segments) == 0:
                return False
            
            # Check characters
            characters = script_data['characters']
            if not isinstance(characters, list) or len(characters) == 0:
                return False
            
            # Basic structure validation
            for segment in segments:
                if not all(key in segment for key in ['id', 'dialogues']):
                    return False
                
                for dialogue in segment['dialogues']:
                    # Required fields for dialogue
                    if not all(key in dialogue for key in ['speaker', 'text']):
                        return False
                    
                    # Optional Enhanced Format 2.0 fields validation
                                # Emotion intensity and speed fields are no longer supported - simplified to emotion only
                    
                    if 'pause_after' in dialogue:
                        pause = dialogue['pause_after']
                        if not isinstance(pause, (int, float)) or not (0.0 <= pause <= 5.0):
                            print(f"‚ö†Ô∏è Invalid pause_after: {pause} (should be 0.0-5.0)")
            
            for character in characters:
                if not all(key in character for key in ['id', 'name']):
                    return False
                
                # Enhanced Format 2.0 character validation
                            # Default emotion intensity and speed fields are no longer supported - simplified to default_emotion only
            
            # Enhanced Format 2.0 detection
            has_project_metadata = 'project' in script_data
            has_audio_settings = 'audio_settings' in script_data
            has_metadata = 'metadata' in script_data
            
            if has_project_metadata or has_audio_settings or has_metadata:
                print("üÜï Enhanced Format 2.0 detected with advanced features")
                
                # Validate project metadata if present
                if has_project_metadata:
                    project = script_data['project']
                    if not all(key in project for key in ['title', 'description']):
                        print("‚ö†Ô∏è Missing required project fields (title, description)")
                
                # Validate audio settings if present
                if has_audio_settings:
                    audio = script_data['audio_settings']
                    if 'crossfade_duration' in audio:
                        fade = audio['crossfade_duration']
                        if not isinstance(fade, (int, float)) or not (0.0 <= fade <= 2.0):
                            print(f"‚ö†Ô∏è Invalid crossfade_duration: {fade}")
            else:
                print("üìú Classic format detected - fully compatible")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Validation error: {e}")
            return False
    
    def update_voice_studio_overview(self):
        """C·∫≠p nh·∫≠t overview c·ªßa script trong Voice Studio - Enhanced Format 2.0 Support"""
        if not self.voice_studio_script_data:
            return
        
        try:
            segments = self.voice_studio_script_data['segments']
            characters = self.voice_studio_script_data['characters']
            
            # Detect format version
            has_enhanced_features = any(key in self.voice_studio_script_data for key in ['project', 'audio_settings', 'metadata'])
            format_version = "Enhanced 2.0" if has_enhanced_features else "Classic"
            
            # Update info labels with enhanced information
            total_dialogues = sum(len(segment['dialogues']) for segment in segments)
            
            # Calculate enhanced features count
            enhanced_features = []
            if 'project' in self.voice_studio_script_data:
                enhanced_features.append("Project Metadata")
            if 'audio_settings' in self.voice_studio_script_data:
                enhanced_features.append("Audio Settings")
            if 'metadata' in self.voice_studio_script_data:
                enhanced_features.append("Metadata")
            
            # Count advanced dialogue features
            advanced_dialogues = 0
            for segment in segments:
                for dialogue in segment['dialogues']:
                    if any(key in dialogue for key in ['pause_after', 'emphasis']):
                        advanced_dialogues += 1
            
            # Build script info text
            script_info = f"‚úÖ Script loaded ({format_version}): {len(segments)} segments, {total_dialogues} dialogues"
            if advanced_dialogues > 0:
                script_info += f", {advanced_dialogues} v·ªõi advanced settings"
            
            self.script_info_label.setText(script_info)
            self.script_info_label.setStyleSheet("color: #007AFF; font-weight: bold;")
            
            # Update characters with enhanced info
            character_info = []
            for char in characters:
                char_text = char['name']
                if 'default_emotion' in char:
                    char_text += f" ({char['default_emotion']})"
                character_info.append(char_text)
            
            self.characters_label.setText(", ".join(character_info))
            
            # Update segments count
            self.segments_count_label.setText(str(len(segments)))
            
            # Show project title if available
            if 'project' in self.voice_studio_script_data and hasattr(self, 'project_title_label'):
                project_title = self.voice_studio_script_data['project']['title']
                self.project_title_label.setText(f"üìñ {project_title}")
                self.project_title_label.setVisible(True)
            
            # Log enhanced features
            if has_enhanced_features:
                print(f"üÜï Enhanced Format 2.0 loaded with: {', '.join(enhanced_features)}")
                
                # Show duration if available
                if 'project' in self.voice_studio_script_data and 'total_duration' in self.voice_studio_script_data['project']:
                    duration = self.voice_studio_script_data['project']['total_duration']
                    print(f"‚è±Ô∏è Estimated duration: {duration} seconds")
            
            # Update voice mapping table
            self.populate_voice_mapping_table()
            
            # Enable generation buttons
            self.generate_selected_btn.setEnabled(True)
            self.generate_all_btn.setEnabled(True)
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t overview:\n{str(e)}")
    
    def populate_voice_mapping_table(self):
        """Populate character settings table - FIXED METHOD"""
        if not self.voice_studio_script_data:
            return
        
        # Call the correct method for character settings table
        self.populate_character_settings_table()
        
        # Enable generation buttons
        self.generate_selected_btn.setEnabled(True)
        self.generate_all_btn.setEnabled(True)
        
        print("‚úÖ Character settings table populated successfully")
        return

    
    def reset_voice_mapping(self):
        """Reset voice mapping v·ªÅ m·∫∑c ƒë·ªãnh"""
        if not self.voice_studio_script_data:
            return
        
        # Reset table
        self.populate_character_settings_table()
        QMessageBox.information(self, "Th√¥ng b√°o", "ƒê√£ reset voice mapping v·ªÅ m·∫∑c ƒë·ªãnh!")
    
    def preview_selected_voice(self):
        """Preview gi·ªçng n√≥i c·ªßa nh√¢n v·∫≠t ƒë∆∞·ª£c ch·ªçn - CH·ªà CHATTERBOX TTS"""
        current_row = self.character_settings_table.currentRow()
        if current_row < 0:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(self, "C·∫£nh b√°o", "Vui l√≤ng ch·ªçn m·ªôt nh√¢n v·∫≠t!")
            return
        
        try:
            # Get character info
            character_id = self.character_settings_table.item(current_row, 0).text()
            voice_combo = self.character_settings_table.cellWidget(current_row, 4)  # Voice column
            selected_voice = voice_combo.currentData()  # Get Chatterbox voice ID
            
            # Get settings from character_settings_table
            emotion_input = self.character_settings_table.cellWidget(current_row, 1)
            speed_input = self.character_settings_table.cellWidget(current_row, 2)
            cfg_weight_input = self.character_settings_table.cellWidget(current_row, 3)
            
            emotion = emotion_input.text() if emotion_input else "friendly"  # Now emotion is string
            speed = float(speed_input.text()) if speed_input else 1.0
            cfg_weight = float(cfg_weight_input.text()) if cfg_weight_input else 0.5
            
            # Preview text
            preview_text = f"Xin ch√†o, t√¥i l√† {character_id}. ƒê√¢y l√† gi·ªçng n√≥i {voice_combo.currentText().split(' ')[1]} c·ªßa t√¥i v·ªõi emotion {emotion}, speed {speed:.1f}x."
            
            # Generate preview audio
            import tempfile
            temp_dir = tempfile.mkdtemp()
            preview_path = os.path.join(temp_dir, f"preview_{character_id}.mp3")
            
            # Check if prompt-based voice is enabled for preview
            voice_prompt = None
            if self.enable_prompt_voice.isChecked() and self.voice_prompt_input.text().strip():
                voice_prompt = self.voice_prompt_input.text().strip()
                print(f"üéß Preview with PROMPT: '{voice_prompt}'")
                preview_text = f"Xin ch√†o, t√¥i l√† {character_id}. ƒê√¢y l√† gi·ªçng ƒë∆∞·ª£c t·∫°o t·ª´ prompt: {voice_prompt[:50]}..."
            else:
                print(f"üéß Preview Settings for {character_id}:")
                print(f"   Voice: {selected_voice}")
                print(f"   Emotion: {emotion}")
                print(f"   Speed: {speed:.1f}x")
                print(f"   CFG Weight: {cfg_weight:.2f}")
                
            result = self.voice_generator.generate_voice_chatterbox(
                text=preview_text,
                save_path=preview_path,
                voice_sample_path=None,
                emotion_exaggeration=emotion,
                speed=speed,
                voice_name=selected_voice if not voice_prompt else None,  # Skip voice_name if using prompt
                cfg_weight=cfg_weight,
                voice_prompt=voice_prompt  # NEW: Pass voice prompt for preview
            )
            
            if result.get('success'):
                # Play preview
                self.play_audio_file(preview_path)
                QMessageBox.information(self, "üéß Preview Voice", 
                    f"Character: {character_id}\n"
                    f"Voice: {voice_combo.currentText()}\n"
                    f"Emotion: {emotion}\n"
                    f"Speed: {speed:.1f}x\n"
                    f"CFG Weight: {cfg_weight:.2f}\n"
                    f"\nü§ñ Generated by Chatterbox TTS")
            else:
                QMessageBox.warning(self, "‚ùå L·ªói Preview", f"Kh√¥ng th·ªÉ t·∫°o preview Chatterbox TTS:\n{result.get('error', 'Unknown error')}")
                
        except Exception as e:
            QMessageBox.critical(self, "‚ùå L·ªói Critical", f"L·ªói preview voice:\n{str(e)}")
    
    def play_audio_file(self, file_path):
        """Play audio file"""
        try:
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', file_path])
            elif platform.system() == "Windows":
                os.startfile(file_path)
            else:  # Linux
                subprocess.Popen(['xdg-open', file_path])
        except Exception as e:
            print(f"Kh√¥ng th·ªÉ play audio: {e}")
    
    def select_voice_output_folder(self):
        """Ch·ªçn th∆∞ m·ª•c output cho voice"""
        folder = QFileDialog.getExistingDirectory(self, "Ch·ªçn th∆∞ m·ª•c output")
        if folder:
            self.voice_output_input.setText(folder)
    
    def generate_selected_character_voice(self):
        """T·∫°o voice cho nh√¢n v·∫≠t ƒë∆∞·ª£c ch·ªçn"""
        current_row = self.character_settings_table.currentRow()
        if current_row < 0:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(self, "C·∫£nh b√°o", "Vui l√≤ng ch·ªçn m·ªôt nh√¢n v·∫≠t!")
            return
        
        # Get character ID
        character_id = self.character_settings_table.item(current_row, 0).text()
        
        # Generate for single character
        self.generate_voices_for_characters([character_id])
    
    def generate_all_voices(self):
        """T·∫°o voice cho t·∫•t c·∫£ nh√¢n v·∫≠t"""
        if not self.voice_studio_script_data:
            return
        
        # Get all character IDs
        character_ids = [char['id'] for char in self.voice_studio_script_data['characters']]
        
        # Generate for all characters
        self.generate_voices_for_characters(character_ids)
    
    def generate_voices_for_characters(self, character_ids):
        """T·∫°o voice cho danh s√°ch character IDs"""
        try:
            # Show progress
            self.voice_progress_bar.setVisible(True)
            self.voice_progress_bar.setRange(0, 0)  # Indeterminate progress
            self.voice_progress_text.setText("ƒêang t·∫°o voice...")
            
            # Get output directory
            output_dir = self.voice_output_input.text() or "./voice_studio_output"
            os.makedirs(output_dir, exist_ok=True)
            
            # CH·ªà S·ª¨ D·ª§NG CHATTERBOX TTS
            # provider = "chatterbox"  # Fixed provider
            
            # Collect voice mapping from character_settings_table
            current_voice_mapping = {}
            for i in range(self.character_settings_table.rowCount()):
                char_id = self.character_settings_table.item(i, 0).text()
                voice_combo = self.character_settings_table.cellWidget(i, 4)  # Voice column
                emotion_input = self.character_settings_table.cellWidget(i, 1)
                speed_input = self.character_settings_table.cellWidget(i, 2)
                cfg_weight_input = self.character_settings_table.cellWidget(i, 3)
                
                current_voice_mapping[char_id] = {
                    'name': char_id,
                    'suggested_voice': voice_combo.currentData() if voice_combo else 'female_young',
                    'emotion': emotion_input.text() if emotion_input and emotion_input.text() else 'friendly',  # Now string
                    'speed': float(speed_input.text()) if speed_input and speed_input.text() else 1.0,
                    'cfg_weight': float(cfg_weight_input.text()) if cfg_weight_input and cfg_weight_input.text() else 0.5
                }
            
            # Count total dialogues for progress tracking
            total_dialogues = 0
            for segment in self.voice_studio_script_data['segments']:
                for dialogue in segment['dialogues']:
                    if dialogue['speaker'] in character_ids:
                        total_dialogues += 1
            
            # Generate audio v·ªõi real-time progress
            total_generated = 0
            total_failed = 0
            current_dialogue = 0
            results_text = ""
            
            # Set determinate progress bar
            self.voice_progress_bar.setRange(0, total_dialogues)
            self.voice_progress_bar.setValue(0)
            
            for segment in self.voice_studio_script_data['segments']:
                segment_id = segment['id']
                print(f"\nüé¨ Processing Segment {segment_id}")
                
                for dialogue_idx, dialogue in enumerate(segment['dialogues'], 1):
                    speaker = dialogue['speaker']
                    
                    # Skip if not in selected characters
                    if speaker not in character_ids:
                        continue
                    
                    current_dialogue += 1
                    text = dialogue['text']
                    emotion = dialogue.get('emotion', 'neutral')
                    
                    # Get voice settings from character_settings_table
                    voice_settings = current_voice_mapping.get(speaker, {})
                    voice_name = voice_settings.get('suggested_voice', 'female_young')
                    table_emotion = voice_settings.get('emotion', 'friendly')  # String emotion from table
                    speed = voice_settings.get('speed', 1.0)
                    cfg_weight = voice_settings.get('cfg_weight', 0.5)
                    
                    # Default emotion_exaggeration - will be overridden by emotion mapping if enabled
                    emotion_exaggeration = 1.0
                    
                    # Get per-character settings t·ª´ character_chatterbox_settings
                    char_settings = self.character_chatterbox_settings.get(speaker, {})
                    voice_prompt = char_settings.get('voice_prompt', '').strip()
                    voice_clone_path = char_settings.get('voice_clone_path', None)
                    
                    # Generate filename
                    filename = f"segment_{segment_id}_dialogue_{dialogue_idx}_{speaker}.mp3"
                    file_path = os.path.join(output_dir, filename)
                    
                    # üìä Update real-time progress
                    progress_text = f"üéôÔ∏è [{current_dialogue}/{total_dialogues}] ƒêang t·∫°o: {speaker} (Segment {segment_id})"
                    self.voice_progress_text.setText(progress_text)
                    self.voice_progress_bar.setValue(current_dialogue)
                    
                    # Process events ƒë·ªÉ UI update ngay l·∫≠p t·ª©c
                    QApplication.processEvents()
                    
                    # Log chi ti·∫øt cho console
                    print(f"üé§ [{current_dialogue}/{total_dialogues}] {speaker}: {text[:50]}{'...' if len(text) > 50 else ''}")
                    
                    # Generate voice - CH·ªà S·ª¨ D·ª§NG CHATTERBOX TTS v·ªõi per-character settings
                    try:
                        # Apply emotion mapping if enabled (use emotion from script, not table)
                        if self.enable_emotion_mapping.isChecked():
                            mapped_emotion, mapped_cfg = self.map_emotion_to_parameters(emotion, emotion_exaggeration)
                            emotion_exaggeration = mapped_emotion
                            cfg_weight = mapped_cfg
                        else:
                            # If no emotion mapping, use script emotion directly for Chatterbox (emotion is now just a label)
                            # Keep emotion_exaggeration as 1.0 for consistent behavior
                            pass
                        
                        # Validate voice settings v√† log generation info
                        voice_mode = self.validate_character_voice_settings(speaker)
                        
                        # CH·ªà S·ª¨ D·ª§NG CHATTERBOX TTS v·ªõi optimized parameter passing
                        result = self.voice_generator.generate_voice_chatterbox(
                            text=text,
                            save_path=file_path,
                            voice_sample_path=voice_clone_path if voice_mode == 'clone' else None,
                            emotion_exaggeration=emotion_exaggeration,
                            speed=speed,
                            voice_name=voice_name if voice_mode == 'selection' else None,
                            cfg_weight=cfg_weight,
                            voice_prompt=voice_prompt if voice_mode == 'prompt' else None
                        )
                        
                        if result.get('success'):
                            total_generated += 1
                            results_text += f"‚úÖ {filename}\n"
                            print(f"   ‚úÖ Success: {filename}")
                        else:
                            total_failed += 1
                            error_msg = result.get('error', 'Unknown error')
                            results_text += f"‚ùå {filename}: {error_msg}\n"
                            print(f"   ‚ùå Failed: {error_msg}")
                            
                        # Update results text ngay l·∫≠p t·ª©c
                        self.voice_results_text.setText(results_text)
                        QApplication.processEvents()
                            
                    except Exception as e:
                        total_failed += 1
                        error_msg = str(e)
                        results_text += f"‚ùå {filename}: {error_msg}\n"
                        print(f"   üí• Exception: {error_msg}")
                        
                        # Update results text ngay l·∫≠p t·ª©c
                        self.voice_results_text.setText(results_text)
                        QApplication.processEvents()
            
            # Update results
            self.voice_results_text.setText(results_text)
            
            # üéµ MERGE ALL AUDIO FILES into complete conversation
            merged_file = None
            if total_generated > 0:
                try:
                    print("üîÑ Merging all audio files into complete conversation...")
                    merged_file = self.merge_all_voice_files(output_dir)
                    if merged_file:
                        print(f"‚úÖ Complete conversation saved: {merged_file}")
                except Exception as merge_error:
                    print(f"‚ö†Ô∏è Failed to merge audio files: {merge_error}")
            
            # Show summary
            summary = f"üéØ Ho√†n th√†nh!\n\n"
            summary += f"‚úÖ Th√†nh c√¥ng: {total_generated} files\n"
            summary += f"‚ùå Th·∫•t b·∫°i: {total_failed} files\n"
            summary += f"üìÅ Output: {output_dir}"
            
            if merged_file:
                summary += f"\n\nüéµ Complete Audio: {os.path.basename(merged_file)}"
                summary += f"\nüìä File g·ªôp ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!"
            
            QMessageBox.information(self, "K·∫øt qu·∫£", summary)
            
            # Update progress
            progress_text = f"Ho√†n th√†nh: {total_generated} th√†nh c√¥ng, {total_failed} th·∫•t b·∫°i"
            if merged_file:
                progress_text += " | üéµ File g·ªôp ƒë√£ t·∫°o"
            self.voice_progress_text.setText(progress_text)
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói t·∫°o voice:\n{str(e)}")
            self.voice_progress_text.setText("L·ªói t·∫°o voice")
        finally:
            self.voice_progress_bar.setVisible(False)
    
    def open_voice_output_folder(self):
        """M·ªü th∆∞ m·ª•c output voice"""
        output_dir = self.voice_output_input.text() or "./voice_studio_output"
        
        if os.path.exists(output_dir):
            if platform.system() == "Darwin":  # macOS
                subprocess.Popen(['open', output_dir])
            elif platform.system() == "Windows":
                os.startfile(output_dir)
            else:  # Linux
                subprocess.Popen(['xdg-open', output_dir])
        else:
            QMessageBox.warning(self, "C·∫£nh b√°o", f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {output_dir}")
    
    def clear_voice_results(self):
        """X√≥a k·∫øt qu·∫£ voice generation"""
        self.voice_results_text.clear()
        self.voice_progress_text.setText("S·∫µn s√†ng t·∫°o voice")
        QMessageBox.information(self, "Th√¥ng b√°o", "ƒê√£ x√≥a k·∫øt qu·∫£!")
    
    def force_merge_all_segments(self):
        """Force merge t·∫•t c·∫£ segment files v·ªõi proper MP3 handling"""
        try:
            output_dir = self.voice_output_input.text() or "./voice_studio_output"
            
            if not os.path.exists(output_dir):
                QMessageBox.warning(self, "C·∫£nh b√°o", f"Th∆∞ m·ª•c output kh√¥ng t·ªìn t·∫°i: {output_dir}")
                return
            
            # Find all segment files
            import glob
            audio_files = glob.glob(os.path.join(output_dir, "segment_*.mp3"))
            
            if not audio_files:
                QMessageBox.warning(self, "C·∫£nh b√°o", f"Kh√¥ng t√¨m th·∫•y file segment_*.mp3 trong th∆∞ m·ª•c: {output_dir}")
                return
            
            # Sort files properly
            def extract_numbers(filename):
                import re
                basename = os.path.basename(filename)
                match = re.search(r'segment_(\d+)_dialogue_(\d+)', basename)
                if match:
                    return (int(match.group(1)), int(match.group(2)))
                return (0, 0)
            
            sorted_files = sorted(audio_files, key=extract_numbers)
            
            print(f"\nüöÄ FORCE MERGE ALL SEGMENTS")
            print(f"üìÅ Directory: {output_dir}")
            print(f"üéµ Found {len(sorted_files)} files to merge")
            
            # Show progress
            self.voice_progress_text.setText(f"Force merging {len(sorted_files)} files...")
            QApplication.processEvents()
            
            # Output file with timestamp
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = os.path.join(output_dir, f"force_merged_conversation_{timestamp}.mp3")
            
            print(f"üîß Using MP3 frame-level concatenation...")
            
            try:
                with open(output_path, 'wb') as outfile:
                    first_file = True
                    files_merged = 0
                    
                    for file_path in sorted_files:
                        if os.path.exists(file_path):
                            print(f"   üìé Processing: {os.path.basename(file_path)}")
                            
                            with open(file_path, 'rb') as infile:
                                data = infile.read()
                                
                                if first_file:
                                    # Keep full first file including headers
                                    outfile.write(data)
                                    first_file = False
                                    print(f"      ‚úÖ Wrote full file with headers ({len(data)} bytes)")
                                else:
                                    # Skip ID3 headers for subsequent files
                                    # Find MP3 sync frame (0xFF 0xFB or 0xFF 0xFA)
                                    sync_pos = 0
                                    for i in range(min(1024, len(data) - 1)):
                                        if data[i] == 0xFF and data[i+1] in [0xFB, 0xFA, 0xF3, 0xF2]:
                                            sync_pos = i
                                            break
                                    
                                    # Write from sync frame onwards
                                    audio_data = data[sync_pos:]
                                    outfile.write(audio_data)
                                    print(f"      ‚úÖ Wrote audio data ({len(audio_data)} bytes, skipped {sync_pos} header bytes)")
                                
                                files_merged += 1
                
                # Check file size
                file_size = os.path.getsize(output_path)
                print(f"\n‚úÖ FORCE MERGE SUCCESS!")
                print(f"üìÅ Output: {os.path.basename(output_path)}")
                print(f"üìè File size: {file_size:,} bytes ({file_size / 1024 / 1024:.2f} MB)")
                
                # Success dialog v·ªõi option to play
                msg = QMessageBox()
                msg.setIcon(QMessageBox.Information)
                msg.setWindowTitle("üéâ Force Merge Success!")
                msg.setText(f"‚úÖ Successfully merged {files_merged} audio files!")
                msg.setInformativeText(f"üìÅ Saved: {os.path.basename(output_path)}\nüìè Size: {file_size / 1024 / 1024:.2f} MB\n\nüéµ B·∫°n c√≥ mu·ªën nghe merged audio kh√¥ng?")
                msg.setStandardButtons(QMessageBox.Yes | QMessageBox.No)
                msg.setDefaultButton(QMessageBox.Yes)
                
                reply = msg.exec_()
                
                if reply == QMessageBox.Yes:
                    self.play_audio_file(output_path)
                
                self.voice_progress_text.setText(f"‚úÖ Force merged: {os.path.basename(output_path)}")
                
            except Exception as merge_error:
                print(f"‚ùå Force merge failed: {merge_error}")
                QMessageBox.critical(self, "L·ªói", f"Force merge th·∫•t b·∫°i:\n{merge_error}")
                self.voice_progress_text.setText("‚ùå Force merge failed")
                
        except Exception as e:
            print(f"‚ùå Error in force merge: {e}")
            QMessageBox.critical(self, "L·ªói", f"L·ªói khi force merge:\n{e}")
    
    def force_merge_all_files(self):
        """Force merge t·∫•t c·∫£ segment files - kh√¥ng c·∫ßn script data"""
        try:
            output_dir = self.voice_output_input.text() or "./voice_studio_output"
            
            if not os.path.exists(output_dir):
                QMessageBox.warning(self, "C·∫£nh b√°o", f"Th∆∞ m·ª•c output kh√¥ng t·ªìn t·∫°i: {output_dir}")
                return
            
            # Show progress
            self.voice_progress_text.setText("Force merging t·∫•t c·∫£ files...")
            QApplication.processEvents()
            
            # Use smart merge logic (doesn't require script data)
            merged_file = self.merge_all_voice_files(output_dir)
            
            if merged_file:
                # Success message
                filename = os.path.basename(merged_file)
                message = f"üéâ Force merge th√†nh c√¥ng!\n\n"
                message += f"üìÅ File: {filename}\n"
                message += f"üìç V·ªã tr√≠: {output_dir}\n\n"
                message += f"‚úÖ ƒê√£ g·ªôp t·∫•t c·∫£ segment files theo th·ª© t·ª± s·ªë.\n"
                message += f"B·∫°n c√≥ mu·ªën nghe cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh kh√¥ng?"
                
                reply = QMessageBox.question(
                    self, "Th√†nh c√¥ng", message,
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.Yes
                )
                
                if reply == QMessageBox.Yes:
                    self.play_audio_file(merged_file)
                    
                self.voice_progress_text.setText(f"‚úÖ Force merge: {filename}")
            else:
                QMessageBox.warning(self, "L·ªói", "Kh√¥ng th·ªÉ force merge files. Xem console ƒë·ªÉ bi·∫øt chi ti·∫øt.")
                self.voice_progress_text.setText("‚ùå L·ªói force merge")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói force merge:\n{str(e)}")
            self.voice_progress_text.setText("‚ùå L·ªói force merge")
        
    def merge_all_voice_files(self, output_dir):
        """G·ªôp t·∫•t c·∫£ audio files th√†nh 1 cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh - SMART MERGE"""
        try:
            from pydub import AudioSegment
            import re
            import glob
            
            print("üîç SMART AUDIO MERGE - Scanning for files...")
            print(f"üìÅ Output directory: {output_dir}")
            print(f"üìç Absolute path: {os.path.abspath(output_dir)}")
            
            # Get all segment MP3 files and sort them intelligently
            search_pattern = os.path.join(output_dir, "segment_*.mp3")
            print(f"üîç Search pattern: {search_pattern}")
            all_mp3_files = glob.glob(search_pattern)
            print(f"üéµ Found {len(all_mp3_files)} segment MP3 files")
            
            if not all_mp3_files:
                print("‚ùå No segment files found with glob search")
                
                # Fallback: Try manual directory listing  
                print("üîÑ Trying manual directory scan...")
                try:
                    if os.path.exists(output_dir):
                        all_files = os.listdir(output_dir)
                        segment_files = [f for f in all_files if f.startswith('segment_') and f.endswith('.mp3')]
                        print(f"üìÇ Manual scan found {len(segment_files)} segment files: {segment_files[:5]}")
                        
                        if segment_files:
                            # Build full paths
                            all_mp3_files = [os.path.join(output_dir, f) for f in segment_files]
                        else:
                            print("‚ùå No segment files found even with manual scan")
                            return None
                    else:
                        print(f"‚ùå Output directory does not exist: {output_dir}")
                        return None
                except Exception as e:
                    print(f"‚ùå Error during manual scan: {e}")
                    return None
            
            # Smart sorting: Extract segment and dialogue numbers for proper ordering
            def extract_numbers(filename):
                """Extract segment_id, dialogue_id from filename like segment_1_dialogue_2_speaker.mp3"""
                match = re.search(r'segment_(\d+)_dialogue_(\d+)', os.path.basename(filename))
                if match:
                    return (int(match.group(1)), int(match.group(2)))
                # Fallback: try to extract just segment number
                match = re.search(r'segment_(\d+)', os.path.basename(filename))
                if match:
                    return (int(match.group(1)), 0)
                return (999, 999)  # Put unrecognized files at end
            
            # Sort files by segment then dialogue order
            sorted_files = sorted(all_mp3_files, key=extract_numbers)
            
            print(f"üìã File order after smart sorting:")
            for i, file_path in enumerate(sorted_files[:5]):  # Show first 5
                seg, dial = extract_numbers(file_path)
                filename = os.path.basename(file_path)
                absolute_path = os.path.abspath(file_path)
                exists = "‚úÖ" if os.path.exists(file_path) else "‚ùå"
                print(f"   {i+1:2d}. {filename} (seg:{seg}, dial:{dial}) {exists}")
                print(f"       Path: {absolute_path}")
            if len(sorted_files) > 5:
                print(f"   ... and {len(sorted_files) - 5} more files")
            
            # Merge all files in order
            merged_audio = AudioSegment.silent(duration=0)
            total_files_added = 0
            
            for file_path in sorted_files:
                filename = os.path.basename(file_path)
                try:
                    # Fix path separators for Windows compatibility
                    normalized_path = os.path.normpath(file_path)
                    
                    # Double check file exists before trying to load
                    if not os.path.exists(normalized_path):
                        print(f"   ‚ö†Ô∏è File not found at: {normalized_path}")
                        continue
                    
                    # Load audio file with PyDub fallback options
                    try:
                        # Try direct MP3 loading first
                        audio_segment = AudioSegment.from_mp3(normalized_path)
                    except Exception as mp3_error:
                        print(f"   üîÑ MP3 loading failed, trying raw audio: {mp3_error}")
                        try:
                            # Fallback: Try loading as raw audio without codec requirements
                            audio_segment = AudioSegment.from_file(normalized_path, format="mp3")
                        except Exception as fallback_error:
                            print(f"   üîÑ Fallback failed, trying with ffmpeg: {fallback_error}")
                            try:
                                # Final fallback: Force ffmpeg usage
                                audio_segment = AudioSegment.from_file(normalized_path)
                            except Exception as final_error:
                                print(f"   ‚ùå All loading methods failed: {final_error}")
                                continue
                    
                    # Add silence padding between dialogues (0.5 seconds)
                    if total_files_added > 0:
                        silence = AudioSegment.silent(duration=500)  # 0.5 second pause
                        merged_audio += silence
                    
                    # Add the dialogue audio
                    merged_audio += audio_segment
                    total_files_added += 1
                    
                    # Log addition
                    duration = len(audio_segment) / 1000.0  # Convert to seconds
                    print(f"   ‚úÖ Added: {filename} ({duration:.1f}s)")
                    
                except Exception as e:
                    print(f"   ‚ùå Failed to load {filename}: {e}")
            
            if total_files_added == 0:
                print("‚ùå No audio files successfully loaded with PyDub")
                print("üîÑ Attempting FORCE BYPASS with simple file concatenation...")
                
                # FORCE BYPASS: Use FFmpeg directly via subprocess (no PyDub)
                try:
                    output_path = os.path.join(output_dir, "complete_merged_audio.mp3")
                    
                    # Try FFmpeg direct command first
                    import subprocess
                    import shutil
                    
                    # Check if ffmpeg is available (multiple locations)
                    ffmpeg_available = shutil.which('ffmpeg') is not None
                    
                    # Try common FFmpeg installation paths on Windows
                    if not ffmpeg_available:
                        common_paths = [
                            r"C:\ffmpeg\bin\ffmpeg.exe",
                            r"C:\Program Files\ffmpeg\bin\ffmpeg.exe", 
                            r"C:\Program Files (x86)\ffmpeg\bin\ffmpeg.exe",
                            r"C:\Users\%USERNAME%\AppData\Local\Microsoft\WinGet\Packages\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\ffmpeg-7.1.1-full_build\bin\ffmpeg.exe"
                        ]
                        
                        for path in common_paths:
                            expanded_path = os.path.expandvars(path)
                            if os.path.exists(expanded_path):
                                ffmpeg_cmd = expanded_path
                                ffmpeg_available = True
                                print(f"üéØ Found FFmpeg at: {expanded_path}")
                                break
                        else:
                            ffmpeg_cmd = 'ffmpeg'
                    
                    if ffmpeg_available:
                        print("üéØ Using FFmpeg direct command for concatenation...")
                        
                        # Create file list for FFmpeg
                        file_list_path = os.path.join(output_dir, "concat_list.txt")
                        with open(file_list_path, 'w', encoding='utf-8') as f:
                            for file_path in sorted_files:
                                normalized_path = os.path.normpath(file_path)
                                if os.path.exists(normalized_path):
                                    # FFmpeg expects forward slashes even on Windows
                                    ffmpeg_path = normalized_path.replace('\\', '/')
                                    f.write(f"file '{ffmpeg_path}'\n")
                        
                        # Run FFmpeg concatenation
                        cmd = [ffmpeg_cmd, '-f', 'concat', '-safe', '0', '-i', file_list_path, '-c', 'copy', output_path, '-y']
                        
                        result = subprocess.run(cmd, capture_output=True, text=True)
                        
                        # Clean up temp file
                        try:
                            os.remove(file_list_path)
                        except:
                            pass
                        
                        if result.returncode == 0:
                            files_concatenated = len([f for f in sorted_files if os.path.exists(os.path.normpath(f))])
                            print(f"‚úÖ FFmpeg SUCCESS: {files_concatenated} files merged to {output_path}")
                        else:
                            print(f"‚ùå FFmpeg failed: {result.stderr}")
                            ffmpeg_available = False
                    
                    if not ffmpeg_available:
                        print("üîÑ FFmpeg not available, trying Windows copy command...")
                        
                        # Fallback: Use Windows copy command for concatenation
                        files_concatenated = 0
                        temp_files = []
                        
                        for i, file_path in enumerate(sorted_files):
                            normalized_path = os.path.normpath(file_path)
                            if os.path.exists(normalized_path):
                                print(f"   üìé Processing: {os.path.basename(file_path)}")
                                files_concatenated += 1
                        
                        if files_concatenated > 0:
                            # Use copy command on Windows
                            files_str = ' + '.join([f'"{os.path.normpath(f)}"' for f in sorted_files if os.path.exists(os.path.normpath(f))])
                            copy_cmd = f'copy /b {files_str} "{output_path}"'
                            
                            result = subprocess.run(copy_cmd, shell=True, capture_output=True, text=True)
                            
                            if result.returncode == 0:
                                print(f"‚úÖ Windows COPY SUCCESS: {files_concatenated} files merged")
                                print(f"‚ö†Ô∏è Note: Duration may show incorrectly due to MP3 header issues")
                            else:
                                print(f"‚ùå Windows copy failed: {result.stderr}")
                                print("üîÑ Trying MP3 frame-level concatenation...")
                                
                                # Alternative: MP3 frame-level concatenation
                                try:
                                    with open(output_path, 'wb') as outfile:
                                        first_file = True
                                        for file_path in sorted_files:
                                            normalized_path = os.path.normpath(file_path)
                                            if os.path.exists(normalized_path):
                                                with open(normalized_path, 'rb') as infile:
                                                    data = infile.read()
                                                    
                                                    if first_file:
                                                        # Keep full first file including headers
                                                        outfile.write(data)
                                                        first_file = False
                                                    else:
                                                        # Skip ID3 headers for subsequent files (usually first 128 bytes)
                                                        # Find MP3 sync frame (0xFF 0xFB or 0xFF 0xFA)
                                                        sync_pos = 0
                                                        for i in range(min(1024, len(data) - 1)):
                                                            if data[i] == 0xFF and data[i+1] in [0xFB, 0xFA, 0xF3, 0xF2]:
                                                                sync_pos = i
                                                                break
                                                        
                                                        # Write from sync frame onwards
                                                        outfile.write(data[sync_pos:])
                                    
                                    print(f"‚úÖ MP3 FRAME SUCCESS: {files_concatenated} files merged with frame sync")
                                    
                                except Exception as frame_error:
                                    print(f"‚ùå MP3 frame concatenation failed: {frame_error}")
                                
                                # Last resort: Create a playlist file instead
                                playlist_path = os.path.join(output_dir, "complete_conversation_playlist.m3u")
                                with open(playlist_path, 'w', encoding='utf-8') as f:
                                    f.write("#EXTM3U\n")
                                    for file_path in sorted_files:
                                        if os.path.exists(os.path.normpath(file_path)):
                                            f.write(f"{os.path.basename(file_path)}\n")
                                
                                output_path = playlist_path
                                print(f"‚úÖ Created playlist file: {playlist_path}")
                                
                                # Show different success dialog for playlist
                                msg = QMessageBox()
                                msg.setIcon(QMessageBox.Information)
                                msg.setWindowTitle("üìù Playlist Created!")
                                msg.setText(f"‚úÖ Created playlist with {files_concatenated} audio files!")
                                msg.setInformativeText(f"üìÅ Saved to: {playlist_path}\n\nüí° Open this file with your music player to play all segments in order.")
                                msg.setStandardButtons(QMessageBox.Ok)
                                msg.exec_()
                                return output_path
                    
                    if files_concatenated > 0:
                        print(f"‚úÖ FORCE BYPASS SUCCESS: {files_concatenated} files concatenated to {output_path}")
                        
                        # Show success dialog
                        msg = QMessageBox()
                        msg.setIcon(QMessageBox.Information)
                        msg.setWindowTitle("üéâ Force Merge Success!")
                        msg.setText(f"‚úÖ Successfully merged {files_concatenated} audio files using FORCE BYPASS method!")
                        msg.setInformativeText(f"üìÅ Saved to: {output_path}\n\n‚ö†Ô∏è Note: Used binary concatenation due to PyDub codec issues.")
                        msg.setStandardButtons(QMessageBox.Ok)
                        msg.exec_()
                        
                        return output_path
                    else:
                        print("‚ùå FORCE BYPASS also failed - no files could be read")
                        return None
                        
                except Exception as bypass_error:
                    print(f"‚ùå FORCE BYPASS failed: {bypass_error}")
                    return None
            
            # Generate output filename with timestamp
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Try to get project name or use default
            project_name = getattr(self, 'current_project_name', 'voice_conversation')
            if hasattr(self, 'voice_studio_script_data') and self.voice_studio_script_data:
                # Try to extract title from script data
                if 'title' in self.voice_studio_script_data:
                    project_name = self.voice_studio_script_data['title']
                elif 'project_name' in self.voice_studio_script_data:
                    project_name = self.voice_studio_script_data['project_name']
            
            # Clean project name for filename
            clean_name = re.sub(r'[^\w\s-]', '', project_name)
            clean_name = re.sub(r'[-\s]+', '_', clean_name)
            
            output_filename = f"{clean_name}_complete_conversation_{timestamp}.mp3"
            merged_file_path = os.path.join(output_dir, output_filename)
            
            # Export merged audio
            print(f"üíæ Exporting complete conversation...")
            merged_audio.export(merged_file_path, format="mp3", bitrate="192k")
            
            # Calculate total duration
            total_duration = len(merged_audio) / 1000.0  # Convert to seconds
            minutes = int(total_duration // 60)
            seconds = int(total_duration % 60)
            
            # Log success summary
            print(f"üéâ MERGE COMPLETE!")
            print(f"   üìä Files merged: {total_files_added}")
            if missing_files:
                print(f"   ‚ö†Ô∏è Missing files: {len(missing_files)}")
                for missing in missing_files[:5]:  # Show first 5 missing files
                    print(f"      - {missing}")
                if len(missing_files) > 5:
                    print(f"      ... and {len(missing_files) - 5} more")
            
            print(f"   ‚è±Ô∏è Total duration: {minutes:02d}:{seconds:02d}")
            print(f"   üìÅ Saved: {output_filename}")
            
            return merged_file_path
            
        except ImportError:
            print("‚ùå pydub library not available - audio merging disabled")
            print("   üí° Install with: pip install pydub")
            return None
        except Exception as e:
            print(f"‚ùå Error merging audio files: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def manual_merge_audio(self):
        """Manual trigger ƒë·ªÉ g·ªôp audio files"""
        try:
            output_dir = self.voice_output_input.text() or "./voice_studio_output"
            
            if not os.path.exists(output_dir):
                QMessageBox.warning(self, "C·∫£nh b√°o", f"Th∆∞ m·ª•c output kh√¥ng t·ªìn t·∫°i: {output_dir}")
                return
            
            # Check if any audio files exist
            audio_files = glob.glob(os.path.join(output_dir, "segment_*.mp3"))
            print(f"üîç Looking for segment files in: {output_dir}")
            print(f"üéµ Found {len(audio_files)} segment files:")
            for audio_file in audio_files[:5]:  # Show first 5 files
                print(f"   - {os.path.basename(audio_file)}")
            if len(audio_files) > 5:
                print(f"   ... and {len(audio_files) - 5} more")
                
            if not audio_files:
                # Also check for any MP3 files
                all_mp3_files = glob.glob(os.path.join(output_dir, "*.mp3"))
                if all_mp3_files:
                    message = f"Kh√¥ng t√¨m th·∫•y file audio theo format segment_*.mp3!\n\n"
                    message += f"Tuy nhi√™n c√≥ {len(all_mp3_files)} file MP3 kh√°c trong th∆∞ m·ª•c:\n"
                    message += f"{output_dir}\n\n"
                    message += "H√£y ki·ªÉm tra l·∫°i ho·∫∑c t·∫°o voice v·ªõi ƒë·ªãnh d·∫°ng ƒë√∫ng."
                else:
                    message = f"Kh√¥ng t√¨m th·∫•y file audio n√†o ƒë·ªÉ g·ªôp!\n\n"
                    message += f"Th∆∞ m·ª•c: {output_dir}\n\n"
                    message += "H√£y t·∫°o voice tr∆∞·ªõc khi g·ªôp."
                QMessageBox.warning(self, "C·∫£nh b√°o", message)
                return
            
            # Show progress
            self.voice_progress_text.setText("ƒêang g·ªôp audio files...")
            QApplication.processEvents()
            
            # Perform merge
            merged_file = self.merge_all_voice_files(output_dir)
            
            if merged_file:
                # Success message
                filename = os.path.basename(merged_file)
                message = f"üéâ G·ªôp audio th√†nh c√¥ng!\n\n"
                message += f"üìÅ File: {filename}\n"
                message += f"üìç V·ªã tr√≠: {output_dir}\n\n"
                message += f"B·∫°n c√≥ mu·ªën nghe cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh kh√¥ng?"
                
                reply = QMessageBox.question(
                    self, "Th√†nh c√¥ng", message,
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.Yes
                )
                
                if reply == QMessageBox.Yes:
                    self.play_audio_file(merged_file)
                    
                self.voice_progress_text.setText(f"‚úÖ ƒê√£ g·ªôp: {filename}")
            else:
                QMessageBox.warning(self, "L·ªói", "Kh√¥ng th·ªÉ g·ªôp audio files. Xem console ƒë·ªÉ bi·∫øt chi ti·∫øt.")
                self.voice_progress_text.setText("‚ùå L·ªói g·ªôp audio")
                
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói g·ªôp audio:\n{str(e)}")
            self.voice_progress_text.setText("‚ùå L·ªói g·ªôp audio")
    
    def play_complete_conversation(self):
        """Ph√°t cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh g·∫ßn nh·∫•t"""
        try:
            output_dir = self.voice_output_input.text() or "./voice_studio_output"
            
            if not os.path.exists(output_dir):
                QMessageBox.warning(self, "C·∫£nh b√°o", f"Th∆∞ m·ª•c output kh√¥ng t·ªìn t·∫°i: {output_dir}")
                return
            
            # Find the most recent complete conversation file
            conversation_files = glob.glob(os.path.join(output_dir, "*_complete_conversation_*.mp3"))
            
            if not conversation_files:
                # Offer to create one
                reply = QMessageBox.question(
                    self, "Kh√¥ng t√¨m th·∫•y file", 
                    "Kh√¥ng t√¨m th·∫•y file cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh.\n\nB·∫°n c√≥ mu·ªën g·ªôp audio files hi·ªán t·∫°i th√†nh cu·ªôc h·ªôi tho·∫°i kh√¥ng?",
                    QMessageBox.Yes | QMessageBox.No,
                    QMessageBox.Yes
                )
                
                if reply == QMessageBox.Yes:
                    self.manual_merge_audio()
                return
            
            # Get the most recent file (by modification time)
            latest_file = max(conversation_files, key=os.path.getmtime)
            
            # Show file info and play
            filename = os.path.basename(latest_file)
            file_size = os.path.getsize(latest_file) / (1024 * 1024)  # MB
            
            # Get duration if possible
            duration_info = ""
            try:
                from pydub import AudioSegment
                audio = AudioSegment.from_mp3(latest_file)
                duration_seconds = len(audio) / 1000.0
                minutes = int(duration_seconds // 60)
                seconds = int(duration_seconds % 60)
                duration_info = f" ({minutes:02d}:{seconds:02d})"
            except:
                pass
            
            self.voice_progress_text.setText(f"‚ñ∂Ô∏è ƒêang ph√°t: {filename}{duration_info}")
            
            # Play the file
            self.play_audio_file(latest_file)
            
            # Show info message
            info = f"üéµ ƒêang ph√°t cu·ªôc h·ªôi tho·∫°i ho√†n ch·ªânh:\n\n"
            info += f"üìÅ File: {filename}\n"
            info += f"üìä Size: {file_size:.1f} MB{duration_info}\n"
            info += f"üìç ƒê∆∞·ªùng d·∫´n: {latest_file}"
            
            QMessageBox.information(self, "ƒêang ph√°t audio", info)
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói ph√°t audio:\n{str(e)}")
            self.voice_progress_text.setText("‚ùå L·ªói ph√°t audio")
    
    def generate_ai_request_form(self):
        """T·∫°o request form cho AI v·ªõi template mode selection"""
        template_mode = self.template_mode_combo.currentData() if hasattr(self, 'template_mode_combo') else 'standard'
        
        # Generate form based on selected template mode
        if template_mode == 'rapid':
            return self.generate_rapid_template_form()
        elif template_mode == 'standard':
            return self.generate_standard_template_form()
        elif template_mode == 'detailed':
            return self.generate_detailed_template_form()
        else:
            return self.generate_standard_template_form()  # Default fallback

    def generate_rapid_template_form(self):
        """Generate RAPID mode template (~150 tokens)"""
        template_content = """
# üöÄ RAPID MODE - T·∫°o Script Video JSON (Ultra Compact ~150 tokens)

## Request:
T·∫°o script video v·ªÅ "[TOPIC]" theo format JSON sau:

```json
{
  "segments": [
    {"id": 1, "dialogues": [
      {"speaker": "narrator", "text": "L·ªùi tho·∫°i narrator...", "emotion": "friendly"},
      {"speaker": "character1", "text": "L·ªùi tho·∫°i character...", "emotion": "excited"}
    ]}
  ],
  "characters": [
    {"id": "narrator", "name": "Narrator", "gender": "neutral"},
    {"id": "character1", "name": "Character", "gender": "female"}
  ]
}
```

**RULES**: 
- segments[].dialogues[]: speaker, text, emotion (required)
- characters[]: id, name, gender (required)
- Emotions: neutral, happy, sad, excited, calm, dramatic
- Vietnamese text with proper punctuation
- 3-5 segments, 2-3 characters max

**Focus on CONTENT QUALITY** - you have +1350 extra tokens for story development!
"""
        self.show_ai_request_dialog("RAPID Mode Template", template_content, 150)

    def generate_standard_template_form(self):
        """Generate STANDARD mode template (~400 tokens)"""
        template_content = """
# üìù STANDARD MODE - T·∫°o Script Video JSON (Balanced ~400 tokens)

## Request:
T·∫°o script video v·ªÅ "[TOPIC]" theo format JSON sau:

```json
{
  "project": {"title": "Story Title", "duration": 60},
  "segments": [
    {
      "id": 1,
      "title": "Scene name",
      "dialogues": [
        {
          "speaker": "narrator",
          "text": "N·ªôi dung v·ªõi d·∫•u c√¢u chu·∫©n Ti·∫øng Vi·ªát",
          "emotion": "friendly",
          "pause_after": 1.0,
          "emphasis": ["t·ª´ kh√≥a"]
        }
      ]
    }
  ],
  "characters": [
    {
      "id": "narrator", 
      "name": "Character Name",
      "gender": "neutral|female|male",
      "default_emotion": "friendly"
    }
  ]
}
```

**Enhanced emotions**: neutral, gentle, contemplative, cheerful, excited, surprised, sorrowful, angry, friendly, happy, sad, mysterious, dramatic, confident, worried, calm, energetic, serious.

**Parameters**:
- emotion: Emotion keyword (e.g., friendly, excited, contemplative)
- pause_after: 0.0-5.0 seconds (optional)
- emphasis: Array of keywords to highlight (optional)
- gender: neutral/female/male

**Focus on CHARACTER DEVELOPMENT** - you have +1100 extra tokens for richer dialogues!
"""
        self.show_ai_request_dialog("STANDARD Mode Template", template_content, 400)

    def generate_detailed_template_form(self):
        """Generate DETAILED mode template (~800 tokens)"""
        template_content = """
# üìö DETAILED MODE - T·∫°o Script Video JSON (Full Features ~800 tokens)

## Request:
T·∫°o script video v·ªÅ "[TOPIC]" theo Enhanced Format 2.0:

```json
{
  "project": {
    "title": "Story Title",
    "description": "Story description",
    "total_duration": 60,
    "target_audience": "adult",
    "style": "educational",
    "created_date": "2024-01-20"
  },
  "segments": [
    {
      "id": 1,
      "title": "Scene name",
      "script": "Scene description",
      "image_prompt": "Visual description for AI image generation",
      "mood": "upbeat",
      "background_music": "energetic",
      "dialogues": [
        {
          "speaker": "narrator",
          "text": "Dialogue with proper Vietnamese punctuation and emphasis",
          "emotion": "friendly",
          "pause_after": 0.5,
          "emphasis": ["key", "words"]
        }
      ],
      "duration": 12,
      "transition": "fade",
      "camera_movement": "zoom_in"
    }
  ],
  "characters": [
    {
      "id": "narrator",
      "name": "Character Name",
      "description": "Character description and role",
      "gender": "neutral",
      "age_range": "adult",
      "personality": "professional, warm, engaging",
      "voice_characteristics": "clear, moderate_pace",
      "suggested_voice": "vi-VN-Wavenet-C",
      "default_emotion": "friendly"
    }
  ],
  "audio_settings": {
    "crossfade_duration": 0.3,
    "normalize_volume": true,
    "output_format": "mp3"
  },
  "metadata": {
    "version": "2.0",
    "language": "vi-VN",
    "content_rating": "G",
    "tags": ["educational"]
  }
}
```

**Full emotion list**: neutral, gentle, contemplative, cheerful, excited, surprised, sorrowful, angry, fierce, pleading, friendly, happy, sad, mysterious, dramatic, confident, worried, calm, energetic, romantic, serious, playful.

**Advanced features**:
- emotion: Rich emotion keywords (friendly, excited, contemplative, etc.)
- pause_after: 0.0-5.0 seconds for natural timing
- emphasis: Array of keywords to highlight for better delivery
- camera_movement, transitions, background_music
- Complete character personalities and voice characteristics

**Focus on CINEMATIC STORYTELLING** - you have +700 extra tokens for complex plot development!
"""
        self.show_ai_request_dialog("DETAILED Mode Template", template_content, 800)

    def show_ai_request_dialog(self, title, content, token_count):
        """Show AI request template in dialog with copy functionality"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, QTextEdit
        
        dialog = QDialog(self)
        dialog.setWindowTitle(title)
        dialog.setFixedSize(800, 700)
        
        layout = QVBoxLayout()
        
        # Header with token info
        header_layout = QHBoxLayout()
        header_label = QLabel(f"üìã {title}")
        header_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #007AFF;")
        
        token_label = QLabel(f"üí° Template size: ~{token_count} tokens")
        token_label.setStyleSheet("color: #28CD41; font-weight: bold;")
        
        savings_label = QLabel(f"üöÄ Story space: +{1500-token_count} tokens")
        savings_label.setStyleSheet("color: #FF6B35; font-weight: bold;")
        
        header_layout.addWidget(header_label)
        header_layout.addStretch()
        header_layout.addWidget(token_label)
        header_layout.addWidget(savings_label)
        layout.addLayout(header_layout)
        
        # Content area
        content_area = QTextEdit()
        content_area.setPlainText(content.strip())
        content_area.setFont(QFont("Courier", 10))
        layout.addWidget(content_area)
        
        # Buttons
        button_layout = QHBoxLayout()
        
        copy_btn = QPushButton("üìã Copy Template")
        copy_btn.setStyleSheet("""
            QPushButton {
                background-color: #5856D6;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 6px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #4B49C8;
            }
        """)
        copy_btn.clicked.connect(lambda: self.copy_to_clipboard(content_area.toPlainText()))
        
        save_btn = QPushButton("üíæ Save Template")
        save_btn.clicked.connect(lambda: self.save_ai_request_template(content_area.toPlainText()))
        
        close_btn = QPushButton("‚ùå Close")
        close_btn.clicked.connect(dialog.close)
        
        button_layout.addWidget(copy_btn)
        button_layout.addWidget(save_btn)
        button_layout.addStretch()
        button_layout.addWidget(close_btn)
        
        layout.addLayout(button_layout)
        dialog.setLayout(layout)
        dialog.exec()
    
    def save_ai_request_template(self, template_content):
        """Save AI request template to file"""
        try:
            file_path, _ = QFileDialog.getSaveFileName(
                self, 
                "Save AI Request Template",
                "./ai_request_template.json",
                "JSON Files (*.json);;All Files (*)"
            )
            
            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(template_content)
                
                QMessageBox.information(
                    self, 
                    "ƒê√£ l∆∞u", 
                    f"AI Request Template ƒë√£ ƒë∆∞·ª£c l∆∞u:\n{file_path}\n\nB·∫°n c√≥ th·ªÉ chia s·∫ª file n√†y v·ªõi AI ƒë·ªÉ t·∫°o script ƒë√∫ng format."
                )
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói l∆∞u file:\n{str(e)}")
    
    # ========== CHATTERBOX MANUAL CONTROLS ==========
    
    def toggle_chatterbox_manual_controls(self, enabled):
        """Toggle hi·ªÉn th·ªã manual controls cho Chatterbox"""
        self.chatterbox_manual_widget.setVisible(enabled)
        if enabled:
            self.populate_character_settings_table()
    
    def update_emotion_label(self, value):
        """C·∫≠p nh·∫≠t label emotion t·ª´ slider"""
        emotion_value = value / 100.0  # Convert 0-300 to 0.0-3.0
        self.emotion_label.setText(f"{emotion_value:.1f}")
    
    def update_speed_label(self, value):
        """C·∫≠p nh·∫≠t label speed t·ª´ slider"""
        speed_value = value / 100.0  # Convert 50-200 to 0.5-2.0
        self.speed_label.setText(f"{speed_value:.1f}x")
    
    def populate_character_settings_table(self):
        """Populate b·∫£ng settings cho t·ª´ng nh√¢n v·∫≠t v·ªõi CFG Weight v√† Voice selection - Enhanced Format 2.0 Support"""
        if not self.voice_studio_script_data:
            return
        
        characters = self.voice_studio_script_data['characters']
        # Enhanced Format 2.0 detection
        has_enhanced_features = any(key in self.voice_studio_script_data for key in ['project', 'audio_settings', 'metadata'])
        
        self.character_settings_table.setRowCount(len(characters))
        
        for i, character in enumerate(characters):
            char_id = character['id']
            
            # Character name v·ªõi enhanced info
            display_name = character['name']
            if has_enhanced_features and 'description' in character:
                display_name += f" ({character['description'][:20]}...)" if len(character.get('description', '')) > 20 else f" ({character.get('description', '')})"
            
            name_item = QTableWidgetItem(display_name)
            name_item.setFlags(name_item.flags() & ~Qt.ItemIsEditable)
            name_item.setToolTip(character.get('description', character['name']))
            self.character_settings_table.setItem(i, 0, name_item)
            
            # Simplified: Only use emotion keywords now
            default_emotion = character.get('default_emotion', 'friendly')
            
            # Emotion input field v·ªõi default emotion
            emotion_input = QLineEdit()
            emotion_input.setText(str(default_emotion))
            emotion_input.setAlignment(Qt.AlignCenter)
            emotion_input.setMaximumWidth(60)
            emotion_input.setStyleSheet("""
                QLineEdit {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QLineEdit:focus {
                    border: 2px solid #007AFF;
                }
            """)
            emotion_input.textChanged.connect(
                lambda text, cid=char_id: self.update_character_emotion_from_input(cid, text)
            )
            self.character_settings_table.setCellWidget(i, 1, emotion_input)
            
            # Enhanced Format 2.0: Use default_speed ho·∫∑c fallback to 1.0  
            default_speed = character.get('default_speed', 1.0)
            
            # Speed input field v·ªõi Enhanced Format defaults
            speed_input = QLineEdit()
            speed_input.setText(str(default_speed))
            speed_input.setAlignment(Qt.AlignCenter)
            speed_input.setMaximumWidth(60)
            speed_input.setStyleSheet("""
                QLineEdit {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QLineEdit:focus {
                    border: 2px solid #007AFF;
                }
            """)
            speed_input.textChanged.connect(
                lambda text, cid=char_id: self.update_character_speed_from_input(cid, text)
            )
            self.character_settings_table.setCellWidget(i, 2, speed_input)
            
            # CFG Weight input field (NEW) - Fix m√†u ƒëen
            cfg_weight_input = QLineEdit()
            cfg_weight_input.setText("0.5")
            cfg_weight_input.setAlignment(Qt.AlignCenter)
            cfg_weight_input.setMaximumWidth(60)
            cfg_weight_input.setStyleSheet("""
                QLineEdit {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QLineEdit:focus {
                    border: 2px solid #007AFF;
                }
            """)
            cfg_weight_input.textChanged.connect(
                lambda text, cid=char_id: self.update_character_cfg_weight_from_input(cid, text)
            )
            self.character_settings_table.setCellWidget(i, 3, cfg_weight_input)
            
            # Voice selection combo (NEW) - Fix dropdown ƒëen
            voice_combo = QComboBox()
            voice_combo.setStyleSheet("""
                QComboBox {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QComboBox::drop-down {
                    background-color: white;
                }
                QComboBox::down-arrow {
                    color: black;
                }
                QComboBox QAbstractItemView {
                    background-color: white;
                    color: black;
                    selection-background-color: #007AFF;
                    selection-color: white;
                }
            """)
            
            # Always use fallback voices ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ data
            fallback_voices = [
                ("üë© Young Female (female)", "female_young"),
                ("üë® Young Male (male)", "male_young"),
                ("üó£Ô∏è Narrator (neutral)", "neutral_narrator"),
                ("üë© Mature Female (female)", "female_mature"),
                ("üë® Mature Male (male)", "male_mature"),
                ("üë© Gentle Female (female)", "female_gentle"),
                ("üë® Deep Male (male)", "male_deep"),
                ("üë∂ Child Voice (neutral)", "child_voice"),
                ("üë¥ Elder Voice (neutral)", "elder_voice"),
                ("üé§ Voice Cloning (variable)", "cloned")
            ]
            
            for display, voice_id in fallback_voices:
                voice_combo.addItem(display, voice_id)
            
            # Enhanced Format 2.0: Use suggested_voice ho·∫∑c default selection
            default_voice_index = 0  # Default to Young Female
            if 'suggested_voice' in character:
                suggested_voice = character['suggested_voice']
                print(f"üéØ Character {character['name']} suggests voice: {suggested_voice}")
                
                # Try to map suggested voice to fallback voice
                voice_mapping = {
                    'vi-VN-Wavenet-A': 0,  # Young Female
                    'vi-VN-Wavenet-C': 0,  # Young Female
                    'vi-VN-Standard-A': 0,  # Young Female
                    'vi-VN-Standard-C': 0,  # Young Female
                    'vi-VN-Wavenet-B': 1,  # Young Male
                    'vi-VN-Wavenet-D': 1,  # Young Male
                    'vi-VN-Standard-B': 1,  # Young Male
                    'vi-VN-Standard-D': 1,  # Young Male
                }
                
                # Map gender to appropriate voice
                if 'gender' in character:
                    gender = character['gender'].lower()
                    age_range = character.get('age_range', 'young_adult')
                    
                    if gender == 'female':
                        if age_range in ['young_adult', 'teen']:
                            default_voice_index = 0  # Young Female
                        else:
                            default_voice_index = 3  # Mature Female
                    elif gender == 'male':
                        if age_range in ['young_adult', 'teen']:
                            default_voice_index = 1  # Young Male
                        else:
                            default_voice_index = 4  # Mature Male
                    elif gender == 'neutral':
                        default_voice_index = 2  # Narrator
                    elif gender == 'child':
                        default_voice_index = 7  # Child Voice
                    elif gender == 'elderly':
                        default_voice_index = 8  # Elder Voice
                
                # Override with direct voice mapping if available
                if suggested_voice in voice_mapping:
                    default_voice_index = voice_mapping[suggested_voice]
            
            voice_combo.setCurrentIndex(default_voice_index)
            
            voice_combo.currentIndexChanged.connect(
                lambda index, cid=char_id, combo=voice_combo: self.update_character_voice(cid, combo.currentData())
            )
            
            # Voice Mode selector (NEW) - Ch·ªçn gi·ªØa Voice Selection vs Voice Clone
            # NOTE: Voice Prompt b·ªã lo·∫°i b·ªè v√¨ ChatterboxTTS kh√¥ng h·ªó tr·ª£ text prompt
            mode_combo = QComboBox()
            mode_combo.setMaximumWidth(120)
            mode_combo.addItem("üó£Ô∏è Voice", "voice_selection")
            mode_combo.addItem("üé§ Clone", "voice_clone")
            mode_combo.setCurrentIndex(0)  # Default to voice selection
            mode_combo.setStyleSheet("""
                QComboBox {
                    background-color: white;
                    border: 1px solid #ccc;
                    border-radius: 4px;
                    padding: 2px;
                    color: black;
                }
                QComboBox::drop-down {
                    border: none;
                }
                QComboBox::down-arrow {
                    color: black;
                }
                QComboBox QAbstractItemView {
                    background-color: white;
                    color: black;
                    selection-background-color: #007AFF;
                    selection-color: white;
                }
            """)
            mode_combo.currentIndexChanged.connect(
                lambda index, cid=char_id, combo=mode_combo: self.update_character_voice_mode(cid, combo.currentData())
            )
            self.character_settings_table.setCellWidget(i, 4, mode_combo)

            # Stacked widget ƒë·ªÉ chuy·ªÉn ƒë·ªïi gi·ªØa Voice/Prompt/Clone
            stacked_widget = QStackedWidget()
            stacked_widget.setMaximumHeight(30)
            
            # 1. Voice Selection Widget
            voice_widget = QWidget()
            voice_layout = QHBoxLayout(voice_widget)
            voice_layout.setContentsMargins(2, 2, 2, 2)
            voice_layout.addWidget(voice_combo)
            
            # 2. Voice Clone Widget (moved up, prompt removed)
            
            clone_widget = QWidget()
            clone_layout = QHBoxLayout(clone_widget)
            clone_layout.setContentsMargins(2, 2, 2, 2)
            clone_layout.setSpacing(4)
            
            voice_clone_btn = QPushButton("üéµ Ch·ªçn file")
            voice_clone_btn.setMaximumWidth(80)
            voice_clone_btn.setToolTip(f"Ch·ªçn audio file l√†m voice sample cho {character['name']}")
            voice_clone_btn.clicked.connect(lambda checked, cid=char_id: self.select_character_voice_clone_folder(cid))
            clone_layout.addWidget(voice_clone_btn)
            
            # Add widgets to stack (only 2 now)
            stacked_widget.addWidget(voice_widget)     # Index 0 - Voice Selection
            stacked_widget.addWidget(clone_widget)     # Index 1 - Voice Clone
            stacked_widget.setCurrentIndex(0)  # Default to voice selection
            
            self.character_settings_table.setCellWidget(i, 5, stacked_widget)
            
            # Quick action button (test for clone, etc.)
            quick_btn = QPushButton("üîß")
            quick_btn.setMaximumWidth(30)
            quick_btn.setToolTip("Quick actions")
            quick_btn.clicked.connect(lambda checked, cid=char_id: self.show_voice_quick_actions(cid))
            self.character_settings_table.setCellWidget(i, 6, quick_btn)
            
            # Status indicator
            status_label = QLabel("üó£Ô∏è")
            status_label.setMaximumWidth(30)
            status_label.setAlignment(Qt.AlignCenter)
            status_label.setToolTip("Voice Selection mode")
            self.character_settings_table.setCellWidget(i, 7, status_label)
            
            # Preview button
            preview_btn = QPushButton("üéß")
            preview_btn.setMaximumWidth(40)
            preview_btn.setToolTip(f"Preview {character['name']}")
            preview_btn.clicked.connect(lambda checked, cid=char_id: self.preview_character_with_settings(cid))
            self.character_settings_table.setCellWidget(i, 8, preview_btn)
            
            # Initialize character settings v·ªõi voice mode
            self.character_chatterbox_settings[char_id] = {
                'emotion': 1.0,
                'speed': 1.0,
                'cfg_weight': 0.5,
                'voice_mode': 'voice_selection',  # NEW: voice_selection | voice_clone
                'voice_id': 'female_young',  # For voice_selection mode
                'voice_clone_path': None,  # For voice_clone mode
                'voice_clone_status': 'none'  # Track clone status
            }
            
            # Store widget references for mode switching
            if not hasattr(self, 'character_widgets'):
                self.character_widgets = {}
            self.character_widgets[char_id] = {
                'mode_combo': mode_combo,
                'stacked_widget': stacked_widget,
                'voice_combo': voice_combo,
                'voice_clone_btn': voice_clone_btn,
                'status_label': status_label,
                'quick_btn': quick_btn
            }
    
    def update_character_emotion_from_input(self, char_id, text):
        """C·∫≠p nh·∫≠t emotion cho nh√¢n v·∫≠t c·ª• th·ªÉ t·ª´ input (now string-based)"""
        # Emotion is now a string keyword (friendly, excited, etc.), not numeric
        if text.strip():  # Only update if text is not empty
            if char_id not in self.character_chatterbox_settings:
                self.character_chatterbox_settings[char_id] = {}
            self.character_chatterbox_settings[char_id]['emotion'] = text.strip()
        # No try/catch needed since emotion is now just a string
    
    # Speed field has been removed from simplified JSON structure
    # def update_character_speed_from_input(self, char_id, text):
    #     """Speed no longer supported - simplified to emotion only"""
    #     pass
    
    def update_character_cfg_weight_from_input(self, char_id, text):
        """C·∫≠p nh·∫≠t CFG weight cho nh√¢n v·∫≠t c·ª• th·ªÉ t·ª´ input"""
        try:
            value = float(text)
            value = max(0.0, min(1.0, value))  # Clamp to 0.0-1.0
            if char_id not in self.character_chatterbox_settings:
                self.character_chatterbox_settings[char_id] = {}
            self.character_chatterbox_settings[char_id]['cfg_weight'] = value
        except ValueError:
            pass  # Ignore invalid input
    
    def update_character_voice(self, char_id, voice_id):
        """C·∫≠p nh·∫≠t voice cho nh√¢n v·∫≠t c·ª• th·ªÉ v√† t·ª± ƒë·ªông adjust parameters theo gender"""
        if char_id not in self.character_chatterbox_settings:
            self.character_chatterbox_settings[char_id] = {}
        
        # L∆∞u voice_id
        self.character_chatterbox_settings[char_id]['voice_id'] = voice_id
        
        # üéØ AUTO-ADJUST PARAMETERS d·ª±a tr√™n voice gender (nh∆∞ AI Gender Analysis)
        voice_gender_params = self._get_voice_gender_parameters(voice_id)
        
        # C·∫≠p nh·∫≠t parameters trong settings (emotion is now string)
        self.character_chatterbox_settings[char_id]['emotion'] = voice_gender_params['emotion']  # String now
        self.character_chatterbox_settings[char_id]['speed'] = voice_gender_params['speed'] 
        self.character_chatterbox_settings[char_id]['cfg_weight'] = voice_gender_params['cfg_weight']
        
        # üîÑ C·∫¨P NH·∫¨T UI: T√¨m v√† update input fields trong table
        for row in range(self.character_settings_table.rowCount()):
            name_item = self.character_settings_table.item(row, 0)
            if name_item and name_item.text() == char_id:
                # Update emotion input (now string)
                emotion_input = self.character_settings_table.cellWidget(row, 1)
                if emotion_input:
                    emotion_input.setText(str(voice_gender_params['emotion']))  # No .1f formatting
                
                # Update speed input  
                speed_input = self.character_settings_table.cellWidget(row, 2)
                if speed_input:
                    speed_input.setText(f"{voice_gender_params['speed']:.1f}")
                
                # Update cfg weight input
                cfg_weight_input = self.character_settings_table.cellWidget(row, 3)
                if cfg_weight_input:
                    cfg_weight_input.setText(f"{voice_gender_params['cfg_weight']:.2f}")
                
                break
        
        print(f"üé≠ Voice changed for {char_id}: {voice_id}")
        print(f"   ‚ú® Auto-adjusted: emotion={voice_gender_params['emotion']}, speed={voice_gender_params['speed']:.1f}, cfg_weight={voice_gender_params['cfg_weight']:.2f}")
    
    def update_character_voice_mode(self, char_id, voice_mode):
        """C·∫≠p nh·∫≠t voice mode cho nh√¢n v·∫≠t v√† switch UI accordingly"""
        if char_id not in self.character_chatterbox_settings:
            self.character_chatterbox_settings[char_id] = {}
        
        # Update voice mode
        self.character_chatterbox_settings[char_id]['voice_mode'] = voice_mode
        
        # Get widget references
        if hasattr(self, 'character_widgets') and char_id in self.character_widgets:
            widgets = self.character_widgets[char_id]
            stacked_widget = widgets['stacked_widget']
            status_label = widgets['status_label']
            quick_btn = widgets['quick_btn']
            
            # Switch stacked widget and update status
            if voice_mode == 'voice_selection':
                stacked_widget.setCurrentIndex(0)  # Voice combo
                status_label.setText("üó£Ô∏è")
                status_label.setToolTip("Voice Selection mode - ch·ªçn gi·ªçng c√≥ s·∫µn")
                quick_btn.setToolTip("Voice options")
                print(f"üó£Ô∏è {char_id}: Switched to VOICE SELECTION mode")
                
            elif voice_mode == 'voice_clone':
                stacked_widget.setCurrentIndex(1)  # Voice clone button
                status_label.setText("üé§")
                status_label.setToolTip("Voice Clone mode - nh√¢n b·∫£n gi·ªçng t·ª´ m·∫´u audio")
                quick_btn.setToolTip("Test voice clone")
                print(f"üé§ {char_id}: Switched to VOICE CLONE mode")
    
    def _get_voice_gender_parameters(self, voice_id):
        """L·∫•y parameters t·ªëi ∆∞u cho voice d·ª±a tr√™n gender (nh∆∞ AI Gender Analysis system)"""
        
        # üë© FEMALE VOICES - nh·∫π nh√†ng, bi·ªÉu c·∫£m h∆°n
        female_voices = ['female_young', 'female_mature', 'female_gentle']
        if voice_id in female_voices:
            return {
                'emotion': 'gentle',    # Emotion keyword
                'speed': 0.95,          # Ch·∫≠m h∆°n m·ªôt ch√∫t  
                'cfg_weight': 0.6       # Ch·∫•t l∆∞·ª£ng cao
            }
        
        # üë® MALE VOICES - m·∫°nh m·∫Ω, √≠t bi·ªÉu c·∫£m
        male_voices = ['male_young', 'male_mature', 'male_deep'] 
        if voice_id in male_voices:
            return {
                'emotion': 'confident', # Strong emotion keyword
                'speed': 1.05,          # Nhanh h∆°n m·ªôt ch√∫t
                'cfg_weight': 0.4       # C√¢n b·∫±ng
            }
        
        # üó£Ô∏è NEUTRAL VOICES - c√¢n b·∫±ng
        neutral_voices = ['neutral_narrator', 'neutral_child', 'neutral_elder']
        if voice_id in neutral_voices:
            return {
                'emotion': 'friendly',  # C√¢n b·∫±ng emotion
                'speed': 1.0,           # B√¨nh th∆∞·ªùng  
                'cfg_weight': 0.5       # C√¢n b·∫±ng
            }
        
        # üé§ VOICE CLONING - default balanced
        if voice_id == 'cloned':
            return {
                'emotion': 'friendly',  # Default emotion
                'speed': 1.0,           # B√¨nh th∆∞·ªùng
                'cfg_weight': 0.5       # C√¢n b·∫±ng
            }
        
        # Default fallback
        return {
            'emotion': 'friendly',  # String emotion
            'speed': 1.0, 
            'cfg_weight': 0.5
        }
    
    def preview_character_with_settings(self, char_id):
        """Preview gi·ªçng v·ªõi settings c·ª• th·ªÉ c·ªßa nh√¢n v·∫≠t"""
        try:
            # Validate v√† hi·ªÉn th·ªã priority logic
            voice_mode = self.validate_character_voice_settings(char_id)
            
            settings = self.character_chatterbox_settings.get(char_id, {})
            emotion = settings.get('emotion', 1.0)
            speed = settings.get('speed', 1.0) 
            cfg_weight = settings.get('cfg_weight', 0.5)
            voice_id = settings.get('voice_id', 'female_young')
            voice_clone_path = settings.get('voice_clone_path', None)
            voice_prompt = settings.get('voice_prompt', '').strip()
            
            char_name = self.get_character_name_by_id(char_id)
            
            # T·∫°o preview text d·ª±a tr√™n voice mode
            if voice_mode == 'clone':
                preview_text = f"Xin ch√†o, t√¥i l√† {char_name}. ƒê√¢y l√† gi·ªçng ƒë∆∞·ª£c clone t·ª´ voice samples."
            else:
                # T√¨m voice display name
                voice_display_name = voice_id
                fallback_voices = [
                    ("üë© Young Female (female)", "female_young"),
                    ("üë® Young Male (male)", "male_young"),
                    ("üó£Ô∏è Narrator (neutral)", "neutral_narrator"),
                    ("üë© Mature Female (female)", "female_mature"),
                    ("üë® Mature Male (male)", "male_mature"),
                    ("üë© Gentle Female (female)", "female_gentle"),
                    ("üë® Deep Male (male)", "male_deep"),
                    ("üë∂ Child Voice (neutral)", "child_voice"),
                    ("üë¥ Elder Voice (neutral)", "elder_voice"),
                    ("üé§ Voice Cloning (variable)", "cloned")
                ]
                
                for display, vid in fallback_voices:
                    if vid == voice_id:
                        voice_display_name = display
                        break
                
                preview_text = f"Xin ch√†o, t√¥i l√† {char_name}. ƒê√¢y l√† gi·ªçng {voice_display_name} v·ªõi emotion {emotion}, speed {speed:.1f}x v√† CFG weight {cfg_weight:.2f}"
            
            # Generate preview
            import tempfile
            temp_dir = tempfile.mkdtemp()
            preview_path = os.path.join(temp_dir, f"preview_{char_id}.mp3")
                
            result = self.voice_generator.generate_voice_chatterbox(
                text=preview_text,
                save_path=preview_path,
                voice_sample_path=voice_clone_path if voice_mode == 'clone' else None,
                emotion_exaggeration=emotion,
                speed=speed,
                voice_name=voice_id if voice_mode == 'selection' else None,
                cfg_weight=cfg_weight
            )
            
            if result.get('success'):
                self.play_audio_file(preview_path)
                from PySide6.QtWidgets import QMessageBox
                
                # T·∫°o message v·ªõi priority info
                message = f"Character: {char_name}\n"
                message += f"Mode: {voice_mode.upper()}\n\n"
                
                if voice_mode == 'clone':
                    message += f"Voice Clone: {voice_clone_path}\n"
                else:
                    message += f"Voice: {voice_display_name}\n"
                
                message += f"Emotion: {emotion:.1f}\n"
                message += f"Speed: {speed:.1f}x\n"
                message += f"CFG Weight: {cfg_weight:.2f}\n"
                message += f"\nü§ñ Generated by Chatterbox TTS"
                
                QMessageBox.information(self, "üéß Preview Voice", message)
            else:
                from PySide6.QtWidgets import QMessageBox
                QMessageBox.warning(self, "‚ùå L·ªói Preview", f"Kh√¥ng th·ªÉ t·∫°o preview:\n{result.get('error', 'Unknown error')}")
                
        except Exception as e:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.critical(self, "‚ùå L·ªói Critical", f"L·ªói preview voice:\n{str(e)}")
    
    def update_character_voice_prompt(self, char_id, prompt_text):
        """C·∫≠p nh·∫≠t voice prompt cho nh√¢n v·∫≠t c·ª• th·ªÉ"""
        if char_id not in self.character_chatterbox_settings:
            self.character_chatterbox_settings[char_id] = {}
        
        self.character_chatterbox_settings[char_id]['voice_prompt'] = prompt_text
        
        if prompt_text.strip():
            print(f"üí¨ Voice prompt updated for {self.get_character_name_by_id(char_id)}: '{prompt_text[:50]}...'")
        else:
            print(f"üí¨ Voice prompt cleared for {self.get_character_name_by_id(char_id)}")
    
    def show_voice_quick_actions(self, char_id):
        """Hi·ªÉn th·ªã quick actions cho voice mode hi·ªán t·∫°i"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_mode = settings.get('voice_mode', 'voice_selection')
        char_name = self.get_character_name_by_id(char_id)
        
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, QMessageBox
        
        dialog = QDialog(self)
        dialog.setWindowTitle(f"Quick Actions - {char_name}")
        dialog.setFixedSize(400, 300)
        
        layout = QVBoxLayout()
        
        if voice_mode == 'voice_selection':
            layout.addWidget(QLabel(f"üó£Ô∏è Voice Selection Mode - {char_name}"))
            layout.addWidget(QLabel("Quick actions for voice selection:"))
            
            # Auto-optimize button
            optimize_btn = QPushButton("üéØ Auto-optimize Parameters")
            optimize_btn.clicked.connect(lambda: self.auto_optimize_voice_params(char_id, dialog))
            layout.addWidget(optimize_btn)
            
            # Reset to defaults
            reset_btn = QPushButton("üîÑ Reset to Defaults")
            reset_btn.clicked.connect(lambda: self.reset_voice_params(char_id, dialog))
            layout.addWidget(reset_btn)
            
        elif voice_mode == 'voice_clone':
            layout.addWidget(QLabel(f"üé§ Voice Clone Mode - {char_name}"))
            layout.addWidget(QLabel("Quick actions for voice cloning:"))
            
            # Test clone button
            test_btn = QPushButton("üß™ Test Voice Clone")
            test_btn.clicked.connect(lambda: self.test_voice_clone(char_id, dialog))
            layout.addWidget(test_btn)
            
            # Clear clone path
            clear_btn = QPushButton("üóëÔ∏è Clear Clone Path")
            clear_btn.clicked.connect(lambda: self.clear_voice_clone_path(char_id, dialog))
            layout.addWidget(clear_btn)
        
        # Close button
        close_btn = QPushButton("‚ùå Close")
        close_btn.clicked.connect(dialog.close)
        layout.addWidget(close_btn)
        
        dialog.setLayout(layout)
        dialog.exec()
    
    def auto_optimize_voice_params(self, char_id, dialog):
        """T·ª± ƒë·ªông t·ªëi ∆∞u parameters cho voice"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_id = settings.get('voice_id', 'female_young')
        
        # Get optimized params
        optimized_params = self._get_voice_gender_parameters(voice_id)
        
        # Update settings
        self.character_chatterbox_settings[char_id].update(optimized_params)
        
        # ‚úÖ FIX: Update UI TABLE DIRECTLY ƒë·ªÉ hi·ªÉn th·ªã changes
        self._update_character_table_row(char_id, optimized_params)
        
        QMessageBox.information(dialog, "‚úÖ Optimized", 
                              f"Parameters optimized for {voice_id}:\n"
                              f"Emotion: {optimized_params['emotion']:.1f}\n"
                              f"Speed: {optimized_params['speed']:.1f}\n"
                              f"CFG Weight: {optimized_params['cfg_weight']:.2f}")
        dialog.close()
    
    def reset_voice_params(self, char_id, dialog):
        """Reset voice parameters v·ªÅ defaults"""
        default_params = {
            'emotion': 1.0,
            'speed': 1.0,
            'cfg_weight': 0.5
        }
        self.character_chatterbox_settings[char_id].update(default_params)
        
        # ‚úÖ FIX: Update UI TABLE DIRECTLY ƒë·ªÉ hi·ªÉn th·ªã changes
        self._update_character_table_row(char_id, default_params)
        
        QMessageBox.information(dialog, "üîÑ Reset", "Parameters reset to defaults")
        dialog.close()
    
    def test_voice_clone(self, char_id, dialog):
        """Test voice clone v·ªõi sample text"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_clone_path = settings.get('voice_clone_path')
        
        if not voice_clone_path:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(dialog, "‚ö†Ô∏è Warning", "No voice clone path selected!")
            return
        
        # Test v·ªõi sample text
        char_name = self.get_character_name_by_id(char_id)
        test_text = f"Xin ch√†o, t√¥i l√† {char_name}. ƒê√¢y l√† test voice cloning."
        
        import tempfile
        temp_dir = tempfile.mkdtemp()
        test_path = os.path.join(temp_dir, f"test_clone_{char_id}.mp3")
        
        result = self.voice_generator.generate_voice_chatterbox(
            text=test_text,
            save_path=test_path,
            voice_sample_path=voice_clone_path,
            emotion_exaggeration=settings.get('emotion', 1.0),
            speed=settings.get('speed', 1.0),
            cfg_weight=settings.get('cfg_weight', 0.5)
        )
        
        if result.get('success'):
            self.play_audio_file(test_path)
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.information(dialog, "‚úÖ Test Success", "Voice clone test completed!")
        else:
            from PySide6.QtWidgets import QMessageBox
            QMessageBox.warning(dialog, "‚ùå Test Failed", f"Test failed: {result.get('error', 'Unknown error')}")
    
    def clear_voice_clone_path(self, char_id, dialog):
        """Clear voice clone path"""
        self.character_chatterbox_settings[char_id]['voice_clone_path'] = None
        self.character_chatterbox_settings[char_id]['voice_clone_status'] = 'none'
        
        # Update UI
        self._update_voice_clone_status_ui(char_id, 'none', "No voice samples")
        
        from PySide6.QtWidgets import QMessageBox
        QMessageBox.information(dialog, "üóëÔ∏è Cleared", "Voice clone path cleared")
        dialog.close()
    
    def show_voice_prompt_examples(self, char_id, input_field):
        """Hi·ªÉn th·ªã dialog v·ªõi voice prompt examples"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QHBoxLayout, QPushButton, QLabel
        
        dialog = QDialog(self)
        dialog.setWindowTitle(f"Voice Prompt Examples - {self.get_character_name_by_id(char_id)}")
        dialog.setFixedSize(500, 400)
        
        layout = QVBoxLayout()
        layout.addWidget(QLabel("Ch·ªçn example ho·∫∑c t·ª± vi·∫øt prompt:"))
        
        examples = [
            ("üë© MC Radio", "Gi·ªçng n·ªØ tr·∫ª, vui v·∫ª, nƒÉng ƒë·ªông nh∆∞ MC radio, n√≥i nhanh v√† c√≥ intonation r√µ r√†ng"),
            ("üë® Tin t·ª©c", "Gi·ªçng nam tr·∫ßm, nghi√™m t√∫c, uy t√≠n nh∆∞ ng∆∞·ªùi d·∫´n ch∆∞∆°ng tr√¨nh tin t·ª©c"),
            ("üë∂ Tr·∫ª em", "Gi·ªçng tr·∫ª em vui v·∫ª, trong tr·∫ªo, h·ªìn nhi√™n nh∆∞ trong truy·ªán c·ªï t√≠ch"),
            ("üë© Gentle", "Gi·ªçng n·ªØ nh·∫π nh√†ng, d·ªãu d√†ng, ·∫•m √°p nh∆∞ ng∆∞·ªùi m·∫π k·ªÉ chuy·ªán"),
            ("üë® Hero", "Gi·ªçng nam m·∫°nh m·∫Ω, quy·∫øt ƒëo√°n, anh h√πng nh∆∞ trong phim h√†nh ƒë·ªông"),
            ("üé≠ Dramatic", "Gi·ªçng k·ªãch t√≠nh, c·∫£m x√∫c m·∫°nh, nh∆∞ di·ªÖn vi√™n s√¢n kh·∫•u"),
            ("üòÑ Happy", "Gi·ªçng vui v·∫ª, t∆∞∆°i t·∫Øn, lu√¥n c∆∞·ªùi, t√≠ch c·ª±c"),
            ("üò¢ Sad", "Gi·ªçng bu·ªìn b√£, u s·∫ßu, ch·∫≠m r√£i, ƒë·∫ßy c·∫£m x√∫c"),
            ("üò† Angry", "Gi·ªçng t·ª©c gi·∫≠n, quy·∫øt li·ªát, m·∫°nh m·∫Ω, c√≥ s·ª©c thuy·∫øt ph·ª•c"),
            ("ü§´ Mysterious", "Gi·ªçng b√≠ ·∫©n, th·∫ßm th√¨, huy·ªÅn b√≠ nh∆∞ trong phim trinh th√°m")
        ]
        
        for title, prompt in examples:
            btn = QPushButton(f"{title}")
            btn.setToolTip(prompt)
            btn.clicked.connect(lambda checked, p=prompt: self.apply_voice_prompt_example(input_field, p, dialog))
            layout.addWidget(btn)
        
        # Buttons
        button_layout = QHBoxLayout()
        cancel_btn = QPushButton("H·ªßy")
        cancel_btn.clicked.connect(dialog.reject)
        button_layout.addWidget(cancel_btn)
        
        layout.addLayout(button_layout)
        dialog.setLayout(layout)
        dialog.exec()
    
    def apply_voice_prompt_example(self, input_field, prompt, dialog):
        """Apply voice prompt example to input field"""
        input_field.setText(prompt)
        dialog.accept()
    
    def select_character_voice_clone_folder(self, char_id):
        """Ch·ªçn th∆∞ m·ª•c v√† file voice sample cho nh√¢n v·∫≠t c·ª• th·ªÉ v·ªõi UI selection"""
        from PySide6.QtWidgets import QFileDialog, QMessageBox, QProgressDialog
        
        character_name = self.get_character_name_by_id(char_id)
        folder = QFileDialog.getExistingDirectory(
            self, 
            f"Ch·ªçn th∆∞ m·ª•c voice samples cho {character_name}",
            "",
            QFileDialog.ShowDirsOnly | QFileDialog.DontResolveSymlinks
        )
        
        if folder:
            # Update status to processing
            self._update_voice_clone_status_ui(char_id, 'processing', 'ƒêang x·ª≠ l√Ω...')
            
            # Ki·ªÉm tra xem folder c√≥ audio files kh√¥ng
            import os
            audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']
            audio_files = []
            
            try:
                print(f"üîç Scanning folder: {folder}")
                all_files = os.listdir(folder)
                print(f"üìÇ Found {len(all_files)} total files: {all_files}")
                
                for file in all_files:
                    file_lower = file.lower()
                    print(f"   Checking file: {file} (lowercase: {file_lower})")
                    
                    if any(file_lower.endswith(ext) for ext in audio_extensions):
                        print(f"   ‚úÖ Audio file detected: {file}")
                        # Get file info
                        file_path = os.path.join(folder, file)
                        
                        try:
                            file_size = os.path.getsize(file_path)
                            file_size_mb = file_size / (1024 * 1024)
                            
                            # Try to get audio duration (optional)
                            duration_info = ""
                            try:
                                import mutagen
                                audio_file = mutagen.File(file_path)
                                if audio_file and hasattr(audio_file, 'info') and hasattr(audio_file.info, 'length'):
                                    duration = audio_file.info.length
                                    duration_info = f" ({duration:.1f}s)"
                            except Exception as e:
                                print(f"   ‚ö†Ô∏è Could not get duration for {file}: {e}")
                                pass  # Skip duration if mutagen not available
                            
                            audio_files.append({
                                'name': file,
                                'path': file_path,
                                'size_mb': file_size_mb,
                                'duration_info': duration_info,
                                'display_name': f"{file} ({file_size_mb:.1f}MB{duration_info})"
                            })
                            print(f"   ‚úÖ Added to list: {file} ({file_size_mb:.1f}MB)")
                            
                        except Exception as e:
                            print(f"   ‚ùå Error processing file {file}: {e}")
                            continue
                    else:
                        print(f"   ‚ùå Not an audio file: {file}")
                
                print(f"üéµ Total audio files found: {len(audio_files)}")
                
                if not audio_files:
                    self._update_voice_clone_status_ui(char_id, 'error', 'Kh√¥ng t√¨m th·∫•y audio files')
                    
                    # Create detailed message with file list for debugging
                    debug_message = f"Th∆∞ m·ª•c '{folder}' kh√¥ng ch·ª©a file audio n√†o.\n\n"
                    debug_message += f"Supported formats: {', '.join(audio_extensions)}\n\n"
                    debug_message += f"Files found in folder ({len(all_files)} total):\n"
                    for i, file in enumerate(all_files[:10]):  # Show first 10 files
                        debug_message += f"  ‚Ä¢ {file}\n"
                    if len(all_files) > 10:
                        debug_message += f"  ... and {len(all_files) - 10} more files"
                    
                    QMessageBox.warning(
                        self, 
                        "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y audio files", 
                        debug_message
                    )
                    return
                
                # Show file selection dialog
                print(f"üîç Calling file selection dialog with {len(audio_files)} files")
                selected_file = self._show_voice_file_selection_dialog(character_name, folder, audio_files)
                print(f"üéØ Dialog result: {selected_file}")
                
                if selected_file is None:
                    print("‚ö†Ô∏è User cancelled file selection")
                    self._update_voice_clone_status_ui(char_id, 'none', 'ƒê√£ h·ªßy ch·ªçn file')
                    return
                
                if selected_file:
                    # L∆∞u file path c·ª• th·ªÉ
                    if char_id not in self.character_chatterbox_settings:
                        self.character_chatterbox_settings[char_id] = {}
                    
                    self.character_chatterbox_settings[char_id]['voice_clone_path'] = selected_file['path']
                    self.character_chatterbox_settings[char_id]['voice_clone_status'] = 'ready'
                    self.character_chatterbox_settings[char_id]['voice_clone_folder'] = folder
                    
                    # Update UI status
                    self._update_voice_clone_status_ui(char_id, 'ready', f"File: {selected_file['name']}")
                    
                    print(f"üìÅ Voice clone file set for {character_name}: {selected_file['path']}")
                    print(f"   üìÇ Folder: {folder}")
                    print(f"   üéµ Selected: {selected_file['name']} ({selected_file['size_mb']:.1f}MB{selected_file['duration_info']})")
                    
                    QMessageBox.information(
                        self,
                        "‚úÖ Voice Clone Setup",
                        f"ƒê√£ thi·∫øt l·∫≠p voice cloning cho {character_name}\n"
                        f"Folder: {os.path.basename(folder)}\n"
                        f"File: {selected_file['name']}\n"
                        f"Size: {selected_file['size_mb']:.1f}MB{selected_file['duration_info']}"
                    )
                else:
                    # User cancelled file selection
                    self._update_voice_clone_status_ui(char_id, 'none', 'Ch∆∞a ch·ªçn file')
                
            except Exception as e:
                self._update_voice_clone_status_ui(char_id, 'error', f'L·ªói: {str(e)}')
                QMessageBox.critical(
                    self,
                    "‚ùå L·ªói Voice Clone Setup",
                    f"Kh√¥ng th·ªÉ thi·∫øt l·∫≠p voice cloning:\n{str(e)}"
                )
    
    def _update_voice_clone_status_ui(self, char_id, status, tooltip_text=""):
        """C·∫≠p nh·∫≠t UI status cho voice clone c·ªßa nh√¢n v·∫≠t v·ªõi file name display"""
        status_icons = {
            'none': '‚ùå',
            'ready': '‚úÖ', 
            'processing': '‚è≥',
            'error': '‚ùå'
        }
        
        status_colors = {
            'none': 'color: red;',
            'ready': 'color: green;',
            'processing': 'color: orange;',
            'error': 'color: red;'
        }
        
        # T√¨m row c·ªßa character n√†y
        for i in range(self.character_settings_table.rowCount()):
            name_item = self.character_settings_table.item(i, 0)
            if name_item and name_item.text() == char_id:  # Note: Updated to use char_id directly
                # L·∫•y voice clone container
                voice_clone_container = self.character_settings_table.cellWidget(i, 6)
                if voice_clone_container:
                    # T√¨m status label (widget th·ª© 2 trong layout)
                    layout = voice_clone_container.layout()
                    if layout and layout.count() > 1:
                        status_label = layout.itemAt(1).widget()
                        if status_label:
                            # ‚úÖ IMPROVED: Show file name for ready status
                            if status == 'ready':
                                settings = self.character_chatterbox_settings.get(char_id, {})
                                voice_clone_path = settings.get('voice_clone_path', '')
                                
                                if voice_clone_path and os.path.exists(voice_clone_path):
                                    file_name = os.path.basename(voice_clone_path)
                                    # Truncate long file names
                                    if len(file_name) > 15:
                                        display_name = file_name[:12] + "..."
                                    else:
                                        display_name = file_name
                                    status_label.setText(f"üéµ {display_name}")
                                    status_label.setToolTip(f"Voice sample: {file_name}\nPath: {voice_clone_path}")
                                else:
                                    status_label.setText(status_icons.get(status, '‚ùì'))
                                    status_label.setToolTip(tooltip_text or f"Status: {status}")
                            else:
                                status_label.setText(status_icons.get(status, '‚ùì'))
                                status_label.setToolTip(tooltip_text or f"Status: {status}")
                            
                            status_label.setStyleSheet(status_colors.get(status, ''))
                break
    
    def get_character_name_by_id(self, char_id):
        """Helper ƒë·ªÉ l·∫•y t√™n nh√¢n v·∫≠t t·ª´ ID"""
        if self.voice_studio_script_data:
            for character in self.voice_studio_script_data['characters']:
                if character['id'] == char_id:
                    return character['name']
        return f"Character {char_id}"
    
    def toggle_voice_cloning(self, enabled):
        """Toggle voice cloning controls"""
        self.voice_clone_folder_btn.setEnabled(enabled)
    
    def select_voice_clone_folder(self):
        """Ch·ªçn th∆∞ m·ª•c ch·ª©a voice samples"""
        from PySide6.QtWidgets import QFileDialog
        folder = QFileDialog.getExistingDirectory(self, "Ch·ªçn th∆∞ m·ª•c voice samples")
        if folder:
            self.voice_clone_folder = folder
            self.voice_clone_path_label.setText(f"üìÅ {folder}")
            self.voice_clone_path_label.setStyleSheet("color: green; font-weight: bold; margin-left: 20px;")
    
    def validate_character_voice_settings(self, char_id):
        """Validate character voice settings d·ª±a tr√™n voice mode ƒë∆∞·ª£c ch·ªçn"""
        settings = self.character_chatterbox_settings.get(char_id, {})
        voice_mode = settings.get('voice_mode', 'voice_selection')
        char_name = self.get_character_name_by_id(char_id)
        
        if voice_mode == 'voice_clone':
            voice_clone_path = settings.get('voice_clone_path')
            if voice_clone_path and os.path.exists(voice_clone_path):
                print(f"üéØ {char_name}: Using VOICE CLONE - {voice_clone_path}")
                return 'clone'
            else:
                # Fallback to voice selection if no clone
                print(f"‚ö†Ô∏è {char_name}: Voice clone mode selected but no samples provided, fallback to voice selection")
                voice_id = settings.get('voice_id', 'female_young')
                print(f"üéØ {char_name}: Using VOICE SELECTION (fallback) - {voice_id}")
                return 'selection'
                
        else:  # voice_selection mode
            voice_id = settings.get('voice_id', 'female_young')
            print(f"üéØ {char_name}: Using VOICE SELECTION - {voice_id}")
            return 'selection'
    
    def apply_preset(self, preset_type):
        """√Åp d·ª•ng preset settings"""
        presets = {
            "natural": {"emotion": 1.0, "speed": 1.0},
            "dramatic": {"emotion": 2.5, "speed": 0.9},
            "fast": {"emotion": 1.2, "speed": 1.5},
            "slow": {"emotion": 0.8, "speed": 0.7}
        }
        
        if preset_type in presets:
            preset = presets[preset_type]
            
            # Update global sliders
            emotion_value = int(preset["emotion"] * 100)
            speed_value = int(preset["speed"] * 100)
            
            self.emotion_slider.setValue(emotion_value)
            self.speed_slider.setValue(speed_value)
            
            # Update all character settings
            for char_id in self.character_chatterbox_settings:
                self.character_chatterbox_settings[char_id]['emotion'] = preset["emotion"]
                self.character_chatterbox_settings[char_id]['speed'] = preset["speed"]
            
            # Update character table sliders
            for i in range(self.character_settings_table.rowCount()):
                emotion_slider = self.character_settings_table.cellWidget(i, 1)
                speed_slider = self.character_settings_table.cellWidget(i, 2)
                if emotion_slider:
                    emotion_slider.setValue(emotion_value)
                if speed_slider:
                    speed_slider.setValue(speed_value)
            
            QMessageBox.information(self, "Preset", f"ƒê√£ √°p d·ª•ng preset '{preset_type.title()}'!")
    
    def get_character_chatterbox_settings(self, char_id):
        """L·∫•y settings cho character khi manual mode enabled"""
        if self.enable_chatterbox_manual.isChecked():
            # ‚úÖ FIX: D√πng character-specific settings thay v√¨ global controls
            return self.character_chatterbox_settings.get(char_id, {
                'emotion': 1.0,
                'speed': 1.0, 
                'cfg_weight': 0.5,
                'voice_clone_path': None,
                'voice_mode': 'voice_selection'
            })
        else:
            return {
                'emotion': 1.0, 
                'speed': 1.0, 
                'cfg_weight': 0.5,
                'voice_clone_path': None,
                'voice_mode': 'voice_selection'
            }
    
    def map_emotion_to_parameters(self, emotion_label, base_exaggeration=1.0):
        """Map emotion label to optimized emotion exaggeration + cfg_weight parameters"""
        
        # üé≠ Enhanced 22-Emotion Mapping Table (English labels for Chatterbox compatibility)
        emotion_mapping = {
            # 1. Neutral - Objective narration, reporting
            'neutral': {'exaggeration': 0.5, 'cfg_weight': 0.5},
            'calm': {'exaggeration': 0.5, 'cfg_weight': 0.5},
            'normal': {'exaggeration': 0.5, 'cfg_weight': 0.5},
            
            # 2. Gentle/Contemplative - Deep inner thoughts, light emotions  
            'gentle': {'exaggeration': 0.35, 'cfg_weight': 0.35},
            'contemplative': {'exaggeration': 0.4, 'cfg_weight': 0.4},
            'soft': {'exaggeration': 0.3, 'cfg_weight': 0.3},
            'whisper': {'exaggeration': 0.3, 'cfg_weight': 0.3},
            
            # 3. Happy/Cheerful - Positive, joyful, friendly greetings
            'happy': {'exaggeration': 1.35, 'cfg_weight': 0.55},
            'cheerful': {'exaggeration': 1.2, 'cfg_weight': 0.5},
            'joyful': {'exaggeration': 1.5, 'cfg_weight': 0.6},
            'friendly': {'exaggeration': 1.2, 'cfg_weight': 0.5},
            
            # 4. Surprised - Shock, disbelief, amazement
            'surprised': {'exaggeration': 1.85, 'cfg_weight': 0.55},
            'shocked': {'exaggeration': 2.0, 'cfg_weight': 0.6},
            'amazed': {'exaggeration': 1.7, 'cfg_weight': 0.5},
            
            # 5. Sad/Hurt - Heartache, disappointment, heavy emotions
            'sad': {'exaggeration': 0.4, 'cfg_weight': 0.35},
            'hurt': {'exaggeration': 0.3, 'cfg_weight': 0.3},
            'disappointed': {'exaggeration': 0.5, 'cfg_weight': 0.4},
            'melancholy': {'exaggeration': 0.3, 'cfg_weight': 0.3},
            
            # 6. Angry/Furious - Irritated, arguing, dissatisfied
            'angry': {'exaggeration': 2.0, 'cfg_weight': 0.7},
            'furious': {'exaggeration': 2.2, 'cfg_weight': 0.8},
            'irritated': {'exaggeration': 1.8, 'cfg_weight': 0.6},
            'frustrated': {'exaggeration': 1.8, 'cfg_weight': 0.6},
            
            # 7. Pleading/Earnest - Begging, deep emotional appeals
            'pleading': {'exaggeration': 1.6, 'cfg_weight': 0.45},
            'earnest': {'exaggeration': 1.4, 'cfg_weight': 0.4},
            'desperate': {'exaggeration': 1.8, 'cfg_weight': 0.5},
            
            # 8. Anxious/Restless - Worried, underlying tension
            'anxious': {'exaggeration': 1.4, 'cfg_weight': 0.55},
            'worried': {'exaggeration': 1.3, 'cfg_weight': 0.5},
            'nervous': {'exaggeration': 1.5, 'cfg_weight': 0.6},
            'restless': {'exaggeration': 1.4, 'cfg_weight': 0.55},
            
            # 9. Mysterious/Suspenseful - Detective, lurking, tense
            'mysterious': {'exaggeration': 1.4, 'cfg_weight': 0.45},
            'suspenseful': {'exaggeration': 1.2, 'cfg_weight': 0.4},
            'ominous': {'exaggeration': 1.6, 'cfg_weight': 0.5},
            'eerie': {'exaggeration': 1.2, 'cfg_weight': 0.4},
            
            # 10. Warning/Emergency - Alerts, danger, urgent calls
            'warning': {'exaggeration': 2.0, 'cfg_weight': 0.8},
            'urgent': {'exaggeration': 2.0, 'cfg_weight': 0.7},
            'emergency': {'exaggeration': 2.0, 'cfg_weight': 0.9},
            'alarm': {'exaggeration': 2.0, 'cfg_weight': 0.8},
            
            # 11. Sarcastic/Mocking - Teasing, implied meanings
            'sarcastic': {'exaggeration': 0.85, 'cfg_weight': 0.45},
            'mocking': {'exaggeration': 0.7, 'cfg_weight': 0.4},
            'ironic': {'exaggeration': 1.0, 'cfg_weight': 0.5},
            
            # 12. Admiring/Impressed - Genuine praise, admiration
            'admiring': {'exaggeration': 1.45, 'cfg_weight': 0.55},
            'impressed': {'exaggeration': 1.3, 'cfg_weight': 0.5},
            'praising': {'exaggeration': 1.6, 'cfg_weight': 0.6},
            
            # 13. Confused/Embarrassed - Hesitant, lacking confidence
            'confused': {'exaggeration': 0.7, 'cfg_weight': 0.45},
            'embarrassed': {'exaggeration': 0.6, 'cfg_weight': 0.4},
            'hesitant': {'exaggeration': 0.8, 'cfg_weight': 0.5},
            'uncertain': {'exaggeration': 0.7, 'cfg_weight': 0.45},
            
            # 14. Cold/Distant - Indifferent, emotionless
            'cold': {'exaggeration': 0.35, 'cfg_weight': 0.65},
            'distant': {'exaggeration': 0.3, 'cfg_weight': 0.6},
            'indifferent': {'exaggeration': 0.4, 'cfg_weight': 0.7},
            'detached': {'exaggeration': 0.3, 'cfg_weight': 0.6},
            
            # 15. Enthusiastic/Encouraging - Inspiring, motivating
            'enthusiastic': {'exaggeration': 1.7, 'cfg_weight': 0.6},
            'encouraging': {'exaggeration': 1.6, 'cfg_weight': 0.6},
            'motivating': {'exaggeration': 1.8, 'cfg_weight': 0.6},
            'inspiring': {'exaggeration': 1.7, 'cfg_weight': 0.6},
            
            # 16. Strong/Decisive - Commands, clear demands
            'commanding': {'exaggeration': 1.75, 'cfg_weight': 0.8},
            'decisive': {'exaggeration': 1.5, 'cfg_weight': 0.7},
            'authoritative': {'exaggeration': 2.0, 'cfg_weight': 0.9},
            'firm': {'exaggeration': 1.8, 'cfg_weight': 0.8},
            
            # 17. Innocent/Naive - Childlike, carefree joy
            'innocent': {'exaggeration': 1.2, 'cfg_weight': 0.5},
            'naive': {'exaggeration': 1.0, 'cfg_weight': 0.4},
            'childlike': {'exaggeration': 1.4, 'cfg_weight': 0.6},
            'carefree': {'exaggeration': 1.3, 'cfg_weight': 0.5},
            
            # 18. Bewildered/Lost - Confused, don't understand
            'bewildered': {'exaggeration': 1.55, 'cfg_weight': 0.45},
            'lost': {'exaggeration': 1.4, 'cfg_weight': 0.4},
            'perplexed': {'exaggeration': 1.7, 'cfg_weight': 0.5},
            'dazed': {'exaggeration': 1.6, 'cfg_weight': 0.45},
            
            # 19. Provocative/Teasing - Intentionally suggestive, playful
            'provocative': {'exaggeration': 1.65, 'cfg_weight': 0.55},
            'teasing': {'exaggeration': 1.5, 'cfg_weight': 0.5},
            'flirtatious': {'exaggeration': 1.8, 'cfg_weight': 0.6},
            'playful': {'exaggeration': 1.6, 'cfg_weight': 0.55},
            
            # 20. Humorous/Witty - Funny, charming, naturally captivating
            'humorous': {'exaggeration': 1.45, 'cfg_weight': 0.5},
            'witty': {'exaggeration': 1.3, 'cfg_weight': 0.4},
            'amusing': {'exaggeration': 1.6, 'cfg_weight': 0.6},
            'charming': {'exaggeration': 1.4, 'cfg_weight': 0.5},
            
            # 21. Persuasive/Rhetorical - Eloquent, logical with emotion
            'persuasive': {'exaggeration': 1.35, 'cfg_weight': 0.55},
            'rhetorical': {'exaggeration': 1.1, 'cfg_weight': 0.5},
            'eloquent': {'exaggeration': 1.6, 'cfg_weight': 0.6},
            'convincing': {'exaggeration': 1.4, 'cfg_weight': 0.55},
            
            # 22. Scornful/Contemptuous - Harsh mockery, clear disdain
            'scornful': {'exaggeration': 1.85, 'cfg_weight': 0.65},
            'contemptuous': {'exaggeration': 1.7, 'cfg_weight': 0.6},
            'disdainful': {'exaggeration': 2.0, 'cfg_weight': 0.7},
            'condescending': {'exaggeration': 1.8, 'cfg_weight': 0.65},
            
            # Additional common emotions
            'excited': {'exaggeration': 1.6, 'cfg_weight': 0.6},
            'romantic': {'exaggeration': 1.2, 'cfg_weight': 0.45},
            'fear': {'exaggeration': 1.4, 'cfg_weight': 0.5},
            'confident': {'exaggeration': 1.5, 'cfg_weight': 0.6},
            'shy': {'exaggeration': 0.6, 'cfg_weight': 0.4},
            'dramatic': {'exaggeration': 1.8, 'cfg_weight': 0.6},
        }
        
        # Get mapping for emotion label (English labels)
        mapping = emotion_mapping.get(emotion_label.lower(), {'exaggeration': 1.0, 'cfg_weight': 0.5})
        
        # Use absolute values from mapping table (optimized for Chatterbox TTS)
        final_exaggeration = mapping['exaggeration']
        cfg_weight = mapping['cfg_weight']
        
        # Clamp exaggeration to valid range 0.0-2.5
        final_exaggeration = max(0.0, min(2.5, final_exaggeration))
        
        # Clamp cfg_weight to valid range 0.0-1.0  
        cfg_weight = max(0.0, min(1.0, cfg_weight))
        
        # Log emotion mapping results (English labels for better clarity)
        if emotion_label.lower() not in ['neutral', 'normal', 'calm']:
            print(f"   üé≠ Emotion Auto-Mapping: '{emotion_label}' ‚Üí exaggeration={final_exaggeration:.2f}, cfg_weight={cfg_weight:.2f}")
        
        return final_exaggeration, cfg_weight
    
    # ‚úÖ REMOVED: Global controls methods no longer needed
    # All voice controls are now per-character only
    
    def _update_character_table_row(self, char_id, params):
        """C·∫≠p nh·∫≠t UI table row cho character c·ª• th·ªÉ v·ªõi parameters m·ªõi"""
        try:
            # T√¨m row c·ªßa character trong table
            for row in range(self.character_settings_table.rowCount()):
                name_item = self.character_settings_table.item(row, 0)
                if name_item and name_item.text() == char_id:
                    # Update emotion input (column 1)
                    emotion_input = self.character_settings_table.cellWidget(row, 1)
                    if emotion_input and 'emotion' in params:
                        emotion_input.setText(f"{params['emotion']:.1f}")
                    
                    # Update speed input (column 2)  
                    speed_input = self.character_settings_table.cellWidget(row, 2)
                    if speed_input and 'speed' in params:
                        speed_input.setText(f"{params['speed']:.1f}")
                    
                    # Update cfg weight input (column 3)
                    cfg_weight_input = self.character_settings_table.cellWidget(row, 3)
                    if cfg_weight_input and 'cfg_weight' in params:
                        cfg_weight_input.setText(f"{params['cfg_weight']:.2f}")
                    
                    print(f"‚úÖ Updated UI for {char_id}: emotion={params.get('emotion', 'N/A'):.1f}, speed={params.get('speed', 'N/A'):.1f}, cfg_weight={params.get('cfg_weight', 'N/A'):.2f}")
                    break
        except Exception as e:
            print(f"‚ö†Ô∏è Error updating character table row: {e}")
    
    def _show_voice_file_selection_dialog(self, character_name, folder, audio_files):
        """Hi·ªÉn th·ªã dialog ƒë·ªÉ ch·ªçn file voice sample t·ª´ danh s√°ch"""
        from PySide6.QtWidgets import QDialog, QVBoxLayout, QHBoxLayout, QListWidget, QListWidgetItem, QPushButton, QLabel
        from PySide6.QtCore import Qt
        import os
        
        print(f"üéØ Creating dialog for {character_name} with {len(audio_files)} audio files")
        
        dialog = QDialog(self)
        dialog.setWindowTitle(f"üé§ Ch·ªçn Voice Sample cho {character_name}")
        dialog.setModal(True)
        dialog.resize(600, 400)
        dialog.setWindowFlags(Qt.Dialog | Qt.WindowTitleHint | Qt.WindowCloseButtonHint)
        
        print(f"üìã Audio files to show:")
        for i, af in enumerate(audio_files):
            print(f"   {i+1}. {af['name']} ({af['size_mb']:.1f}MB)")
        
        if len(audio_files) == 0:
            print("‚ùå ERROR: No audio files provided to dialog!")
            return None
        
        layout = QVBoxLayout()
        
        # Header
        header_label = QLabel(f"üìÇ Folder: {os.path.basename(folder)}")
        header_label.setStyleSheet("font-weight: bold; font-size: 14px; margin: 10px;")
        layout.addWidget(header_label)
        
        info_label = QLabel(f"üéµ T√¨m th·∫•y {len(audio_files)} audio files. Ch·ªçn 1 file ƒë·ªÉ l√†m voice sample:")
        info_label.setStyleSheet("color: #666; margin-bottom: 10px;")
        layout.addWidget(info_label)
        
        # File list
        file_list = QListWidget()
        file_list.setAlternatingRowColors(True)
        file_list.setMinimumHeight(200)
        
        print(f"üîÑ Adding {len(audio_files)} items to list widget...")
        
        for i, audio_file in enumerate(audio_files):
            print(f"   Adding item {i+1}: {audio_file['display_name']}")
            item = QListWidgetItem(audio_file['display_name'])
            item.setData(Qt.UserRole, audio_file)  # Store file data
            
            # Color coding by file size
            try:
                from PySide6.QtGui import QColor
                if audio_file['size_mb'] < 1:
                    item.setBackground(QColor('#e8f5e8'))  # Light green for small files
                elif audio_file['size_mb'] > 10:
                    item.setBackground(QColor('#fff3cd'))  # Light yellow for large files
            except Exception as e:
                print(f"   ‚ö†Ô∏è Could not set background color: {e}")
                pass  # Skip color coding if it fails
            
            file_list.addItem(item)
            print(f"   ‚úÖ Item {i+1} added successfully")
        
        print(f"‚úÖ List widget now has {file_list.count()} items")
        
        layout.addWidget(file_list)
        
        # Preview section
        preview_info = QLabel("üí° Tip: File nh·ªè h∆°n (<5MB) v√† r√µ r√†ng s·∫Ω cho k·∫øt qu·∫£ voice cloning t·ªët h∆°n")
        preview_info.setStyleSheet("color: #007acc; font-style: italic; margin: 5px;")
        layout.addWidget(preview_info)
        
        # Buttons
        button_layout = QHBoxLayout()
        
        # Play button (preview - if possible)
        play_button = QPushButton("üîä Preview")
        play_button.setEnabled(False)  # Disable for now - can implement later
        play_button.setToolTip("T√≠nh nƒÉng preview s·∫Ω ƒë∆∞·ª£c th√™m trong b·∫£n c·∫≠p nh·∫≠t sau")
        
        # Cancel button
        cancel_button = QPushButton("‚ùå H·ªßy")
        cancel_button.clicked.connect(dialog.reject)
        
        # Select button  
        select_button = QPushButton("‚úÖ Ch·ªçn File N√†y")
        select_button.setEnabled(False)
        select_button.setStyleSheet("font-weight: bold; background-color: #007acc; color: white;")
        
        # Enable select button when item is selected
        def on_selection_changed():
            has_selection = len(file_list.selectedItems()) > 0
            select_button.setEnabled(has_selection)
            if has_selection:
                selected_item = file_list.selectedItems()[0]
                selected_file = selected_item.data(Qt.UserRole)
                select_button.setText(f"‚úÖ Ch·ªçn: {selected_file['name'][:20]}")
        
        file_list.itemSelectionChanged.connect(on_selection_changed)
        
        def on_select():
            if file_list.selectedItems():
                dialog.selected_file = file_list.selectedItems()[0].data(Qt.UserRole)
                dialog.accept()
        
        select_button.clicked.connect(on_select)
        
        # Double click to select
        file_list.itemDoubleClicked.connect(on_select)
        
        button_layout.addWidget(play_button)
        button_layout.addStretch()
        button_layout.addWidget(cancel_button)
        button_layout.addWidget(select_button)
        
        layout.addLayout(button_layout)
        dialog.setLayout(layout)
        
        # Show dialog
        dialog.selected_file = None
        
        print("üîç About to show dialog...")
        result = dialog.exec()
        print(f"üìä Dialog result: {result} (Accepted={QDialog.Accepted}, Rejected={QDialog.Rejected})")
        
        if result == QDialog.Accepted:
            print(f"‚úÖ Dialog accepted, returning file: {dialog.selected_file}")
            return dialog.selected_file
        else:
            print("‚ùå Dialog was cancelled or rejected")
            return None
    
    def import_multiple_script_files(self):
        """Import v√† merge nhi·ªÅu file JSON scripts v·ªõi smart merge logic"""
        from PySide6.QtWidgets import QFileDialog, QMessageBox, QProgressDialog
        
        file_paths, _ = QFileDialog.getOpenFileNames(
            self,
            "Ch·ªçn nhi·ªÅu file JSON scripts",
            "",
            "JSON files (*.json);;All files (*.*)"
        )
        
        if not file_paths:
            return
        
        # Progress dialog
        progress = QProgressDialog("ƒêang import v√† merge files...", "H·ªßy", 0, len(file_paths), self)
        progress.setWindowModality(Qt.WindowModal)
        progress.show()
        
        merged_data = {
            "project": {
                "title": "Merged Multi-File Story",
                "description": "Story ƒë∆∞·ª£c merge t·ª´ nhi·ªÅu files",
                "total_duration": 0,
                "target_audience": "general",
                "style": "multi_story",
                "created_date": "2024-01-20"
            },
            "segments": [],
            "characters": [],
            "audio_settings": {
                "merge_order": ["intro", "content", "conclusion"],
                "crossfade_duration": 0.5,
                "normalize_volume": True,
                "background_music_volume": 0.2,
                "voice_volume": 1.0,
                "output_format": "mp3",
                "sample_rate": 44100
            },
            "metadata": {
                "version": "2.0",
                "ai_model": "Multi-File Merger",
                "generation_date": "2024-01-20",
                "language": "vi-VN",
                "content_rating": "G",
                "source_files": [],
                "merge_type": "smart_merge"
            }
        }
        
        character_id_map = {}  # Map old char IDs to new merged IDs
        next_character_id = 1
        next_segment_id = 1
        
        loaded_files = []
        errors = []
        
        try:
            for i, file_path in enumerate(file_paths):
                if progress.wasCanceled():
                    return
                
                progress.setValue(i)
                progress.setLabelText(f"Processing: {os.path.basename(file_path)}")
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        script_data = json.load(f)
                    
                    if not self.validate_script_data(script_data):
                        errors.append(f"{os.path.basename(file_path)}: Invalid format")
                        continue
                    
                    # Store source file info
                    file_info = {
                        "filename": os.path.basename(file_path),
                        "segments": len(script_data.get('segments', [])),
                        "characters": len(script_data.get('characters', []))
                    }
                    merged_data["metadata"]["source_files"].append(file_info)
                    
                    # === SMART CHARACTER MERGE ===
                    file_char_map = {}  # Map for this specific file
                    
                    for char in script_data.get('characters', []):
                        old_char_id = char['id']
                        char_name = char.get('name', '')
                        
                        # Check if character already exists (by name similarity)
                        existing_char_id = None
                        for existing_char in merged_data['characters']:
                            if existing_char['name'].lower() == char_name.lower():
                                existing_char_id = existing_char['id']
                                break
                        
                        if existing_char_id:
                            # Use existing character
                            file_char_map[old_char_id] = existing_char_id
                            print(f"üîÑ Merged character: {char_name} -> {existing_char_id}")
                        else:
                            # Create new character with unique ID
                            new_char_id = f"character{next_character_id}"
                            while any(c['id'] == new_char_id for c in merged_data['characters']):
                                next_character_id += 1
                                new_char_id = f"character{next_character_id}"
                            
                            new_char = char.copy()
                            new_char['id'] = new_char_id
                            merged_data['characters'].append(new_char)
                            file_char_map[old_char_id] = new_char_id
                            character_id_map[old_char_id] = new_char_id
                            next_character_id += 1
                            print(f"‚úÖ Added character: {char_name} -> {new_char_id}")
                    
                    # === MERGE SEGMENTS ===
                    for segment in script_data.get('segments', []):
                        new_segment = segment.copy()
                        new_segment['id'] = next_segment_id
                        
                        # Update character IDs in dialogues
                        for dialogue in new_segment.get('dialogues', []):
                            old_speaker = dialogue['speaker']
                            if old_speaker in file_char_map:
                                dialogue['speaker'] = file_char_map[old_speaker]
                            else:
                                print(f"‚ö†Ô∏è Character not found: {old_speaker}")
                        
                        # Add file source info
                        new_segment['source_file'] = os.path.basename(file_path)
                        merged_data['segments'].append(new_segment)
                        next_segment_id += 1
                    
                    # Update project duration
                    if 'project' in script_data and 'total_duration' in script_data['project']:
                        merged_data['project']['total_duration'] += script_data['project']['total_duration']
                    
                    loaded_files.append(os.path.basename(file_path))
                    
                except Exception as e:
                    errors.append(f"{os.path.basename(file_path)}: {str(e)}")
                    continue
            
            progress.setValue(len(file_paths))
            
            if not merged_data['segments']:
                QMessageBox.warning(self, "L·ªói", "Kh√¥ng c√≥ segment n√†o ƒë∆∞·ª£c load t·ª´ c√°c files!")
                return
            
            # Update project title with file count
            merged_data['project']['title'] = f"Multi-Story ({len(loaded_files)} files)"
            merged_data['project']['description'] = f"Merged from: {', '.join(loaded_files)}"
            
            # Set merged data
            self.voice_studio_script_data = merged_data
            self.imported_file_label.setText(f"‚úÖ {len(loaded_files)} files merged")
            self.imported_file_label.setStyleSheet("color: #007AFF; font-weight: bold;")
            self.update_voice_studio_overview()
            
            # Show success message
            success_msg = f"‚úÖ Multi-file merge th√†nh c√¥ng!\n\n"
            success_msg += f"üìÅ Files loaded: {len(loaded_files)}\n"
            success_msg += f"üé≠ Characters: {len(merged_data['characters'])}\n"  
            success_msg += f"üìù Segments: {len(merged_data['segments'])}\n"
            success_msg += f"‚è±Ô∏è Total duration: {merged_data['project']['total_duration']}s\n"
            
            if errors:
                success_msg += f"\n‚ö†Ô∏è Errors ({len(errors)}):\n"
                for error in errors[:3]:  # Show first 3 errors
                    success_msg += f"  ‚Ä¢ {error}\n"
                if len(errors) > 3:
                    success_msg += f"  ... v√† {len(errors) - 3} errors kh√°c"
            
            QMessageBox.information(self, "Multi-File Import", success_msg)
            
        except Exception as e:
            QMessageBox.critical(self, "L·ªói", f"L·ªói trong qu√° tr√¨nh merge:\n{str(e)}")
        finally:
            progress.close()