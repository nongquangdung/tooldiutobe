#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CUDA Setup Guide - H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t GPU support cho ChatterboxTTS
"""

import sys
import os
import subprocess
import platform

def check_gpu_hardware():
    """Ki·ªÉm tra hardware GPU"""
    print("üñ•Ô∏è GPU HARDWARE DETECTION")
    print("=" * 50)
    
    try:
        # Try nvidia-smi command
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("‚úÖ NVIDIA GPU detected!")
            lines = result.stdout.split('\n')
            for line in lines:
                if 'NVIDIA' in line or 'GeForce' in line or 'RTX' in line or 'GTX' in line:
                    print(f"   üéÆ {line.strip()}")
            return True
        else:
            print("‚ùå nvidia-smi failed")
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("‚ùå nvidia-smi not found - No NVIDIA GPU or drivers not installed")
        return False

def check_current_pytorch():
    """Ki·ªÉm tra PyTorch hi·ªán t·∫°i"""
    print("\nüî• PYTORCH CURRENT STATUS")
    print("=" * 50)
    
    try:
        import torch
        print(f"‚úÖ PyTorch installed: {torch.__version__}")
        
        if '+cpu' in torch.__version__:
            print("‚ö†Ô∏è CPU-only version detected!")
            print("   This is why ChatterboxTTS is using CPU")
        elif '+cu' in torch.__version__:
            cuda_version = torch.__version__.split('+cu')[1]
            print(f"‚úÖ CUDA version: {cuda_version}")
        
        print(f"üéØ CUDA Available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"   üéÆ GPU Count: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"   üñ•Ô∏è GPU {i}: {props.name}")
        else:
            print("   ‚ùå No CUDA support in current PyTorch")
            
        return torch.cuda.is_available()
        
    except ImportError:
        print("‚ùå PyTorch not installed")
        return False

def generate_cuda_install_commands():
    """T·∫°o commands ƒë·ªÉ c√†i ƒë·∫∑t CUDA PyTorch"""
    print("\nüöÄ CUDA INSTALLATION GUIDE")
    print("=" * 50)
    
    print("üìã Step 1: Check NVIDIA Driver")
    print("   Run this command: nvidia-smi")
    print("   If it fails, install NVIDIA drivers first from:")
    print("   https://www.nvidia.com/Download/index.aspx")
    
    print("\nüìã Step 2: Install CUDA Toolkit (Optional but recommended)")
    print("   Download from: https://developer.nvidia.com/cuda-downloads")
    print("   Choose your OS and follow instructions")
    
    print("\nüìã Step 3: Install PyTorch with CUDA")
    print("   üî• MOST IMPORTANT: Replace CPU PyTorch with CUDA version")
    print()
    
    # Get latest PyTorch CUDA commands
    print("   Option A: CUDA 11.8 (Recommended for compatibility)")
    print("   pip uninstall torch torchvision torchaudio")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    print()
    
    print("   Option B: CUDA 12.1 (Latest)")
    print("   pip uninstall torch torchvision torchaudio") 
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    print()
    
    print("   Option C: Auto-detect (Recommended)")
    print("   Go to: https://pytorch.org/get-started/locally/")
    print("   Select your configuration and copy the command")

def test_performance_difference():
    """So s√°nh performance CPU vs GPU n·∫øu c√≥"""
    print("\n‚ö° PERFORMANCE COMPARISON")
    print("=" * 50)
    
    try:
        import torch
        import time
        
        # Test tensor operations
        size = 1000
        cpu_tensor = torch.randn(size, size)
        
        # CPU test
        start_time = time.time()
        for _ in range(10):
            result = torch.mm(cpu_tensor, cpu_tensor)
        cpu_time = time.time() - start_time
        print(f"üì± CPU Performance: {cpu_time:.3f}s for 10 matrix multiplications")
        
        if torch.cuda.is_available():
            # GPU test
            gpu_tensor = cpu_tensor.cuda()
            torch.cuda.synchronize()
            
            start_time = time.time()
            for _ in range(10):
                result = torch.mm(gpu_tensor, gpu_tensor)
            torch.cuda.synchronize()
            gpu_time = time.time() - start_time
            
            speedup = cpu_time / gpu_time
            print(f"üéÆ GPU Performance: {gpu_time:.3f}s for 10 matrix multiplications")
            print(f"üöÄ GPU Speedup: {speedup:.1f}x faster than CPU")
            
            if speedup > 2:
                print("‚úÖ Significant GPU advantage - CUDA worth installing!")
            else:
                print("‚ö†Ô∏è Minor GPU advantage - CPU may be sufficient")
        else:
            print("‚ùå No GPU available for comparison")
            
    except Exception as e:
        print(f"‚ùå Performance test failed: {e}")

def create_install_script():
    """T·∫°o script t·ª± ƒë·ªông c√†i ƒë·∫∑t"""
    print("\nüìù AUTO INSTALL SCRIPT")
    print("=" * 50)
    
    script_content = """@echo off
echo Installing PyTorch with CUDA support...
echo.

echo Step 1: Uninstalling CPU-only PyTorch...
pip uninstall torch torchvision torchaudio -y

echo.
echo Step 2: Installing CUDA PyTorch...
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

echo.
echo Step 3: Testing installation...
python -c "import torch; print('PyTorch version:', torch.__version__); print('CUDA available:', torch.cuda.is_available())"

echo.
if torch.cuda.is_available():
    echo ‚úÖ SUCCESS! CUDA PyTorch installed correctly
else:
    echo ‚ùå FAILED! CUDA not available - check NVIDIA drivers
endif

pause
"""
    
    with open("install_pytorch_cuda.bat", "w") as f:
        f.write(script_content)
    
    print("‚úÖ Created install_pytorch_cuda.bat")
    print("   Run this script as Administrator to auto-install CUDA PyTorch")

def main():
    """Main diagnostic and setup guide"""
    print("üéÆ CUDA SETUP DIAGNOSTIC & GUIDE")
    print("Setting up GPU acceleration for ChatterboxTTS")
    print("=" * 60)
    
    # Check system
    print(f"üíª System: {platform.system()} {platform.release()}")
    print(f"üêç Python: {sys.version.split()[0]}")
    
    # Run checks
    has_gpu = check_gpu_hardware()
    has_cuda_pytorch = check_current_pytorch()
    
    # Analysis and recommendations
    print("\n" + "=" * 60)
    print("üéØ ANALYSIS & RECOMMENDATIONS")
    
    if not has_gpu:
        print("‚ùå ISSUE: No NVIDIA GPU detected")
        print("üí° SOLUTION: ")
        print("   1. Install NVIDIA GPU drivers")
        print("   2. Or continue using CPU (slower but works)")
        
    elif not has_cuda_pytorch:
        print("‚ùå ISSUE: NVIDIA GPU available but PyTorch is CPU-only")
        print("üí° SOLUTION: Install CUDA-enabled PyTorch")
        print("   This is why ChatterboxTTS is using CPU instead of GPU!")
        
        generate_cuda_install_commands()
        create_install_script()
        
        print("\nüöÄ QUICK FIX:")
        print("   1. Run: pip uninstall torch torchvision torchaudio")
        print("   2. Run: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        print("   3. Restart your application")
        print("   4. ChatterboxTTS will automatically use GPU!")
        
    else:
        print("‚úÖ ALL GOOD: GPU available and PyTorch has CUDA support")
        test_performance_difference()
    
    print("\nüìö Additional Resources:")
    print("   - PyTorch Installation: https://pytorch.org/get-started/locally/")
    print("   - CUDA Toolkit: https://developer.nvidia.com/cuda-downloads")
    print("   - NVIDIA Drivers: https://www.nvidia.com/Download/index.aspx")

if __name__ == "__main__":
    main() 